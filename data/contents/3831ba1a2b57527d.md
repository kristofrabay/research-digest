# Use docs programmatically

**URL:** https://docs.langchain.com/use-these-docs
**Published:** 2025-04-01T00:00:00.000Z

---

## Summary

The webpage describes how to use the LangChain documentation programmatically, primarily through the **Model Context Protocol (MCP) server**.

Key points related to your query:

*   **agent_infrastructure:** The page focuses on making the documentation accessible to AI tools and workflows.
*   **agent memory/agentic memory:** The MCP server allows AI applications to query the latest docs in real-time, effectively providing a source of up-to-date knowledge for agents.
*   **agent frameworks:** The documentation is for **LangChain** and **LangGraph**.
*   **tool use/function calling/structured outputs:** While the page doesn't detail these concepts directly, it shows how to connect the documentation as a data source (via MCP) to AI assistants/tools (like Claude Code, Codex CLI, Cursor, VS Code) that would utilize these capabilities.
*   **agent orchestration:** The ability to connect documentation to various tools suggests integration into broader agent workflows.
*   **agent frameworks (LangChain, LlamaIndex, OpenAI Agents SDK, Anthropic Agents SDK, Google SDK):** The page is specifically about **LangChain** documentation. It shows integration examples with **Claude** (Anthropic) and mentions **OpenAI Codex CLI**.
*   **agent_infrastructure: MCP servers:** The core feature discussed is the built-in **Model Context Protocol (MCP) server** provided by the LangChain docs.

**Summary:**

This page explains how to programmatically access the LangChain documentation using its built-in **Model Context Protocol (MCP) server**. This server allows AI applications (like those built with **LangChain** or using tools like **Claude** or **Codex CLI**) to query the documentation in real-time, serving as a source of current information for agents. It provides specific instructions on how to connect this MCP server to various tools, including **Claude Code**, **Claude Desktop**, **Codex CLI**, **Cursor/VS Code**, and **Antigravity**.

---

## Full Content

Use docs programmatically - Docs by LangChain
[Skip to main content](#content-area)
[Docs by LangChainhome page![light logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-teal.svg?fit=max&amp;auto=format&amp;n=Xbr8HuVd9jPi6qTU&amp;q=85&amp;s=16111530672bf976cb54ef2143478342)![dark logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-lilac.svg?fit=max&amp;auto=format&amp;n=Xbr8HuVd9jPi6qTU&amp;q=85&amp;s=b70fb1a2208670492ef94aef14b680be)](https://docs.langchain.com/)
LangChain + LangGraph
Search...
⌘K
Search...
Navigation
Use docs programmatically
[LangChain
](https://docs.langchain.com/oss/python/langchain/overview)[LangGraph
](https://docs.langchain.com/oss/python/langgraph/overview)[Deep Agents
](https://docs.langchain.com/oss/python/deepagents/overview)[Integrations
](https://docs.langchain.com/oss/python/integrations/providers/overview)[Learn
](https://docs.langchain.com/oss/python/learn)[Reference
](https://docs.langchain.com/oss/python/reference/overview)[Contribute
](https://docs.langchain.com/oss/python/contributing/overview)
Python
* [
Overview
](https://docs.langchain.com/oss/python/langchain/overview)
##### Get started
* [
Install
](https://docs.langchain.com/oss/python/langchain/install)
* [
Quickstart
](https://docs.langchain.com/oss/python/langchain/quickstart)
* [
Changelog
](https://docs.langchain.com/oss/python/releases/changelog)
* [
Philosophy
](https://docs.langchain.com/oss/python/langchain/philosophy)
##### Core components
* [
Agents
](https://docs.langchain.com/oss/python/langchain/agents)
* [
Models
](https://docs.langchain.com/oss/python/langchain/models)
* [
Messages
](https://docs.langchain.com/oss/python/langchain/messages)
* [
Tools
](https://docs.langchain.com/oss/python/langchain/tools)
* [
Short-term memory
](https://docs.langchain.com/oss/python/langchain/short-term-memory)
* [
Streaming
](https://docs.langchain.com/oss/python/langchain/streaming)
* [
Structured output
](https://docs.langchain.com/oss/python/langchain/structured-output)
##### Middleware
* [
Overview
](https://docs.langchain.com/oss/python/langchain/middleware/overview)
* [
Built-in middleware
](https://docs.langchain.com/oss/python/langchain/middleware/built-in)
* [
Custom middleware
](https://docs.langchain.com/oss/python/langchain/middleware/custom)
##### Advanced usage
* [
Guardrails
](https://docs.langchain.com/oss/python/langchain/guardrails)
* [
Runtime
](https://docs.langchain.com/oss/python/langchain/runtime)
* [
Context engineering
](https://docs.langchain.com/oss/python/langchain/context-engineering)
* [
Model Context Protocol (MCP)
](https://docs.langchain.com/oss/python/langchain/mcp)
* [
Human-in-the-loop
](https://docs.langchain.com/oss/python/langchain/human-in-the-loop)
* Multi-agent
* [
Retrieval
](https://docs.langchain.com/oss/python/langchain/retrieval)
* [
Long-term memory
](https://docs.langchain.com/oss/python/langchain/long-term-memory)
##### Agent development
* [
LangSmith Studio
](https://docs.langchain.com/oss/python/langchain/studio)
* [
Test
](https://docs.langchain.com/oss/python/langchain/test)
* [
Agent Chat UI
](https://docs.langchain.com/oss/python/langchain/ui)
##### Deploy with LangSmith
* [
Deployment
](https://docs.langchain.com/oss/python/langchain/deploy)
* [
Observability
](https://docs.langchain.com/oss/python/langchain/observability)
On this page
* [Quick access options](#quick-access-options)
* [Use our MCP server](#use-our-mcp-server)
* [Connect with Claude Code](#connect-with-claude-code)
* [Connect with Claude Desktop](#connect-with-claude-desktop)
* [Connect with Codex CLI](#connect-with-codex-cli)
* [Connect with Cursor or VS Code](#connect-with-cursor-or-vs-code)
* [Connect with Antigravity](#connect-with-antigravity)
* [Learn more](#learn-more)
# Use docs programmatically
Copy page
Connect LangChain documentation to your AI tools and workflows
Copy page
We want to make our documentation as accessible as possible. We’ve included several ways for you to use these docs programmatically through AI assistants, code editors, and direct integrations, such as Model Context Protocol (MCP).## [​
](#quick-access-options)
Quick access options
On any page in our documentation, you’ll find a contextual menu dropdown in the top right corner:![Copy page light mode](https://mintcdn.com/langchain-5e9cc07a/jKM-tvbl7XiR347g/images/copy-page-light.png?fit=max&amp;auto=format&amp;n=jKM-tvbl7XiR347g&amp;q=85&amp;s=81d6cf67dc039d588707bd97ee3f3a72)![Copy page dark mode](https://mintcdn.com/langchain-5e9cc07a/jKM-tvbl7XiR347g/images/copy-page-dark.png?fit=max&amp;auto=format&amp;n=jKM-tvbl7XiR347g&amp;q=85&amp;s=9257e0b3480b22cdaf56b5c70305124d)This includes our`llms.txt`, MCP server connection, and other quick access options such as ChatGPT and Claude.## [​
](#use-our-mcp-server)
Use our MCP server
Our documentation includes a built-in**Model Context Protocol (MCP) server**that lets AI applications query the latest docs in real-time.The LangChain docs MCP server is available at:
Copy
```
`https://docs.langchain.com/mcp`
```
Once connected, you can ask your AI assistant questions about LangChain, LangGraph, and LangSmith, and it will search our documentation to provide accurate, current answers.### [​
](#connect-with-claude-code)
Connect with Claude Code
If you’re using Claude Code, run this command in your terminal to add the server to your current project:
Copy
```
`claudemcpadd--transporthttpdocs-langchainhttps://docs.langchain.com/mcp`
```
**Project (local) scoped**The command above adds the MCP server only to your current project/working directory. To add the MCP server globally and access it in all projects, add the user scope by adding`--scope user`to the command:
Copy
```
`claudemcpadd--transporthttpdocs-langchain--scopeuserhttps://docs.langchain.com/mcp`
```
### [​
](#connect-with-claude-desktop)
Connect with Claude Desktop
1. Open Claude Desktop
2. Go to Settings &gt; Connectors
3. Add our MCP server URL:`https://docs.langchain.com/mcp`### [​
](#connect-with-codex-cli)
Connect with Codex CLI
If you’re using OpenAI Codex CLI, run this command in your terminal to add the server globally:
Copy
```
`codexmcpaddlangchain-docs--urlhttps://docs.langchain.com/mcp`
```
### [​
](#connect-with-cursor-or-vs-code)
Connect with Cursor or VS Code
Add the following to your MCP settings configuration file:
Copy
```
`{&quot;mcpServers&quot;: {&quot;docs-langchain&quot;: {&quot;url&quot;:&quot;https://docs.langchain.com/mcp&quot;}}}`
```
### [​
](#connect-with-antigravity)
Connect with Antigravity
Add the following to your MCP settings configuration file:
Copy
```
`{&quot;mcpServers&quot;: {&quot;docs-langchain&quot;: {&quot;serverUrl&quot;:&quot;https://docs.langchain.com/mcp&quot;}}}`
```
## [​
](#learn-more)
Learn more
For more information about using Mintlify’s MCP servers, see the[official Mintlify documentation](https://www.mintlify.com/docs/ai/model-context-protocol).Have questions or feedback? Let us know in our[community forum](https://forum.langchain.com/).
[Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/use-these-docs.mdx)or[file an issue](https://github.com/langchain-ai/docs/issues/new/choose).
[Connect these docs](https://docs.langchain.com/use-these-docs)to Claude, VSCode, and more via MCP for real-time answers.
Was this page helpful?
YesNo
⌘I
