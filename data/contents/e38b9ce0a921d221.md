# MCP endpoint in Agent Server

**URL:** https://docs.langchain.com/langsmith/server-mcp
**Published:** 2025-03-26T00:00:00.000Z

---

## Summary

The webpage describes the **Model Context Protocol (MCP) endpoint in LangChain's Agent Server**.

**Key Summary Points:**

*   **What MCP is:** MCP is an open protocol for describing tools and data sources in a model-agnostic format, allowing LLMs to discover and use them via a structured API.
*   **Implementation:** Agent Server implements MCP using the Streamable HTTP transport. This allows **LangGraph agents** to be exposed as **MCP tools**.
*   **Endpoint Location:** The MCP endpoint is available at `/mcp` on the Agent Server.
*   **Usage:** MCP-compliant clients (supporting Streamable HTTP) can connect to the Agent Server to use these exposed agents as tools. Examples are provided for connecting via Python (using `langchain-mcp-adapters`) and JavaScript/TypeScript.
*   **Exposing Agents as Tools:** Agents are exposed with their name, description, and input schema. It is recommended to define custom agents with explicit input/output schemas rather than relying on the general `AnyMessage` state.
*   **User-Scoped Tools:** Custom authentication middleware can be used to populate user context, allowing user-scoped MCP tools to be accessed within a LangSmith deployment.
*   **Limitations:** The current LangGraph MCP implementation **does not support sessions**; each `/mcp` request is stateless.
*   **Disabling MCP:** The endpoint can be disabled by setting `"disable_mcp": true` in the configuration file.

**Regarding the User Query:**

The query lists several concepts related to agent infrastructure, frameworks, and SDKs: *agent\_infrastructure: MCP servers, tool use, agent memory, agentic memory, agent frameworks, LangChain, LlamaIndex, OpenAI Agents SDK, Anthropic Agents SDK, Google SDK, function calling, structured outputs, agent orchestration*.

The webpage directly addresses **MCP servers**, **tool use** (exposing agents as tools), **LangChain** (specifically LangGraph/Agent Server), and **structured outputs** (via defining explicit schemas).

It **does not** provide specific information on:
*   Agent memory or agentic memory.
*   LlamaIndex.
*   OpenAI Agents SDK, Anthropic Agents SDK, or Google SDK.
*   Agent orchestration (beyond the context of LangGraph).

**Summary tailored to the query:**

The page details the **

---

## Full Content

MCP endpoint in Agent Server - Docs by LangChain
[Skip to main content](#content-area)
[Docs by LangChainhome page![light logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-teal.svg?fit=max&amp;auto=format&amp;n=Xbr8HuVd9jPi6qTU&amp;q=85&amp;s=16111530672bf976cb54ef2143478342)![dark logo](https://mintcdn.com/langchain-5e9cc07a/Xbr8HuVd9jPi6qTU/images/brand/langchain-docs-lilac.svg?fit=max&amp;auto=format&amp;n=Xbr8HuVd9jPi6qTU&amp;q=85&amp;s=b70fb1a2208670492ef94aef14b680be)](https://docs.langchain.com/)
LangSmith
Search...
⌘K
Search...
Navigation
Core capabilities
MCP endpoint in Agent Server
[Get started
](https://docs.langchain.com/langsmith/home)[Observability
](https://docs.langchain.com/langsmith/observability)[Evaluation
](https://docs.langchain.com/langsmith/evaluation)[Prompt engineering
](https://docs.langchain.com/langsmith/prompt-engineering)[Deployment
](https://docs.langchain.com/langsmith/deployments)[Agent Builder
](https://docs.langchain.com/langsmith/agent-builder)[Platform setup
](https://docs.langchain.com/langsmith/platform-setup)[Reference
](https://docs.langchain.com/langsmith/reference)
* [
Overview
](https://docs.langchain.com/langsmith/deployments)
* [
Test locally
](https://docs.langchain.com/langsmith/local-server)
* [
App development
](https://docs.langchain.com/langsmith/app-development)
* [
Cloud quickstart
](https://docs.langchain.com/langsmith/deployment-quickstart)
##### Configure app for deployment
* [
Application structure
](https://docs.langchain.com/langsmith/application-structure)
* Setup
* Deployment components
* [
Rebuild graph at runtime
](https://docs.langchain.com/langsmith/graph-rebuild)
* [
Interact with a deployment using RemoteGraph
](https://docs.langchain.com/langsmith/use-remote-graph)
* [
Add semantic search to your agent deployment
](https://docs.langchain.com/langsmith/semantic-search)
* [
Add TTLs to your application
](https://docs.langchain.com/langsmith/configure-ttl)
* [
Configure Agent Server for scale
](https://docs.langchain.com/langsmith/agent-server-scale)
* [
Implement a CI/CD pipeline
](https://docs.langchain.com/langsmith/cicd-pipeline-example)
##### Deployment guides
* [
Cloud
](https://docs.langchain.com/langsmith/deploy-to-cloud)
* [
With control plane
](https://docs.langchain.com/langsmith/deploy-with-control-plane)
* [
Standalone servers
](https://docs.langchain.com/langsmith/deploy-standalone-server)
##### App development
* Data models
* Core capabilities
* [
Streaming API
](https://docs.langchain.com/langsmith/streaming)
* [
Human-in-the-loop using server API
](https://docs.langchain.com/langsmith/add-human-in-the-loop)
* [
Time travel using the server API
](https://docs.langchain.com/langsmith/human-in-the-loop-time-travel)
* [
MCP endpoint in Agent Server
](https://docs.langchain.com/langsmith/server-mcp)
* [
A2A endpoint in Agent Server
](https://docs.langchain.com/langsmith/server-a2a)
* [
Distributed tracing
](https://docs.langchain.com/langsmith/agent-server-distributed-tracing)
* [
Webhooks
](https://docs.langchain.com/langsmith/use-webhooks)
* Double-texting
* Tutorials
##### Studio
* [
Overview
](https://docs.langchain.com/langsmith/studio)
* [
Quickstart
](https://docs.langchain.com/langsmith/quick-start-studio)
* [
Runs, assistants, threads
](https://docs.langchain.com/langsmith/use-studio)
* [
Traces, datasets, prompts
](https://docs.langchain.com/langsmith/observability-studio)
* [
Troubleshooting
](https://docs.langchain.com/langsmith/troubleshooting-studio)
##### Auth &amp; access control
* [
Overview
](https://docs.langchain.com/langsmith/auth)
* [
Add custom authentication
](https://docs.langchain.com/langsmith/custom-auth)
* [
Set up custom authentication
](https://docs.langchain.com/langsmith/set-up-custom-auth)
* [
Make conversations private
](https://docs.langchain.com/langsmith/resource-auth)
* [
Connect an authentication provider
](https://docs.langchain.com/langsmith/add-auth-server)
* [
Document API authentication in OpenAPI
](https://docs.langchain.com/langsmith/openapi-security)
* [
Set up Agent Auth (Beta)
](https://docs.langchain.com/langsmith/agent-auth)
##### Server customization
* [
Add custom lifespan events
](https://docs.langchain.com/langsmith/custom-lifespan)
* [
Add custom middleware
](https://docs.langchain.com/langsmith/custom-middleware)
* [
Add custom routes
](https://docs.langchain.com/langsmith/custom-routes)
* [
Configurable headers
](https://docs.langchain.com/langsmith/configurable-headers)
* [
Logging Headers
](https://docs.langchain.com/langsmith/configurable-logs)
On this page
* [Requirements](#requirements)
* [Usage overview](#usage-overview)
* [Client](#client)
* [Expose an agent as MCP tool](#expose-an-agent-as-mcp-tool)
* [Setting name and description](#setting-name-and-description)
* [Schema](#schema)
* [Use user-scoped MCP tools in your deployment](#use-user-scoped-mcp-tools-in-your-deployment)
* [Session behavior](#session-behavior)
* [Authentication](#authentication)
* [Disable MCP](#disable-mcp)
[App development](https://docs.langchain.com/langsmith/assistants)
[Core capabilities](https://docs.langchain.com/langsmith/streaming)
# MCP endpoint in Agent Server
Copy page
Copy page
The Model Context Protocol (MCP) is an open protocol for describing tools and data sources in a model-agnostic format, enabling LLMs to discover and use them via a structured API.[Agent Server](https://docs.langchain.com/langsmith/agent-server)implements MCP using the[Streamable HTTP transport](https://spec.modelcontextprotocol.io/specification/2025-03-26/basic/transports/#streamable-http). This allows LangGraph**agents**to be exposed as**MCP tools**, making them usable with any MCP-compliant client supporting Streamable HTTP.The MCP endpoint is available at`/mcp`on[Agent Server](https://docs.langchain.com/langsmith/agent-server).You can set up[custom authentication middleware](https://docs.langchain.com/langsmith/custom-auth)to authenticate a user with an MCP server to get access to user-scoped tools within your LangSmith deployment.An example architecture for this flow:## [​
](#requirements)
Requirements
To use MCP, ensure you have the following dependencies installed:
* `langgraph-api &gt;= 0.2.3`
* `langgraph-sdk &gt;= 0.1.61`Install them with:
pip
uv
Copy
```
`pipinstall&quot;langgraph-api&gt;=0.2.3&quot;&quot;langgraph-sdk&gt;=0.1.61&quot;`
```
## [​
](#usage-overview)
Usage overview
To enable MCP:
* Upgrade to use langgraph-api&gt;=0.2.3. If you are deploying LangSmith, this will be done for you automatically if you create a new revision.
* MCP tools (agents) will be automatically exposed.
* Connect with any MCP-compliant client that supports Streamable HTTP.### [​
](#client)
Client
Use an MCP-compliant client to connect to the Agent Server. The following examples show how to connect using different programming languages.
* JavaScript/TypeScript
* Python
Copy
```
`npminstall@modelcontextprotocol/sdk`
```
> **> Note
**> Replace `> serverUrl
`> with your Agent Server URL and configure authentication headers as needed.
> Copy
```
`import{Client}from&quot;@modelcontextprotocol/sdk/client/index.js&quot;;import{StreamableHTTPClientTransport}from&quot;@modelcontextprotocol/sdk/client/streamableHttp.js&quot;;// Connects to the LangGraph MCP endpointasyncfunctionconnectClient(url) {constbaseUrl=newURL(url);constclient=newClient({name:&#x27;streamable-http-client&#x27;,version:&#x27;1.0.0&#x27;});consttransport=newStreamableHTTPClientTransport(baseUrl);awaitclient.connect(transport);console.log(&quot;Connected using Streamable HTTP transport&quot;);console.log(JSON.stringify(awaitclient.listTools(),null,2));returnclient;}constserverUrl=&quot;http://localhost:2024/mcp&quot;;connectClient(serverUrl).then(()=&gt;{console.log(&quot;Client connected successfully&quot;);}).catch(error=&gt;{console.error(&quot;Failed to connect client:&quot;,error);});`
```
Install the adapter with:
Copy
```
`pipinstalllangchain-mcp-adapters`
```
Here is an example of how to connect to a remote MCP endpoint and use an agent as a tool:
Copy
```
`# Create server parameters for stdio connectionfrommcpimportClientSessionfrommcp.client.streamable\_httpimportstreamablehttp\_clientimportasynciofromlangchain\_mcp\_adapters.toolsimportload\_mcp\_toolsfromlangchain.agentsimportcreate\_agentserver\_params={&quot;url&quot;:&quot;https://mcp-finance-agent.xxx.us.langgraph.app/mcp&quot;,&quot;headers&quot;: {&quot;X-Api-Key&quot;:&quot;&quot;lsv2\_pt\_your\_api\_key&quot;&quot;}}asyncdefmain():asyncwithstreamablehttp\_client(\*\*server\_params)as(read, write, \_):asyncwithClientSession(read, write)assession:# Initialize the connectionawaitsession.initialize()# Load the remote graph as if it was a tooltools=awaitload\_mcp\_tools(session)# Create and run a react agent with the toolsagent=create\_agent(&quot;gpt-4.1&quot;, tools)# Invoke the agent with a messageagent\_response=awaitagent.ainvoke({&quot;messages&quot;:&quot;What can the finance agent do for me?&quot;})print(agent\_response)if\_\_name\_\_==&quot;&quot;\_\_main\_\_&quot;&quot;:asyncio.run(main())`
```
## [​
](#expose-an-agent-as-mcp-tool)
Expose an agent as MCP tool
When deployed, your agent will appear as a tool in the MCP endpoint
with this configuration:
* **Tool name**: The agent’s name.
* **Tool description**: The agent’s description.
* **Tool input schema**: The agent’s input schema.### [​
](#setting-name-and-description)
Setting name and description
You can set the name and description of your agent in`langgraph.json`:
Copy
```
`{&quot;graphs&quot;: {&quot;&quot;my\_agent&quot;&quot;: {&quot;path&quot;:&quot;&quot;./my\_agent/agent.py:graph&quot;&quot;,&quot;description&quot;:&quot;A description of what the agent does&quot;}},&quot;env&quot;:&quot;.env&quot;}`
```
After deployment, you can update the name and description using the LangGraph SDK.### [​
](#schema)
Schema
Define clear, minimal input and output schemas to avoid exposing unnecessary internal complexity to the LLM.The default[MessagesState](https://docs.langchain.com/oss/python/langgraph/graph-api#messagesstate)uses`AnyMessage`, which supports many message types but is too general for direct LLM exposure.Instead, define**custom agents or workflows**that use explicitly typed input and output structures.For example, a workflow answering documentation questions might look like this:
Copy
```
`fromlanggraph.graphimportStateGraph,START,ENDfromtyping\_extensionsimportTypedDict# Define input schemaclassInputState(TypedDict):question:str# Define output schemaclassOutputState(TypedDict):answer:str# Combine input and outputclassOverallState(InputState,OutputState):pass# Define the processing nodedefanswer\_node(state: InputState):# Replace with actual logic and do something usefulreturn{&quot;answer&quot;:&quot;bye&quot;,&quot;question&quot;: state[&quot;question&quot;]}# Build the graph with explicit schemasbuilder=StateGraph(OverallState,input\_schema=InputState,output\_schema=OutputState)builder.add\_node(answer\_node)builder.add\_edge(START,&quot;&quot;answer\_node&quot;&quot;)builder.add\_edge(&quot;&quot;answer\_node&quot;&quot;,END)graph=builder.compile()# Run the graphprint(graph.invoke({&quot;question&quot;:&quot;hi&quot;}))`
```
For more details, see the[low-level concepts guide](https://docs.langchain.com/oss/python/langgraph/graph-api#state).## [​
](#use-user-scoped-mcp-tools-in-your-deployment)
Use user-scoped MCP tools in your deployment
**Prerequisites**You have added your own[custom auth middleware](https://docs.langchain.com/langsmith/custom-auth)that populates the`langgraph\_auth\_user`object, making it accessible through configurable context for every node in your graph.
To make user-scoped tools available to your LangSmith deployment, start with implementing a snippet like the following:
Copy
```
`fromlangchain\_mcp\_adapters.clientimportMultiServerMCPClientdefmcp\_tools\_node(state,config):user=config[&quot;configurable&quot;].get(&quot;&quot;langgraph\_auth\_user&quot;&quot;), user[&quot;&quot;github\_token&quot;&quot;], user[&quot;email&quot;], etc.client=MultiServerMCPClient({&quot;github&quot;: {&quot;transport&quot;:&quot;&quot;streamable\_http&quot;&quot;,# (1)&quot;url&quot;:&quot;https://my-github-mcp-server/mcp&quot;,# (2)&quot;headers&quot;: {&quot;Authorization&quot;:f&quot;Bearer{user[&#x27;&#x27;github\_token&#x27;&#x27;]}&quot;}}})tools=awaitclient.get\_tools()# (3)# Your tool-calling logic heretool\_messages=...return{&quot;messages&quot;: tool\_messages}`
```
1. MCP only supports adding headers to requests made to`streamable\_http`and`sse``transport`servers.
2. Your MCP server URL.
3. Get available tools from your MCP server.*This can also be done by[rebuilding your graph at runtime](https://docs.langchain.com/langsmith/graph-rebuild)to have a different configuration for a new run*## [​
](#session-behavior)
Session behavior
The current LangGraph MCP implementation does not support sessions. Each`/mcp`request is stateless and independent.## [​
](#authentication)
Authentication
The`/mcp`endpoint uses the same authentication as the rest of the LangGraph API. Refer to the[authentication guide](https://docs.langchain.com/langsmith/auth)for setup details.## [​
](#disable-mcp)
Disable MCP
To disable the MCP endpoint, set`disable\_mcp`to`true`in your`langgraph.json`configuration file:
Copy
```
`{&quot;$schema&quot;:&quot;https://langgra.ph/schema.json&quot;,&quot;http&quot;: {&quot;&quot;disable\_mcp&quot;&quot;:true}}`
```
This will prevent the server from exposing the`/mcp`endpoint.
[Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/server-mcp.mdx)or[file an issue](https://github.com/langchain-ai/docs/issues/new/choose).
[Connect these docs](https://docs.langchain.com/use-these-docs)to Claude, VSCode, and more via MCP for real-time answers.
Was this page helpful?
YesNo
[
Time travel using the server API
Previous
](https://docs.langchain.com/langsmith/human-in-the-loop-time-travel)[
A2A endpoint in Agent Server
Next
](https://docs.langchain.com/langsmith/server-a2a)
⌘I
