# Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search | OpenReview

**URL:** https://openreview.net/forum?id=9SpWvX9ykp&noteId=kH2xomkeeu
**Published:** 2025-01-01T00:00:00.000Z

---

## Summary

The webpage describes a paper titled "Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search."

The user query is a broad list of topics related to advanced LLM capabilities, including: 'reasoning\_and\_planning: Reasoning LLMs, chain-of-thought, inference-time compute, self-reflection, planning with LLMs, MCTS (Monte Carlo Tree Search) for language models, test-time scaling, hallucination reduction and detection, grounding, factuality'.

The webpage directly addresses several of these concepts:
*   **Planning with LLMs / MCTS (Monte Carlo Tree Search) for language models:** The core of the work involves using Monte Carlo Tree Search (MCTS) to guide the generation of code world models by an LLM, and then using these code models for planning.
*   **Reasoning LLMs / Reasoning and Planning:** The goal is to use code generated by an LLM as a world model for model-based Reinforcement Learning (RL) planning, aiming for precision and reliability over direct LLM calls for planning.

However, the page does not explicitly discuss or detail: chain-of-thought, inference-time compute, self-reflection (beyond the "Fix" step in GIF-MCTS), test-time scaling, hallucination reduction and detection, grounding, or factuality in a general sense.

**Summary relevant to the query:**

This paper proposes using Large Language Models (LLMs) to generate "Code World Models" (Python code representing RL environments) for model-based Reinforcement Learning (RL) planning. To improve the code generation necessary for this task, they introduce **Generate, Improve and Fix with Monte Carlo Tree Search (GIF-MCTS)**, a strategy that leverages **MCTS** to guide the LLM. The resulting code world models are shown to enable **planning** that is more precise, reliable, and efficient than direct LLM planning.

---

## Full Content

Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search | OpenReview
[![back arrow](https://openreview.net/images/arrow_left.svg)Go to**NeurIPS 2024 Conference**homepage](https://openreview.net/group?id=NeurIPS.cc/2024/Conference)
## Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search
[![Download PDF](https://openreview.net/images/pdf_icon_blue.svg)](https://openreview.net/pdf?id=9SpWvX9ykp)
### [Nicola Dainese](https://openreview.net/profile?id=~Nicola_Dainese2),[Matteo Merler](https://openreview.net/profile?id=~Matteo_Merler1),[Minttu Alakuijala](https://openreview.net/profile?id=~Minttu_Alakuijala1),[Pekka Marttinen](https://openreview.net/profile?id=~Pekka_Marttinen1)
Published: 25 Sept 2024, Last Modified: 06 Nov 2024NeurIPS 2024 posterEveryone[Revisions](https://openreview.net/revisions?id=9SpWvX9ykp)[BibTeX](#)[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)
**Keywords:**Large Language Models, code generation, MCTS, model-based reinforcement learning
**TL;DR:**We propose to model RL environments with code written by an LLM, propose a method to improve code generation for this task and show how to plan with code world models.
**Abstract:**In this work we consider Code World Models, world models generated by a Large Language Model (LLM) in the form of Python code for model-based Reinforcement Learning (RL). Calling code instead of LLMs for planning has potential to be more precise, reliable, interpretable, and extremely efficient.
However, writing appropriate Code World Models requires the ability to understand complex instructions, to generate exact code with non-trivial logic and to self-debug a long program with feedback from unit tests and environment trajectories. To address these challenges, we propose Generate, Improve and Fix with Monte Carlo Tree Search (GIF-MCTS), a new code generation strategy for LLMs. To test our approach in an offline RL setting, we introduce the Code World Models Benchmark (CWMB), a suite of program synthesis and planning tasks comprised of 18 diverse RL environments paired with corresponding textual descriptions and curated trajectories. GIF-MCTS surpasses all baselines on the CWMB and two other benchmarks, and we show that the Code World Models synthesized with it can be successfully used for planning, resulting in model-based RL agents with greatly improved sample efficiency and inference speed.
**Supplementary Material:**[zip](https://openreview.net/attachment?id=9SpWvX9ykp&amp;name=supplementary_material)
**Primary Area:**Natural language processing
**Submission Number:**12041
Loading
[OpenReview](https://openreview.net/about)is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the[OpenReview Sponsors](https://openreview.net/sponsors). Â©2025OpenReview
