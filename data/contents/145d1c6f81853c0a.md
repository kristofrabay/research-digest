# Language Models Perform Reasoning via Chain of Thought

**URL:** https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/
**Published:** 2024-05-30T00:00:00.000Z

---

## Summary

The provided webpage discusses **Chain of Thought (CoT) Prompting** as a method to enable large language models (LLMs) to perform multi-step reasoning tasks, such as arithmetic word problems and commonsense reasoning.

Key points related to your query:

*   **Reasoning LLMs and Chain-of-Thought:** CoT prompting involves prompting the model to produce intermediate reasoning steps before giving the final answer, mimicking an intuitive thought process. This method is shown to improve reasoning abilities in LLMs of sufficient scale ($\sim$100B parameters).
*   **Inference-time Compute/Scaling:** The benefits of CoT prompting are an **emergent property of model scale**; performance improvements are only seen with larger models (around 100B parameters or more).
*   **Planning with LLMs:** While the text focuses on reasoning decomposition, the concept of breaking down a problem into intermediate steps is foundational to planning.
*   **Performance Improvements:** CoT prompting led to state-of-the-art performance on the GSM8K arithmetic reasoning benchmark when combined with the 540B parameter PaLM model. Performance also improved on commonsense reasoning tasks.

The page **does not** explicitly discuss:
*   MCTS (Monte Carlo Tree Search) for language models.
*   Test-time scaling (beyond the observation that CoT is scale-dependent).
*   Hallucination reduction and detection.
*   Grounding or factuality (though improved reasoning might indirectly help).
*   Self-reflection.

---

## Full Content

Language Models Perform Reasoning via Chain of Thought
[Jump to Content](#page-content)
[
Research](https://research.google/)
[
Research](https://research.google/)
Search
![](https://storage.googleapis.com/gweb-research2023-media/original_images/8a16b7eee6b4708eb244336077430e64-chainofthought.png)
# Language Models Perform Reasoning via Chain of Thought
May 11, 2022
Posted by Jason Wei and Denny Zhou, Research Scientists, Google Research, Brain team
## Quick links
* Share
* [](https://twitter.com/intent/tweet?text=https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/)
* [](https://www.facebook.com/sharer/sharer.php?u=https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/)
* [](https://www.linkedin.com/shareArticle?url=https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/&amp;mini=true)
* []()
* Copy link
×In recent years,[scaling up the size of language models](https://arxiv.org/abs/2005.14165)has been shown to be a reliable way to improve performance on a range of natural language processing (NLP) tasks. Today’s language models at the scale of 100B or more parameters achieve strong performance on tasks like[sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)and machine translation,[even with little or no training examples](http://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html). Even the[largest language models](https://deepmind.com/blog/article/language-modelling-at-scale), however, can still struggle with certain multi-step reasoning tasks, such as math word problems and[commonsense reasoning](https://en.wikipedia.org/wiki/Commonsense_reasoning). How might we enable language models to perform such reasoning tasks?
In “[Chain of Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903),” we explore a prompting method for improving the reasoning abilities of language models. Called*chain of thought prompting*, this method enables models to decompose multi-step problems into intermediate steps. With chain of thought prompting, language models of sufficient scale (\~100B parameters) can solve complex reasoning problems that are not solvable with standard prompting methods.
## Comparison to Standard Prompting
With*standard prompting*(popularized by[GPT-3](https://arxiv.org/abs/2005.14165)) the model is given examples of input–output pairs (formatted as questions and answers) before being asked to predict the answer for a test-time example (shown below on the left). In*chain of thought prompting*(below, right), the model is prompted to produce intermediate reasoning steps before giving the final answer to a multi-step problem. The idea is that a model-generated chain of thought would mimic an intuitive thought process when working through a multi-step reasoning problem. While producing a thought process has been[previously accomplished](https://arxiv.org/abs/2006.06609)via fine-tuning, we show that such thought processes can be elicited by including a few examples of chain of thought via prompting only, which does not require a large training dataset or modifying the language model’s weights.
[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVgTjwA0IzKekrQoMziCmDXjO10QKjdDdzK1Oj8bZToPOI6VjVzTKXZ6vnWvAGOdVnWznJK2ZZjfBuTLojobayI_yrvlFzE3dCErF2j5wKLGFWAkuGP9-r-hMrqFivnjYhbCIu7HFINSmHu4wUjlKHfJxWHZ8Y7CYUowWvxTeRJhQEAUswGh2fUd3VHA/s16000/chainofthought.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVgTjwA0IzKekrQoMziCmDXjO10QKjdDdzK1Oj8bZToPOI6VjVzTKXZ6vnWvAGOdVnWznJK2ZZjfBuTLojobayI_yrvlFzE3dCErF2j5wKLGFWAkuGP9-r-hMrqFivnjYhbCIu7HFINSmHu4wUjlKHfJxWHZ8Y7CYUowWvxTeRJhQEAUswGh2fUd3VHA/s2500/chainofthought.png)|
Whereas standard prompting asks the model to directly give the answer to a multi-step reasoning problem, chain of thought prompting induces the model to decompose the problem into intermediate reasoning steps, in this case leading to a correct final answer.|
Chain of thought reasoning allows models to decompose complex problems into intermediate steps that are solved individually. Moreover, the language-based nature of chain of thought makes it applicable to any task that a person could solve via language. We find through empirical experiments that chain of thought prompting can improve performance on various reasoning tasks, and that successful chain of thought reasoning is an emergent property of model scale —that is, the benefits of chain of thought prompting only materialize with a sufficient number of model parameters (around 100B).
## Arithmetic Reasoning
One class of tasks where language models typically struggle is arithmetic reasoning (i.e., solving math word problems). Two benchmarks in arithmetic reasoning are[MultiArith](https://aclanthology.org/D15-1202/)and[GSM8K](https://arxiv.org/abs/2110.14168), which test the ability of language models to solve multi-step math problems similar to the one shown in the figure above. We evaluate both the[LaMDA collection](https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html)of language models ranging from 422M to 137B parameters, as well as the[PaLM collection](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)of language models ranging from 8B to 540B parameters. We manually compose chains of thought to include in the examples for chain of thought prompting.
For these two benchmarks, using standard prompting leads to relatively flat scaling curves: increasing the scale of the model does not substantially improve performance (shown below). However, we find that when using chain of thought prompting, increasing model scale leads to improved performance that substantially outperforms standard prompting for large model sizes.
[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVDwdni4scPDoSVP6km1ShzOv4_ksu5drP9tgb8UKmcwEv123vJplm8YmxvyqIjP5IrUF6XcE5WdgC6a92V73g0A6OC3_JVEFSsHI_pqngH-Ox9SgApnx_8n-wSO3uL51VvFugJVnvh8a8JxDs3IB6YttmnIr2_tAY1lAMsUo2NmmQDBZFgbKSlqS3tg/w400-h361/image3.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVDwdni4scPDoSVP6km1ShzOv4_ksu5drP9tgb8UKmcwEv123vJplm8YmxvyqIjP5IrUF6XcE5WdgC6a92V73g0A6OC3_JVEFSsHI_pqngH-Ox9SgApnx_8n-wSO3uL51VvFugJVnvh8a8JxDs3IB6YttmnIr2_tAY1lAMsUo2NmmQDBZFgbKSlqS3tg/s1668/image3.png)|
Employing chain of thought prompting enables language models to solve arithmetic reasoning problems for which standard prompting has a mostly flat scaling curve.|
On the GSM8K dataset of math word problems, PaLM shows remarkable performance when scaled to 540B parameters. As shown in the table below, combining chain of thought prompting with the 540B parameter PaLM model leads to new state-of-the-art performance of 58%, surpassing the prior state of the art of 55% achieved by fine-tuning GPT-3 175B on a large training set and then ranking potential solutions via a specially trained verifier. Moreover,[follow-up work](https://arxiv.org/abs/2203.11171)on self-consistency shows that the performance of chain of thought prompting can be improved further by taking the majority vote of a broad set of generated reasoning processes, which results in 74% accuracy on GSM8K.
[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSCwXiVA9mfEWOSGsMLykyu9K8NVArBjX3ctAItxNKTFRSmYp5d-55YggcKcG_Zcw8mAZxNtil2JwKW46egcUNTirMGnWlcXEN8Z8WRqFCEwRalgm6TUNGYT1nfvaXNSPXVZcJ0AbVLGGu13oLEeQEVFdsdMA2sPgi1gL9Ss8BHjdvy7Fxt5OIzgaaQw/s16000/image1.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSCwXiVA9mfEWOSGsMLykyu9K8NVArBjX3ctAItxNKTFRSmYp5d-55YggcKcG_Zcw8mAZxNtil2JwKW46egcUNTirMGnWlcXEN8Z8WRqFCEwRalgm6TUNGYT1nfvaXNSPXVZcJ0AbVLGGu13oLEeQEVFdsdMA2sPgi1gL9Ss8BHjdvy7Fxt5OIzgaaQw/s1650/image1.png)|
Chain of thought prompting with[PaLM](https://arxiv.org/abs/2204.02311)achieves a new state of the art on the[GSM8K](https://arxiv.org/abs/2110.14168)benchmark of math word problems. For a fair comparison against[fine-tuned GPT-3 baselines](https://arxiv.org/abs/2110.14168), the chain of thought prompting results shown here also use an external calculator to compute basic arithmetic functions (i.e., addition, subtraction, multiplication and division).|
## Commonsense Reasoning
In addition to arithmetic reasoning, we consider whether the language-based nature of chain of thought prompting also makes it applicable to commonsense reasoning, which involves reasoning about physical and human interactions under the presumption of general background knowledge. For these evaluations, we use the[CommonsenseQA](https://aclanthology.org/N19-1421)and[StrategyQA](https://aclanthology.org/2021.tacl-1.21)benchmarks, as well as two domain-specific tasks from[BIG-Bench collaboration](https://github.com/google/BIG-bench/)regarding[date understanding](https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/date_understanding)and[sports understanding](https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/sports_understanding). Example questions are below:
[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiz7H_4e2Jpq8m2CiSpl0JO0-Ud9c_ebWdnzrrkr4N3yVqAnyDaCAf8Bp-9chUi1mFqI4bkw__E6jaAVn1Kv2B2l8ZoPCSIjSMcddiaVAM7HvT63Rl8BBhtq84rpUCSHeTBP5K6Md-n3pJqpaOt7GP3qbjaXNrp2_ybWGJkHYpO8SU2g7VdX8esuaucOQ/s16000/image5.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiz7H_4e2Jpq8m2CiSpl0JO0-Ud9c_ebWdnzrrkr4N3yVqAnyDaCAf8Bp-9chUi1mFqI4bkw__E6jaAVn1Kv2B2l8ZoPCSIjSMcddiaVAM7HvT63Rl8BBhtq84rpUCSHeTBP5K6Md-n3pJqpaOt7GP3qbjaXNrp2_ybWGJkHYpO8SU2g7VdX8esuaucOQ/s1999/image5.png)|
|
As shown below, for CommonsenseQA, StrategyQA, and Date Understanding, performance improved with model scale, and employing chain of thought prompting led to additional small improvements. Chain of thought prompting had the biggest improvement on sports understanding, for which PaLM 540B’s chain of thought performance surpassed that of an unaided sports enthusiast (95% vs 84%).
[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgDGlodyYt7Sia5fltmP7LiXNoc3sKEdKRUWcRhhQ5Q2FgGJ8Zjxz_kcEYGJGkOtYOZww12JYeyYkv5bpJCL6qCB8ZnEIL-VoVUxWOg34fFGPK00IHqQGsiHQQ5A8xf65Nq9waX7pP-AfpLHSJTslQPurvTK6MgT_a-EcxJnpT_ub4SV9zAOwnFYB4whg/s16000/image4.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgDGlodyYt7Sia5fltmP7LiXNoc3sKEdKRUWcRhhQ5Q2FgGJ8Zjxz_kcEYGJGkOtYOZww12JYeyYkv5bpJCL6qCB8ZnEIL-VoVUxWOg34fFGPK00IHqQGsiHQQ5A8xf65Nq9waX7pP-AfpLHSJTslQPurvTK6MgT_a-EcxJnpT_ub4SV9zAOwnFYB4whg/s1999/image4.png)|
Chain of thought prompting also improves performance on various types of commonsense reasoning tasks.|
## Conclusions
Chain of thought prompting is a simple and broadly applicable method for improving the ability of language models to perform various reasoning tasks. Through experiments on arithmetic and commonsense reasoning, we find that chain of thought prompting is an emergent property of model scale. Broadening the range of reasoning tasks that language models can perform will hopefully inspire further work on language-based approaches to reasoning.
## Acknowledgements
*It was an honor and privilege to work with Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Quoc Le on this project.*
Labels:
* [Conferences &amp; Events](https://research.google/blog/label/conferences-events)
## Quick links
* Share
* [](https://twitter.com/intent/tweet?text=https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/)
* [](https://www.facebook.com/sharer/sharer.php?u=https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/)
* [](https://www.linkedin.com/shareArticle?url=https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/&amp;mini=true)
* []()
* Copy link
×### Other posts of interest
* [
![](https://storage.googleapis.com/gweb-research2023-media/original_images/Ideathon1_Group.png)
December 12, 2025
Spotlight on innovation: Google-sponsored Data Science for Health Ideathon across Africa
* Conferences &amp; Events&#183;
* Generative AI&#183;
* Global&#183;
* Health &amp; Bioscience
](https://research.google/blog/spotlight-on-innovation-google-sponsored-data-science-for-health-ideathon-across-africa/)
* [
![](https://storage.googleapis.com/gweb-research2023-media/original_images/CodecLM1-Hero.png)
May 30, 2024
CodecLM: Aligning language models with tailored synthetic data
* Conferences &amp; Events&#183;
* Machine Intelligence&#183;
* Natural Language Processing
](https://research.google/blog/codeclm-aligning-language-models-with-tailored-synthetic-data/)
* [
![](https://storage.googleapis.com/gweb-research2023-media/original_images/GRatIO2024-1-logo.png)
May 24, 2024
Google Research at Google I/O 2024
* Conferences &amp; Events&#183;
* Generative AI&#183;
* Health &amp; Bioscience&#183;
* Machine Intelligence&#183;
* Product&#183;
* Quantum&#183;
* Responsible AI
](https://research.google/blog/google-research-at-google-io-2024/)
&times;&#10094;&#10095;
![https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgDGlodyYt7Sia5fltmP7LiXNoc3sKEdKRUWcRhhQ5Q2FgGJ8Zjxz_kcEYGJGkOtYOZww12JYeyYkv5bpJCL6qCB8ZnEIL-VoVUxWOg34fFGPK00IHqQGsiHQQ5A8xf65Nq9waX7pP-AfpLHSJTslQPurvTK6MgT_a-EcxJnpT_ub4SV9zAOwnFYB4whg/s16000/image4.png](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgDGlodyYt7Sia5fltmP7LiXNoc3sKEdKRUWcRhhQ5Q2FgGJ8Zjxz_kcEYGJGkOtYOZww12JYeyYkv5bpJCL6qCB8ZnEIL-VoVUxWOg34fFGPK00IHqQGsiHQQ5A8xf65Nq9waX7pP-AfpLHSJTslQPurvTK6MgT_a-EcxJnpT_ub4SV9zAOwnFYB4whg/s16000/image4.png)
![https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiz7H_4e2Jpq8m2CiSpl0JO0-Ud9c_ebWdnzrrkr4N3yVqAnyDaCAf8Bp-9chUi1mFqI4bkw__E6jaAVn1Kv2B2l8ZoPCSIjSMcddiaVAM7HvT63Rl8BBhtq84rpUCSHeTBP5K6Md-n3pJqpaOt7GP3qbjaXNrp2_ybWGJkHYpO8SU2g7VdX8esuaucOQ/s16000/image5.png](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiz7H_4e2Jpq8m2CiSpl0JO0-Ud9c_ebWdnzrrkr4N3yVqAnyDaCAf8Bp-9chUi1mFqI4bkw__E6jaAVn1Kv2B2l8ZoPCSIjSMcddiaVAM7HvT63Rl8BBhtq84rpUCSHeTBP5K6Md-n3pJqpaOt7GP3qbjaXNrp2_ybWGJkHYpO8SU2g7VdX8esuaucOQ/s16000/image5.png)
![https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVgTjwA0IzKekrQoMziCmDXjO10QKjdDdzK1Oj8bZToPOI6VjVzTKXZ6vnWvAGOdVnWznJK2ZZjfBuTLojobayI_yrvlFzE3dCErF2j5wKLGFWAkuGP9-r-hMrqFivnjYhbCIu7HFINSmHu4wUjlKHfJxWHZ8Y7CYUowWvxTeRJhQEAUswGh2fUd3VHA/s16000/chainofthought.png](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVgTjwA0IzKekrQoMziCmDXjO10QKjdDdzK1Oj8bZToPOI6VjVzTKXZ6vnWvAGOdVnWznJK2ZZjfBuTLojobayI_yrvlFzE3dCErF2j5wKLGFWAkuGP9-r-hMrqFivnjYhbCIu7HFINSmHu4wUjlKHfJxWHZ8Y7CYUowWvxTeRJhQEAUswGh2fUd3VHA/s16000/chainofthought.png)
![https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVDwdni4scPDoSVP6km1ShzOv4_ksu5drP9tgb8UKmcwEv123vJplm8YmxvyqIjP5IrUF6XcE5WdgC6a92V73g0A6OC3_JVEFSsHI_pqngH-Ox9SgApnx_8n-wSO3uL51VvFugJVnvh8a8JxDs3IB6YttmnIr2_tAY1lAMsUo2NmmQDBZFgbKSlqS3tg/w400-h361/image3.png](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhVDwdni4scPDoSVP6km1ShzOv4_ksu5drP9tgb8UKmcwEv123vJplm8YmxvyqIjP5IrUF6XcE5WdgC6a92V73g0A6OC3_JVEFSsHI_pqngH-Ox9SgApnx_8n-wSO3uL51VvFugJVnvh8a8JxDs3IB6YttmnIr2_tAY1lAMsUo2NmmQDBZFgbKSlqS3tg/w400-h361/image3.png)
![https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSCwXiVA9mfEWOSGsMLykyu9K8NVArBjX3ctAItxNKTFRSmYp5d-55YggcKcG_Zcw8mAZxNtil2JwKW46egcUNTirMGnWlcXEN8Z8WRqFCEwRalgm6TUNGYT1nfvaXNSPXVZcJ0AbVLGGu13oLEeQEVFdsdMA2sPgi1gL9Ss8BHjdvy7Fxt5OIzgaaQw/s16000/image1.png](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSCwXiVA9mfEWOSGsMLykyu9K8NVArBjX3ctAItxNKTFRSmYp5d-55YggcKcG_Zcw8mAZxNtil2JwKW46egcUNTirMGnWlcXEN8Z8WRqFCEwRalgm6TUNGYT1nfvaXNSPXVZcJ0AbVLGGu13oLEeQEVFdsdMA2sPgi1gL9Ss8BHjdvy7Fxt5OIzgaaQw/s16000/image1.png)
&times;
![]()
