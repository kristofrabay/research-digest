# Search code, repositories, users, issues, pull requests...

**URL:** https://github.com/langchain-ai/agent-protocol
**Published:** 2024-11-12T22:41:45.000Z

---

## Summary

The webpage describes the **Agent Protocol**, which aims to codify framework-agnostic APIs for serving LLM agents in production.

The protocol centers around three core concepts:

1.  **Runs:** APIs for executing an agent, supporting both stateless (one-shot) and background execution paradigms, including waiting for output or streaming results.
2.  **Threads:** APIs for organizing multi-turn agent executions, providing persistent state, history tracking, and concurrency controls.
3.  **Store:** APIs for working with long-term memory, allowing for customizable memory scopes and flexible storage (text and structured data) with CRUD and search capabilities.

The protocol also defines endpoints for **Agent Introspection** (getting agent capabilities) and first-class support for **Messages**, defining a Message spec based on formats used by providers like OpenAI and Anthropic.

While the page details the structure and endpoints of the Agent Protocol (Runs, Threads, Store), it **does not explicitly mention or detail** the following terms from your query: **MCP servers, tool use, agent memory (beyond the Store concept), agentic memory, agent frameworks (other than mentioning LangGraph implements a superset), LangChain, LlamaIndex, OpenAI Agents SDK, Anthropic Agents SDK, Google SDK, function calling, structured outputs, or agent orchestration.**

---

## Full Content

GitHub - langchain-ai/agent-protocol
[Skip to content](#start-of-content)
## Navigation Menu
Toggle navigation
[](https://github.com/)
[Sign in](https://github.com/login?return_to=https://github.com/langchain-ai/agent-protocol)
Appearance settings
Search or jump to...
# Search code, repositories, users, issues, pull requests...
 
Search
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
# Provide feedback
 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
CancelSubmit feedback
# Saved searches
## Use saved searches to filter your results more quickly
 
Name
Query
To see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).
CancelCreate saved search
[Sign in](https://github.com/login?return_to=https://github.com/langchain-ai/agent-protocol)
[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=langchain-ai/agent-protocol)
Appearance settings
Resetting focus
You signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert
{{ message }}
[langchain-ai](https://github.com/langchain-ai)/**[agent-protocol](https://github.com/langchain-ai/agent-protocol)**Public
* [Notifications](https://github.com/login?return_to=/langchain-ai/agent-protocol)You must be signed in to change notification settings
* [Fork37](https://github.com/login?return_to=/langchain-ai/agent-protocol)
* [Star499](https://github.com/login?return_to=/langchain-ai/agent-protocol)
[langchain-ai.github.io/agent-protocol/api.html](https://langchain-ai.github.io/agent-protocol/api.html)
### License
[MIT license](https://github.com/langchain-ai/agent-protocol/blob/main/LICENSE)
[499stars](https://github.com/langchain-ai/agent-protocol/stargazers)[37forks](https://github.com/langchain-ai/agent-protocol/forks)[Branches](https://github.com/langchain-ai/agent-protocol/branches)[Tags](https://github.com/langchain-ai/agent-protocol/tags)[Activity](https://github.com/langchain-ai/agent-protocol/activity)
[Star](https://github.com/login?return_to=/langchain-ai/agent-protocol)
[Notifications](https://github.com/login?return_to=/langchain-ai/agent-protocol)You must be signed in to change notification settings
# langchain-ai/agent-protocol
main
[Branches](https://github.com/langchain-ai/agent-protocol/branches)[Tags](https://github.com/langchain-ai/agent-protocol/tags)
[](https://github.com/langchain-ai/agent-protocol/branches)[](https://github.com/langchain-ai/agent-protocol/tags)
Go to file
Code
Open more actions menu
## Folders and files
|Name|Name|
Last commit message
|
Last commit date
|
## Latest commit
## History
[136 Commits](https://github.com/langchain-ai/agent-protocol/commits/main/)
[](https://github.com/langchain-ai/agent-protocol/commits/main/)
|
[client-python](https://github.com/langchain-ai/agent-protocol/tree/main/client-python)
|
[client-python](https://github.com/langchain-ai/agent-protocol/tree/main/client-python)
|
|
|
[server](https://github.com/langchain-ai/agent-protocol/tree/main/server)
|
[server](https://github.com/langchain-ai/agent-protocol/tree/main/server)
|
|
|
[tooling](https://github.com/langchain-ai/agent-protocol/tree/main/tooling)
|
[tooling](https://github.com/langchain-ai/agent-protocol/tree/main/tooling)
|
|
|
[.gitignore](https://github.com/langchain-ai/agent-protocol/blob/main/.gitignore)
|
[.gitignore](https://github.com/langchain-ai/agent-protocol/blob/main/.gitignore)
|
|
|
[CONTRIBUTING.md](https://github.com/langchain-ai/agent-protocol/blob/main/CONTRIBUTING.md)
|
[CONTRIBUTING.md](https://github.com/langchain-ai/agent-protocol/blob/main/CONTRIBUTING.md)
|
|
|
[LICENSE](https://github.com/langchain-ai/agent-protocol/blob/main/LICENSE)
|
[LICENSE](https://github.com/langchain-ai/agent-protocol/blob/main/LICENSE)
|
|
|
[README.md](https://github.com/langchain-ai/agent-protocol/blob/main/README.md)
|
[README.md](https://github.com/langchain-ai/agent-protocol/blob/main/README.md)
|
|
|
[api.html](https://github.com/langchain-ai/agent-protocol/blob/main/api.html)
|
[api.html](https://github.com/langchain-ai/agent-protocol/blob/main/api.html)
|
|
|
[openapi.json](https://github.com/langchain-ai/agent-protocol/blob/main/openapi.json)
|
[openapi.json](https://github.com/langchain-ai/agent-protocol/blob/main/openapi.json)
|
|
|
View all files
|
## Repository files navigation
# Agent Protocol
[](#agent-protocol)
Agent Protocol is our attempt at codifying the framework-agnostic APIs that are needed to serve LLM agents in production. This document explains the purpose of the protocol and makes the case for each of the endpoints in the spec. We finish by listing some roadmap items for the future.
See the full OpenAPI docs[here](https://langchain-ai.github.io/agent-protocol/api.html)and the JSON spec[here](https://langchain-ai.github.io/agent-protocol/openapi.json).
[LangGraph Platform](https://www.langchain.com/pricing-langgraph-platform)implements a superset of this protocol, but we very much welcome other implementations from the community.
## Resources
[](#resources)
* [Agent Protocol OpenAPI Docs](https://langchain-ai.github.io/agent-protocol/api.html)
* [Agent Protocol JSON Spec](https://langchain-ai.github.io/agent-protocol/openapi.json)
* [Agent Protocol Python Server Stubs](https://github.com/langchain-ai/agent-protocol/blob/main/server)- a Python server, using Pydantic V2 and FastAPI, auto-generated from the OpenAPI spec
* [LangGraph.js API](https://github.com/langchain-ai/langgraphjs-api/tree/main/libs/langgraph-api)- an open-source implementation of this protocol, for LangGraph.js agents, using in-memory storage
* [LangGraph Platform](https://www.langchain.com/pricing-langgraph-platform)- a commercial platform that implements a superset of this protocol for deploying any LLM agent in production
## Why Agent Protocol
[](#why-agent-protocol)
What is the right API to serve an LLM application in production? We believe it’s centered around 3 important concepts:
* Runs: APIs for executing an agent
* Threads: APIs to organize multi-turn executions of agents
* Store: APIs to work with long-term memory
Let’s dive deeper into each one, starting with the requirements, and then presenting the Protocol endpoints that meet these requirements.
## Stateless Runs: one-shot interactions
[](#stateless-runs-one-shot-interactions)
In some cases, you may want to create a thread and run in one request, and have the thread be deleted after the run concludes. This is useful for ephemeral or stateless interactions, where you don’t need to keep track of the thread’s state.
* [`POST /runs/wait`](https://langchain-ai.github.io/agent-protocol/api.html#tag/runs/POST/runs/wait)- Create an ephemeral run, and wait for its final output, which is returned in the response.
* [`POST /runs/stream`](https://langchain-ai.github.io/agent-protocol/api.html#tag/runs/POST/runs/stream)- Create an ephemeral run, and stream output as produced.
## Threads: multi-turn interactions
[](#threads-multi-turn-interactions)
What APIs do you need to enable multi-turn interactions?
* Persistent state
* Get and update state
* Track history of past states of a thread, modelled as an append-only log of states
* Optimize storage by storing only diffs between states
* Concurrency controls
* Ensure that only one run per thread is active at a time
* Customizable handling of concurrent runs (interrupt, enqueue, interrupt or rollback)
* CRUD endpoints for threads
* List threads by user, or other metadata
* List threads by status (idle, interrupted, errored, finished)
* Copy or delete threads
Endpoints:
* [`POST /threads`](https://langchain-ai.github.io/agent-protocol/api.html#tag/threads/POST/threads)- Create a thread.
* [`POST /threads/search`](https://langchain-ai.github.io/agent-protocol/api.html#tag/threads/POST/threads/search)- Search threads.
* [`GET /threads/{thread\_id}`](https://langchain-ai.github.io/agent-protocol/api.html#tag/threads/GET/threads/{thread_id})- Get a thread.
* [`GET /threads/{thread\_id}/history`](https://langchain-ai.github.io/agent-protocol/api.html#tag/threads/GET/threads/{thread_id}/history)- Browse past revisions of a thread’s state. Revisions are created by runs, or through the PATCH endpoint below.
* [`POST /threads/{thread\_id}/copy`](https://langchain-ai.github.io/agent-protocol/api.html#tag/threads/POST/threads/{thread_id}/copy)- Create an independent copy of a thread.
* [`DELETE /threads/{thread\_id}`](https://langchain-ai.github.io/agent-protocol/api.html#tag/threads/DELETE/threads/{thread_id})- Delete a thread.
* [`PATCH /threads/{thread\_id}`](https://langchain-ai.github.io/agent-protocol/api.html#tag/threads/PATCH/threads/{thread_id})- Update a thread's values or metadata. Updating values creates a new revision in the thread's history.
## Agents: Introspection
[](#agents-introspection)
Before you make use of an agent, it's sometimes useful to know what it can do, what inputs it accepts, what it returns, etc. This is where the introspection endpoints come in.
Endpoints:
* [`POST /agents/search`](https://langchain-ai.github.io/agent-protocol/api.html#tag/agents/POST/agents/search)- List all agents, optionally filtered by metadata or name.
* [`GET /agents/{agent\_id}`](https://langchain-ai.github.io/agent-protocol/api.html#tag/agents/GET/agents/{agent_id})- Get basic information about an agent, including its name, description, metadata.
* [`GET /agents/{agent\_id}/schemas`](https://langchain-ai.github.io/agent-protocol/api.html#tag/agents/GET/agents/{agent_id}/schemas)- Get the input, output, state and config schemas for an agent. All schemas are represented in JSON Schema format.
## Background Runs: Atomic agent executions
[](#background-runs-atomic-agent-executions)
What do we need out of an API to execute an agent?
* Support the two paradigms for launching a run
* Fire and forget, ie. launch a run in the background, but don’t wait for it to finish
* Waiting on a reply (blocking or polling), ie. launch a run and wait/stream its output
* Support CRUD for agent executions
* List and get runs
* Cancel and delete runs
* Flexible ways to consume output
* Get the final state
* Multiple types of streaming output, eg. token-by-token, intermediate steps, etc.
* Able to reconnect to output stream if disconnected
* Handling edge cases
* Failures should be handled gracefully, and retried if desired
* Bursty traffic should be queued up
Base Endpoints:
* [`GET /threads/{thread\_id}/runs`](https://langchain-ai.github.io/agent-protocol/api.html#tag/background-runs/GET/threads/{thread_id}/runs)- List runs for a thread.
* [`POST /runs`](https://langchain-ai.github.io/agent-protocol/api.html#tag/background-runs/POST/runs)- Create a background run.
* [`GET /runs/{run\_id}`](https://langchain-ai.github.io/agent-protocol/api.html#tag/background-runs/GET/runs/{run_id})- Get a run and its status.
* [`POST /runs/{run\_id}/cancel`](https://langchain-ai.github.io/agent-protocol/api.html#tag/background-runs/POST/runs/{run_id}/cancel)- Cancel a run. If the run hasn’t started, cancel it immediately, if it’s currently running then cancel it as soon as possible.
* [`DELETE /runs/{run\_id}`](https://langchain-ai.github.io/agent-protocol/api.html#tag/background-runs/DELETE/runs/{run_id})- Delete a finished run. A pending run needs to be cancelled first, see previous endpoint.
* [`GET /runs/{run\_id}/wait`](https://langchain-ai.github.io/agent-protocol/api.html#tag/background-runs/GET/runs/{run_id}/wait)- Wait for a run to finish, return the final output. If the run already finished, returns its final output immediately.
* [`GET /runs/{run\_id}/stream`](https://langchain-ai.github.io/agent-protocol/api.html#tag/background-runs/GET/runs/{run_id}/stream)- Join the output stream of an existing run. Only output produced after this endpoint is called will be streamed.
## Store: Long-term memory
[](#store-long-term-memory)
What do you need out of a memory API for agents?
* Customizable memory scopes
* Storing memory against the user, thread, assistant, company, etc
* Accessing memory from different scopes in the same run
* Flexible storage
* Support simple text memories, as well as structured data
* CRUD operations for memories (create, read, update, delete)
* Search and retrieval
* Get a single memory by namespace and key
* List memories filtered by namespace, contents, sorted by time, etc
Endpoints:
* [`PUT /store/items`](https://langchain-ai.github.io/agent-protocol/api.html#tag/store/PUT/store/items)- Create or update a memory item, at a given namespace and key.
* [`DELETE /store/items`](https://langchain-ai.github.io/agent-protocol/api.html#tag/store/DELETE/store/items)- Delete a memory item, at a given namespace and key.
* [`GET /store/items`](https://langchain-ai.github.io/agent-protocol/api.html#tag/store/GET/store/items)- Get a memory item, at a given namespace and key.
* [`POST /store/items/search`](https://langchain-ai.github.io/agent-protocol/api.html#tag/store/POST/store/items/search)- Search memory items.
* [`POST /store/namespaces`](https://langchain-ai.github.io/agent-protocol/api.html#tag/store/POST/store/namespaces)- List namespaces.
## Messages
[](#messages)
Messages have emerged as a core primitive in dealing with LLMs, and as such we have first-class support for messages in Agent Protocol. This is in addition to completely customizable input/output schemas for agents. We define a Message spec, which is a subset of the message formats supported by major LLM providers, such as OpenAI and Anthropic. In all endpoints that expose thread values, there is also a separate`messages`field, which agents can optionally implement.
## Agent Protocol in Action
[](#agent-protocol-in-action)
Below are a few illustrative “user journeys” in[Hurl](https://hurl.dev)format, each showing a common sequence of API calls against your Agent Protocol service (listening at localhost:8000, no auth required).
They’re organized so that you can paste each journey into its own .hurl file (or combine them), then run them with the “hurl” command. This should give you a good sense of how the protocol can be used in practice.
### Journey 1: Create Thread →Get Thread →Create Run →Wait for Output
[](#journey-1-create-thread--get-thread--create-run--wait-for-output)
This journey demonstrates the typical sequence of creating a thread, launching a run, and waiting for the final output. You can then repeat the two last steps to launch more runs in the same thread. This is the most common pattern for multi-turn interactions, such as a chatbot conversation.
```
`# 1. Create a brand new thread
POST http://localhost:8000/threads
Content-Type: application/json
{
"thread\_id": "229c1834-bc04-4d90-8fd6-77f6b9ef1462",
"metadata": {
"purpose": "support-chat"
}
}
HTTP/1.1 200
[Asserts]
jsonpath "$.thread\_id" == "229c1834-bc04-4d90-8fd6-77f6b9ef1462"
# 2. Retrieve the thread we just created
GET http://localhost:8000/threads/229c1834-bc04-4d90-8fd6-77f6b9ef1462
HTTP/1.1 200
[Asserts]
jsonpath "$.status" == "idle"
# 3. Create a run in the existing thread (background run).
# Capture the run\_id for the next step.
POST http://localhost:8000/threads/229c1834-bc04-4d90-8fd6-77f6b9ef1462/runs
Content-Type: application/json
{
"input": {
"message": "Hi there, what's the weather?"
},
"metadata": {
"requestType": "weatherQuery"
}
}
HTTP/1.1 200
[Captures]
run\_id: jsonpath "$.run\_id"
[Asserts]
jsonpath "$.status" == "pending"
# 4. Wait for final run output
GET http://localhost:8000/threads/229c1834-bc04-4d90-8fd6-77f6b9ef1462/runs/{{run\_id}}/wait
HTTP/1.1 200
[Asserts]
# For example, check that the run status is success or error,
# depending on your actual system's response:
jsonpath "$.status" == "success"`
```
You can replace the last step with`GET /threads/{thread\_id}/runs/{run\_id}/stream`to stream the output as it’s produced, or with`GET /threads/{thread\_id}`to poll status/output without waiting.
### Journey 2: Ephemeral “Stateless” Run (Create + Wait)
[](#journey-2-ephemeral-stateless-run-create--wait)
This journey demonstrates a one-shot run, where you create a thread and run in one request, and wait for the final output. This is useful for stateless interactions, where you want to start fresh each time. Good use cases include extraction or research agents.
```
`# Launch a one-shot run with a brand new ephemeral thread,
# and wait for the final output right away.
POST http://localhost:8000/runs/wait
Content-Type: application/json
{
"input": {
"prompt": "What's the fastest route to the airport?"
},
"metadata": {
"useCase": "travelPlan"
},
"config": {
"tags": ["ephemeral", "demo"]
}
}
HTTP/1.1 200`
```
### Journey 3: Using the Store (Add, Retrieve, and Delete an Item)
[](#journey-3-using-the-store-add-retrieve-and-delete-an-item)
This journey demonstrates how to use the Store API to add, retrieve, and delete an item. This is useful for storing long-term memory, such as user profiles, preferences, or other structured data, which can be accessed both inside and outside the agent.
```
`# 1. Put (store or update) an item in the store
PUT http://localhost:8000/store/items
Content-Type: application/json
{
"namespace": ["user\_profiles"],
"key": "profile\_jane\_doe",
"value": {
"displayName": "Jane Doe",
"role": "customer"
}
}
HTTP/1.1 204
# 2. Retrieve it by namespace/key
GET http://localhost:8000/store/items?key=profile\_jane\_doe&amp;&amp;namespace=user\_profiles
HTTP/1.1 200
[Asserts]
jsonpath "$.value.displayName" == "Jane Doe"
jsonpath "$.value.role" == "customer"
# 3. Delete the item
DELETE http://localhost:8000/store/items
Content-Type: application/json
{
"namespace": ["user\_profiles"],
"key": "profile\_jane\_doe"
}
HTTP/1.1 204`
```
## Roadmap
[](#roadmap)
* Add detailed specification for each stream mode (currently this is left open to the implementer)
* Add Store endpoint to perform a vector search over memory entries
* Add param for`POST /threads/{thread\_id}/runs/{run\_id}/stream`to replay events since`event-id`before streaming new events
* Add param to`POST /threads/{thread\_id}/runs`to optionally allow concurrent runs on the same thread (current spec makes this forbidden)
* (Open an issue and let us know what else should be here!)
## About
[langchain-ai.github.io/agent-protocol/api.html](https://langchain-ai.github.io/agent-protocol/api.html)
### Resources
[Readme](#readme-ov-file)
### License
[MIT license](#MIT-1-ov-file)
### Code of conduct
[Code of conduct](#coc-ov-file)
### Contributing
[Contributing](#contributing-ov-file)
### Security policy
[Security policy](#security-ov-file)
### Uh oh!
There was an error while loading.[Please reload this page]().
[Activity](https://github.com/langchain-ai/agent-protocol/activity)
[Custom properties](https://github.com/langchain-ai/agent-protocol/custom-properties)
### Stars
[**499**stars](https://github.com/langchain-ai/agent-protocol/stargazers)
### Watchers
[**11**watching](https://github.com/langchain-ai/agent-protocol/watchers)
### Forks
[**37**forks](https://github.com/langchain-ai/agent-protocol/forks)
[Report repository](https://github.com/contact/report-content?content_url=https://github.com/langchain-ai/agent-protocol&amp;report=langchain-ai+(user))
## [Releases8](https://github.com/langchain-ai/agent-protocol/releases)
[
0.2.0Latest
Apr 14, 2025
](https://github.com/langchain-ai/agent-protocol/releases/tag/0.2.0)
[+ 7 releases](https://github.com/langchain-ai/agent-protocol/releases)
## [Packages0](https://github.com/orgs/langchain-ai/packages?repo_name=agent-protocol)
No packages published
### Uh oh!
There was an error while loading.[Please reload this page]().
## [Contributors7](https://github.com/langchain-ai/agent-protocol/graphs/contributors)
* [![@nfcampos](https://avatars.githubusercontent.com/u/56902?s=64&amp;v=4)](https://github.com/nfcampos)
* [![@beryder](https://avatars.githubusercontent.com/u/142427115?s=64&amp;v=4)](https://github.com/beryder)
* [![@dqbd](https://avatars.githubusercontent.com/u/1443449?s=64&amp;v=4)](https://github.com/dqbd)
* [![@hinthornw](https://avatars.githubusercontent.com/u/13333726?s=64&amp;v=4)](https://github.com/hinthornw)
* [![@ccurme](https://avatars.githubusercontent.com/u/26529506?s=64&amp;v=4)](https://github.com/ccurme)
* [![@MadaraUchiha-314](https://avatars.githubusercontent.com/u/6977429?s=64&amp;v=4)](https://github.com/MadaraUchiha-314)
* [![@adilhafeez](https://avatars.githubusercontent.com/u/13196462?s=64&amp;v=4)](https://github.com/adilhafeez)
## Languages
* [Python99.2%](https://github.com/langchain-ai/agent-protocol/search?l=python)
* Other0.8%
You can’t perform that action at this time.
