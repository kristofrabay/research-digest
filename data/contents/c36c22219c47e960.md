# Tools - OpenAI Agents SDK

**URL:** https://openai.github.io/openai-agents-python/tools/
**Published:** 2011-06-09T00:00:00.000Z

---

## Summary

The provided text is documentation for **Tools in the OpenAI Agents SDK**. It details how agents can take actions using three classes of tools:

1.  **Hosted tools:** Built-in tools running on LLM servers, such as `WebSearchTool`, `FileSearchTool`, `ComputerTool`, `CodeInterpreterTool`, `ImageGenerationTool`, and the `HostedMCPTool` (which exposes a remote MCP server's tools).
2.  **Function calling:** Allows using any Python function as a tool, with automatic schema and docstring parsing.
3.  **Agents as tools:** Enables agents to call other agents, facilitating agent orchestration.

The documentation also covers:
*   Returning images or files from function tools.
*   Creating custom function tools directly without using a Python function decorator.
*   Automatic parsing of function arguments and docstrings using `inspect`, `griffe`, and `pydantic`.
*   Customizing agent tools with configuration like `custom_output_extractor` and handling streaming results.
*   Conditionally enabling/disabling tools at runtime using the `is_enabled` parameter, which can accept booleans or callable functions that check context.
*   Handling errors during function tool invocation using a `failure_error_function`.

Regarding your specific query terms:

*   **agent\_infrastructure:** The document describes the tooling aspect of agent infrastructure within the OpenAI SDK.
*   **MCP servers:** Mentioned via the `HostedMCPTool`.
*   **tool use:** This is the central topic of the document.
*   **agent memory, agentic memory:** Not explicitly discussed.
*   **agent frameworks, LangChain, LlamaIndex, OpenAI Agents SDK, Anthropic Agents SDK, Google SDK:** The document focuses specifically on the **OpenAI Agents SDK**. Other frameworks are not mentioned.
*   **function calling:** Covered extensively.
*   **structured outputs:** Implied through Pydantic/schema creation for function arguments, and the ability to return specific types like images/files from tools.
*   **agent orchestration:** Covered under "Agents as tools," where one agent can call others.

**Summary relevant to the query:**

The OpenAI Agents SDK supports **tool use** through three mechanisms: **hosted tools** (including the **HostedMCPTool** for remote **MCP servers**), **function calling** (which supports **structured outputs

---

## Full Content

Tools - OpenAI Agents SDK
[Skip to content](#tools)
# Tools
Tools let agents take actions: things like fetching data, running code, calling external APIs, and even using a computer. There are three classes of tools in the Agent SDK:
* Hosted tools: these run on LLM servers alongside the AI models. OpenAI offers retrieval, web search and computer use as hosted tools.
* Function calling: these allow you to use any Python function as a tool.
* Agents as tools: this allows you to use an agent as a tool, allowing Agents to call other agents without handing off to them.## Hosted tools
OpenAI offers a few built-in tools when using the[`OpenAIResponsesModel`](../ref/models/openai_responses/#agents.models.openai_responses.OpenAIResponsesModel):
* The[`WebSearchTool`](../ref/tool/#agents.tool.WebSearchTool)lets an agent search the web.
* The[`FileSearchTool`](../ref/tool/#agents.tool.FileSearchTool)allows retrieving information from your OpenAI Vector Stores.
* The[`ComputerTool`](../ref/tool/#agents.tool.ComputerTool)allows automating computer use tasks.
* The[`CodeInterpreterTool`](../ref/tool/#agents.tool.CodeInterpreterTool)lets the LLM execute code in a sandboxed environment.
* The[`HostedMCPTool`](../ref/tool/#agents.tool.HostedMCPTool)exposes a remote MCP server's tools to the model.
* The[`ImageGenerationTool`](../ref/tool/#agents.tool.ImageGenerationTool)generates images from a prompt.
* The[`LocalShellTool`](../ref/tool/#agents.tool.LocalShellTool)runs shell commands on your machine.
```
`[](#__codelineno-0-1)fromagentsimportAgent,FileSearchTool,Runner,WebSearchTool[](#__codelineno-0-2)[](#__codelineno-0-3)agent=Agent([](#__codelineno-0-4)name=&quot;Assistant&quot;,[](#__codelineno-0-5)tools=[[](#__codelineno-0-6)WebSearchTool(),[](#__codelineno-0-7)FileSearchTool([](#__codelineno-0-8)max\_num\_results=3,[](#__codelineno-0-9)vector\_store\_ids=[&quot;&quot;VECTOR\_STORE\_ID&quot;&quot;],[](#__codelineno-0-10)),[](#__codelineno-0-11)],[](#__codelineno-0-12))[](#__codelineno-0-13)[](#__codelineno-0-14)asyncdefmain():[](#__codelineno-0-15)result=awaitRunner.run(agent,&quot;Which coffee shop should I go to, taking into account my preferences and the weather today in SF?&quot;)[](#__codelineno-0-16)print(result.final\_output)`
```
## Function tools
You can use any Python function as a tool. The Agents SDK will setup the tool automatically:
* The name of the tool will be the name of the Python function (or you can provide a name)
* Tool description will be taken from the docstring of the function (or you can provide a description)
* The schema for the function inputs is automatically created from the function's arguments
* Descriptions for each input are taken from the docstring of the function, unless disabled
We use Python's`inspect`module to extract the function signature, along with[`griffe`](https://mkdocstrings.github.io/griffe/)to parse docstrings and`pydantic`for schema creation.
```
`[](#__codelineno-1-1)importjson[](#__codelineno-1-2)[](#__codelineno-1-3)fromtyping\_extensionsimportTypedDict,Any[](#__codelineno-1-4)[](#__codelineno-1-5)fromagentsimportAgent,FunctionTool,RunContextWrapper,function\_tool[](#__codelineno-1-6)[](#__codelineno-1-7)[](#__codelineno-1-8)classLocation(TypedDict):[](#__codelineno-1-9)lat:float[](#__codelineno-1-10)long:float[](#__codelineno-1-11)[](#__codelineno-1-12)@function\_tool# (1)![](#__codelineno-1-13)asyncdeffetch\_weather(location:Location)-&gt;str:[](#__codelineno-1-14)# (2)![](#__codelineno-1-15)&quot;&quot;&quot;Fetch the weather for a given location.[](#__codelineno-1-16)[](#__codelineno-1-17)Args:[](#__codelineno-1-18)location: The location to fetch the weather for.[](#__codelineno-1-19)&quot;&quot;&quot;[](#__codelineno-1-20)# In real life, we&#39;d fetch the weather from a weather API[](#__codelineno-1-21)return&quot;sunny&quot;[](#__codelineno-1-22)[](#__codelineno-1-23)[](#__codelineno-1-24)@function\_tool(name\_override=&quot;&quot;fetch\_data&quot;&quot;)# (3)![](#__codelineno-1-25)defread\_file(ctx:RunContextWrapper[Any],path:str,directory:str|None=None)-&gt;str:[](#__codelineno-1-26)&quot;&quot;&quot;Read the contents of a file.[](#__codelineno-1-27)[](#__codelineno-1-28)Args:[](#__codelineno-1-29)path: The path to the file to read.[](#__codelineno-1-30)directory: The directory to read the file from.[](#__codelineno-1-31)&quot;&quot;&quot;[](#__codelineno-1-32)# In real life, we&#39;d read the file from the file system[](#__codelineno-1-33)return&quot;&lt;file contents&gt;&quot;[](#__codelineno-1-34)[](#__codelineno-1-35)[](#__codelineno-1-36)agent=Agent([](#__codelineno-1-37)name=&quot;Assistant&quot;,[](#__codelineno-1-38)tools=[fetch\_weather,read\_file],# (4)![](#__codelineno-1-39))[](#__codelineno-1-40)[](#__codelineno-1-41)fortoolinagent.tools:[](#__codelineno-1-42)ifisinstance(tool,FunctionTool):[](#__codelineno-1-43)print(tool.name)[](#__codelineno-1-44)print(tool.description)[](#__codelineno-1-45)print(json.dumps(tool.params\_json\_schema,indent=2))[](#__codelineno-1-46)print()`
```
1. You can use any Python types as arguments to your functions, and the function can be sync or async.
2. Docstrings, if present, are used to capture descriptions and argument descriptions
3. Functions can optionally take the`context`(must be the first argument). You can also set overrides, like the name of the tool, description, which docstring style to use, etc.
4. You can pass the decorated functions to the list of tools.Expand to see output
```
`[](#__codelineno-2-1)fetch\_weather[](#__codelineno-2-2)Fetch the weather for a given location.[](#__codelineno-2-3){[](#__codelineno-2-4)&quot;$defs&quot;: {[](#__codelineno-2-5)&quot;Location&quot;: {[](#__codelineno-2-6)&quot;properties&quot;: {[](#__codelineno-2-7)&quot;lat&quot;: {[](#__codelineno-2-8)&quot;title&quot;: &quot;Lat&quot;,[](#__codelineno-2-9)&quot;type&quot;: &quot;number&quot;[](#__codelineno-2-10)},[](#__codelineno-2-11)&quot;long&quot;: {[](#__codelineno-2-12)&quot;title&quot;: &quot;Long&quot;,[](#__codelineno-2-13)&quot;type&quot;: &quot;number&quot;[](#__codelineno-2-14)}[](#__codelineno-2-15)},[](#__codelineno-2-16)&quot;required&quot;: [[](#__codelineno-2-17)&quot;lat&quot;,[](#__codelineno-2-18)&quot;long&quot;[](#__codelineno-2-19)],[](#__codelineno-2-20)&quot;title&quot;: &quot;Location&quot;,[](#__codelineno-2-21)&quot;type&quot;: &quot;object&quot;[](#__codelineno-2-22)}[](#__codelineno-2-23)},[](#__codelineno-2-24)&quot;properties&quot;: {[](#__codelineno-2-25)&quot;location&quot;: {[](#__codelineno-2-26)&quot;$ref&quot;: &quot;#/$defs/Location&quot;,[](#__codelineno-2-27)&quot;description&quot;: &quot;The location to fetch the weather for.&quot;[](#__codelineno-2-28)}[](#__codelineno-2-29)},[](#__codelineno-2-30)&quot;required&quot;: [[](#__codelineno-2-31)&quot;location&quot;[](#__codelineno-2-32)],[](#__codelineno-2-33)&quot;&quot;title&quot;&quot;: &quot;&quot;fetch\_weather\_args&quot;&quot;,[](#__codelineno-2-34)&quot;type&quot;: &quot;object&quot;[](#__codelineno-2-35)}[](#__codelineno-2-36)[](#__codelineno-2-37)fetch\_data[](#__codelineno-2-38)Read the contents of a file.[](#__codelineno-2-39){[](#__codelineno-2-40)&quot;properties&quot;: {[](#__codelineno-2-41)&quot;path&quot;: {[](#__codelineno-2-42)&quot;description&quot;: &quot;The path to the file to read.&quot;,[](#__codelineno-2-43)&quot;title&quot;: &quot;Path&quot;,[](#__codelineno-2-44)&quot;type&quot;: &quot;string&quot;[](#__codelineno-2-45)},[](#__codelineno-2-46)&quot;directory&quot;: {[](#__codelineno-2-47)&quot;anyOf&quot;: [[](#__codelineno-2-48){[](#__codelineno-2-49)&quot;type&quot;: &quot;string&quot;[](#__codelineno-2-50)},[](#__codelineno-2-51){[](#__codelineno-2-52)&quot;type&quot;: &quot;null&quot;[](#__codelineno-2-53)}[](#__codelineno-2-54)],[](#__codelineno-2-55)&quot;default&quot;: null,[](#__codelineno-2-56)&quot;description&quot;: &quot;The directory to read the file from.&quot;,[](#__codelineno-2-57)&quot;title&quot;: &quot;Directory&quot;[](#__codelineno-2-58)}[](#__codelineno-2-59)},[](#__codelineno-2-60)&quot;required&quot;: [[](#__codelineno-2-61)&quot;path&quot;[](#__codelineno-2-62)],[](#__codelineno-2-63)&quot;&quot;title&quot;&quot;: &quot;&quot;fetch\_data\_args&quot;&quot;,[](#__codelineno-2-64)&quot;type&quot;: &quot;object&quot;[](#__codelineno-2-65)}`
```
### Returning images or files from function tools
In addition to returning text outputs, you can return one or many images or files as the output of a function tool. To do so, you can return any of:
* Images:[`ToolOutputImage`](../ref/tool/#agents.tool.ToolOutputImage)(or the TypedDict version,[`ToolOutputImageDict`](../ref/tool/#agents.tool.ToolOutputImageDict))
* Files:[`ToolOutputFileContent`](../ref/tool/#agents.tool.ToolOutputFileContent)(or the TypedDict version,[`ToolOutputFileContentDict`](../ref/tool/#agents.tool.ToolOutputFileContentDict))
* Text: either a string or stringable objects, or[`ToolOutputText`](../ref/tool/#agents.tool.ToolOutputText)(or the TypedDict version,[`ToolOutputTextDict`](../ref/tool/#agents.tool.ToolOutputTextDict))### Custom function tools
Sometimes, you don't want to use a Python function as a tool. You can directly create a[`FunctionTool`](../ref/tool/#agents.tool.FunctionTool)if you prefer. You'll need to provide:
* `name`
* `description`
* `params\_json\_schema`, which is the JSON schema for the arguments
* `on\_invoke\_tool`, which is an async function that receives a[`ToolContext`](../ref/tool_context/#agents.tool_context.ToolContext)and the arguments as a JSON string, and must return the tool output as a string.
```
`[](#__codelineno-3-1)fromtypingimportAny[](#__codelineno-3-2)[](#__codelineno-3-3)frompydanticimportBaseModel[](#__codelineno-3-4)[](#__codelineno-3-5)fromagentsimportRunContextWrapper,FunctionTool[](#__codelineno-3-6)[](#__codelineno-3-7)[](#__codelineno-3-8)[](#__codelineno-3-9)defdo\_some\_work(data:str)-&gt;str:[](#__codelineno-3-10)return&quot;done&quot;[](#__codelineno-3-11)[](#__codelineno-3-12)[](#__codelineno-3-13)classFunctionArgs(BaseModel):[](#__codelineno-3-14)username:str[](#__codelineno-3-15)age:int[](#__codelineno-3-16)[](#__codelineno-3-17)[](#__codelineno-3-18)asyncdefrun\_function(ctx:RunContextWrapper[Any],args:str)-&gt;str:[](#__codelineno-3-19)parsed=FunctionArgs.model\_validate\_json(args)[](#__codelineno-3-20)returndo\_some\_work(data=f&quot;{parsed.username}is{parsed.age}years old&quot;)[](#__codelineno-3-21)[](#__codelineno-3-22)[](#__codelineno-3-23)tool=FunctionTool([](#__codelineno-3-24)name=&quot;&quot;process\_user&quot;&quot;,[](#__codelineno-3-25)description=&quot;Processes extracted user data&quot;,[](#__codelineno-3-26)params\_json\_schema=FunctionArgs.model\_json\_schema(),[](#__codelineno-3-27)on\_invoke\_tool=run\_function,[](#__codelineno-3-28))`
```
### Automatic argument and docstring parsing
As mentioned before, we automatically parse the function signature to extract the schema for the tool, and we parse the docstring to extract descriptions for the tool and for individual arguments. Some notes on that:
1. The signature parsing is done via the`inspect`module. We use type annotations to understand the types for the arguments, and dynamically build a Pydantic model to represent the overall schema. It supports most types, including Python primitives, Pydantic models, TypedDicts, and more.
2. We use`griffe`to parse docstrings. Supported docstring formats are`google`,`sphinx`and`numpy`. We attempt to automatically detect the docstring format, but this is best-effort and you can explicitly set it when calling`function\_tool`. You can also disable docstring parsing by setting`use\_docstring\_info`to`False`.
The code for the schema extraction lives in[`agents.function\_schema`](../ref/function_schema/#agents.function_schema).
## Agents as tools
In some workflows, you may want a central agent to orchestrate a network of specialized agents, instead of handing off control. You can do this by modeling agents as tools.
```
`[](#__codelineno-4-1)fromagentsimportAgent,Runner[](#__codelineno-4-2)importasyncio[](#__codelineno-4-3)[](#__codelineno-4-4)spanish\_agent=Agent([](#__codelineno-4-5)name=&quot;Spanish agent&quot;,[](#__codelineno-4-6)instructions=&quot;You translate the user&#39;s message to Spanish&quot;,[](#__codelineno-4-7))[](#__codelineno-4-8)[](#__codelineno-4-9)french\_agent=Agent([](#__codelineno-4-10)name=&quot;French agent&quot;,[](#__codelineno-4-11)instructions=&quot;You translate the user&#39;s message to French&quot;,[](#__codelineno-4-12))[](#__codelineno-4-13)[](#__codelineno-4-14)orchestrator\_agent=Agent([](#__codelineno-4-15)name=&quot;&quot;orchestrator\_agent&quot;&quot;,[](#__codelineno-4-16)instructions=([](#__codelineno-4-17)&quot;You are a translation agent. You use the tools given to you to translate.&quot;[](#__codelineno-4-18)&quot;If asked for multiple translations, you call the relevant tools.&quot;[](#__codelineno-4-19)),[](#__codelineno-4-20)tools=[[](#__codelineno-4-21)spanish\_agent.as\_tool([](#__codelineno-4-22)tool\_name=&quot;&quot;translate\_to\_spanish&quot;&quot;,[](#__codelineno-4-23)tool\_description=&quot;Translate the user&#39;s message to Spanish&quot;,[](#__codelineno-4-24)),[](#__codelineno-4-25)french\_agent.as\_tool([](#__codelineno-4-26)tool\_name=&quot;&quot;translate\_to\_french&quot;&quot;,[](#__codelineno-4-27)tool\_description=&quot;Translate the user&#39;s message to French&quot;,[](#__codelineno-4-28)),[](#__codelineno-4-29)],[](#__codelineno-4-30))[](#__codelineno-4-31)[](#__codelineno-4-32)asyncdefmain():[](#__codelineno-4-33)result=awaitRunner.run(orchestrator\_agent,input=&quot;Say &#39;Hello, how are you?&#39; in Spanish.&quot;)[](#__codelineno-4-34)print(result.final\_output)`
```
### Customizing tool-agents
The`agent.as\_tool`function is a convenience method to make it easy to turn an agent into a tool. It doesn't support all configuration though; for example, you can't set`max\_turns`. For advanced use cases, use`Runner.run`directly in your tool implementation:
```
`[](#__codelineno-5-1)@function\_tool[](#__codelineno-5-2)asyncdefrun\_my\_agent()-&gt;str:[](#__codelineno-5-3)&quot;&quot;&quot;A tool that runs the agent with custom configs&quot;&quot;&quot;[](#__codelineno-5-4)[](#__codelineno-5-5)agent=Agent(name=&quot;My agent&quot;,instructions=&quot;...&quot;)[](#__codelineno-5-6)[](#__codelineno-5-7)result=awaitRunner.run([](#__codelineno-5-8)agent,[](#__codelineno-5-9)input=&quot;...&quot;,[](#__codelineno-5-10)max\_turns=5,[](#__codelineno-5-11)run\_config=...[](#__codelineno-5-12))[](#__codelineno-5-13)[](#__codelineno-5-14)returnstr(result.final\_output)`
```
### Custom output extraction
In certain cases, you might want to modify the output of the tool-agents before returning it to the central agent. This may be useful if you want to:
* Extract a specific piece of information (e.g., a JSON payload) from the sub-agent's chat history.
* Convert or reformat the agent’s final answer (e.g., transform Markdown into plain text or CSV).
* Validate the output or provide a fallback value when the agent’s response is missing or malformed.
You can do this by supplying the`custom\_output\_extractor`argument to the`as\_tool`method:
```
`[](#__codelineno-6-1)asyncdefextract\_json\_payload(run\_result:RunResult)-&gt;str:[](#__codelineno-6-2)# Scan the agent’s outputs in reverse order until we find a JSON-like message from a tool call.[](#__codelineno-6-3)foriteminreversed(run\_result.new\_items):[](#__codelineno-6-4)ifisinstance(item,ToolCallOutputItem)anditem.output.strip().startswith(&quot;{&quot;):[](#__codelineno-6-5)returnitem.output.strip()[](#__codelineno-6-6)# Fallback to an empty JSON object if nothing was found[](#__codelineno-6-7)return&quot;{}&quot;[](#__codelineno-6-8)[](#__codelineno-6-9)[](#__codelineno-6-10)json\_tool=data\_agent.as\_tool([](#__codelineno-6-11)tool\_name=&quot;&quot;get\_data\_json&quot;&quot;,[](#__codelineno-6-12)tool\_description=&quot;Run the data agent and return only its JSON payload&quot;,[](#__codelineno-6-13)custom\_output\_extractor=extract\_json\_payload,[](#__codelineno-6-14))`
```
### Streaming nested agent runs
Pass an`on\_stream`callback to`as\_tool`to listen to streaming events emitted by the nested agent while still returning its final output once the stream completes.
```
`[](#__codelineno-7-1)fromagentsimportAgentToolStreamEvent[](#__codelineno-7-2)[](#__codelineno-7-3)[](#__codelineno-7-4)asyncdefhandle\_stream(event:AgentToolStreamEvent)-&gt;None:[](#__codelineno-7-5)# Inspect the underlying StreamEvent along with agent metadata.[](#__codelineno-7-6)print(f&quot;[stream]{event[&#39;agent&#39;][&#39;name&#39;]}::{event[&#39;event&#39;].type}&quot;)[](#__codelineno-7-7)[](#__codelineno-7-8)[](#__codelineno-7-9)billing\_agent\_tool=billing\_agent.as\_tool([](#__codelineno-7-10)tool\_name=&quot;&quot;billing\_helper&quot;&quot;,[](#__codelineno-7-11)tool\_description=&quot;Answer billing questions.&quot;,[](#__codelineno-7-12)on\_stream=handle\_stream,# Can be sync or async.[](#__codelineno-7-13))`
```
What to expect:
* Event types mirror`StreamEvent["type"]`:`raw\_response\_event`,`run\_item\_stream\_event`,`agent\_updated\_stream\_event`.
* Providing`on\_stream`automatically runs the nested agent in streaming mode and drains the stream before returning the final output.
* The handler may be synchronous or asynchronous; each event is delivered in order as it arrives.
* `tool\_call\_id`is present when the tool is invoked via a model tool call; direct calls may leave it`None`.
* See`examples/agent\_patterns/agents\_as\_tools\_streaming.py`for a complete runnable sample.### Conditional tool enabling
You can conditionally enable or disable agent tools at runtime using the`is\_enabled`parameter. This allows you to dynamically filter which tools are available to the LLM based on context, user preferences, or runtime conditions.
```
`[](#__codelineno-8-1)importasyncio[](#__codelineno-8-2)fromagentsimportAgent,AgentBase,Runner,RunContextWrapper[](#__codelineno-8-3)frompydanticimportBaseModel[](#__codelineno-8-4)[](#__codelineno-8-5)classLanguageContext(BaseModel):[](#__codelineno-8-6)language\_preference:str=&quot;&quot;french\_spanish&quot;&quot;[](#__codelineno-8-7)[](#__codelineno-8-8)deffrench\_enabled(ctx:RunContextWrapper[LanguageContext],agent:AgentBase)-&gt;bool:[](#__codelineno-8-9)&quot;&quot;&quot;Enable French for French+Spanish preference.&quot;&quot;&quot;[](#__codelineno-8-10)returnctx.context.language\_preference==&quot;&quot;french\_spanish&quot;&quot;[](#__codelineno-8-11)[](#__codelineno-8-12)# Create specialized agents[](#__codelineno-8-13)spanish\_agent=Agent([](#__codelineno-8-14)name=&quot;&quot;spanish\_agent&quot;&quot;,[](#__codelineno-8-15)instructions=&quot;You respond in Spanish. Always reply to the user&#39;s question in Spanish.&quot;,[](#__codelineno-8-16))[](#__codelineno-8-17)[](#__codelineno-8-18)french\_agent=Agent([](#__codelineno-8-19)name=&quot;&quot;french\_agent&quot;&quot;,[](#__codelineno-8-20)instructions=&quot;You respond in French. Always reply to the user&#39;s question in French.&quot;,[](#__codelineno-8-21))[](#__codelineno-8-22)[](#__codelineno-8-23)# Create orchestrator with conditional tools[](#__codelineno-8-24)orchestrator=Agent([](#__codelineno-8-25)name=&quot;orchestrator&quot;,[](#__codelineno-8-26)instructions=([](#__codelineno-8-27)&quot;You are a multilingual assistant. You use the tools given to you to respond to users. &quot;[](#__codelineno-8-28)&quot;You must call ALL available tools to provide responses in different languages. &quot;[](#__codelineno-8-29)&quot;You never respond in languages yourself, you always use the provided tools.&quot;[](#__codelineno-8-30)),[](#__codelineno-8-31)tools=[[](#__codelineno-8-32)spanish\_agent.as\_tool([](#__codelineno-8-33)tool\_name=&quot;&quot;respond\_spanish&quot;&quot;,[](#__codelineno-8-34)tool\_description=&quot;Respond to the user&#39;s question in Spanish&quot;,[](#__codelineno-8-35)is\_enabled=True,# Always enabled[](#__codelineno-8-36)),[](#__codelineno-8-37)french\_agent.as\_tool([](#__codelineno-8-38)tool\_name=&quot;&quot;respond\_french&quot;&quot;,[](#__codelineno-8-39)tool\_description=&quot;Respond to the user&#39;s question in French&quot;,[](#__codelineno-8-40)is\_enabled=french\_enabled,[](#__codelineno-8-41)),[](#__codelineno-8-42)],[](#__codelineno-8-43))[](#__codelineno-8-44)[](#__codelineno-8-45)asyncdefmain():[](#__codelineno-8-46)context=RunContextWrapper(LanguageContext(language\_preference=&quot;&quot;french\_spanish&quot;&quot;))[](#__codelineno-8-47)result=awaitRunner.run(orchestrator,&quot;How are you?&quot;,context=context.context)[](#__codelineno-8-48)print(result.final\_output)[](#__codelineno-8-49)[](#__codelineno-8-50)asyncio.run(main())`
```
The`is\_enabled`parameter accepts:
* **Boolean values**:`True`(always enabled) or`False`(always disabled)
* **Callable functions**: Functions that take`(context, agent)`and return a boolean
* **Async functions**: Async functions for complex conditional logic
Disabled tools are completely hidden from the LLM at runtime, making this useful for:
* Feature gating based on user permissions
* Environment-specific tool availability (dev vs prod)
* A/B testing different tool configurations
* Dynamic tool filtering based on runtime state## Handling errors in function tools
When you create a function tool via`@function\_tool`, you can pass a`failure\_error\_function`. This is a function that provides an error response to the LLM in case the tool call crashes.
* By default (i.e. if you don't pass anything), it runs a`default\_tool\_error\_function`which tells the LLM an error occurred.
* If you pass your own error function, it runs that instead, and sends the response to the LLM.
* If you explicitly pass`None`, then any tool call errors will be re-raised for you to handle. This could be a`ModelBehaviorError`if the model produced invalid JSON, or a`UserError`if your code crashed, etc.
```
`[](#__codelineno-9-1)fromagentsimportfunction\_tool,RunContextWrapper[](#__codelineno-9-2)fromtypingimportAny[](#__codelineno-9-3)[](#__codelineno-9-4)defmy\_custom\_error\_function(context:RunContextWrapper[Any],error:Exception)-&gt;str:[](#__codelineno-9-5)&quot;&quot;&quot;A custom function to provide a user-friendly error message.&quot;&quot;&quot;[](#__codelineno-9-6)print(f&quot;A tool call failed with the following error:{error}&quot;)[](#__codelineno-9-7)return&quot;An internal server error occurred. Please try again later.&quot;[](#__codelineno-9-8)[](#__codelineno-9-9)@function\_tool(failure\_error\_function=my\_custom\_error\_function)[](#__codelineno-9-10)defget\_user\_profile(user\_id:str)-&gt;str:[](#__codelineno-9-11)&quot;&quot;&quot;Fetches a user profile from a mock API.[](#__codelineno-9-12)This function demonstrates a &#39;flaky&#39; or failing API call.[](#__codelineno-9-13)&quot;&quot;&quot;[](#__codelineno-9-14)ifuser\_id==&quot;&quot;user\_123&quot;&quot;:[](#__codelineno-9-15)return&quot;&quot;User profile for user\_123 successfully retrieved.&quot;&quot;[](#__codelineno-9-16)else:[](#__codelineno-9-17)raiseValueError(f&quot;&quot;Could not retrieve profile for user\_id:{user\_id}. API returned an error.&quot;)`
```
If you are manually creating a`FunctionTool`object, then you must handle errors inside the`on\_invoke\_tool`function.
