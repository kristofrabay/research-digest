# 

**URL:** https://medium.com/@scholarly360/gpt4-vision-for-form-and-table-understanding-b24ceb3c948b
**Published:** 2023-11-13T07:40:22.000Z

---

## Summary

The webpage discusses using **GPT-4 Vision (GPT-4V)** for **form and table understanding**. It explains that GPT-4V incorporates visual capabilities, allowing it to process images and documents, unlike previous text-only models. The text provides Python code examples demonstrating how to use the OpenAI API with `gpt-4-vision-preview` to extract information from images of forms and tables. Key learnings indicate that GPT-4V works well for form understanding, but sometimes struggles with JSON responses, and its performance for table extraction via the API was noted as "pretty bad" compared to using the GPT-4 User Interface.

---

## Full Content

[Sitemap](https://medium.com/sitemap/sitemap.xml)

[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fb24ceb3c948b&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)

Sign up

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40scholarly360%2Fgpt4-vision-for-form-and-table-understanding-b24ceb3c948b&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)

[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)

[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)

Sign up

[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40scholarly360%2Fgpt4-vision-for-form-and-table-understanding-b24ceb3c948b&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)

# GPT4 Vision for Form and Table Understanding

[Yogendra Sisodia](https://medium.com/@scholarly360?source=post_page---byline--b24ceb3c948b---------------------------------------)

3 min read

·

Nov 13, 2023

--

Listen

Share

Press enter or click to view image in full size

GPT4V for Form and Table Understanding

**Introduction**

The GPT-4 model, also known as GPT-4V or gpt-4-vision-preview, incorporates visual capabilities, enabling it to process documents and images and provide responses to queries related to them. In the past, language model systems have only been able to process text as an input type. The limitations imposed by these factors restricted the use of models such as GPT-4 to specific scenarios.

Developers who have access to GPT-4 can now use the gpt-4-vision-preview model to get to the GPT-4 model, which has visual features. Additionally, the Chat Completions API has been enhanced to accommodate image inputs. It should be noted that the current version of the Assistants API does not include support for picture inputs.

```
OpenAI Guide:https://platform.openai.com/docs/guides/vision
```

**Early Experiments**

I used two images, one for form understanding and one for table extraction, and tried several prompts to get the answer, especially in JSON format. Currently, GPT-4 with vision does not support the message.name parameter, functions or tools, or the response\_format parameter.

Press enter or click to view image in full size

Form Understanding and Table Extraction Samples

```
import osOPENAI_API_TOKEN = "sk-YOUR_KEY"# OpenAI API Keyapi_key = os.environ["OPENAI_API_KEY"] = OPENAI_API_TOKENimport base64import requests# Function to encode the imagedef encode_image(image_path): with open(image_path, "rb") as image_file: return base64.b64encode(image_file.read()).decode('utf-8')def form_and_table_understanding(image_path, prompt_text): """ form_and_table_understanding """ base64_image = encode_image(image_path) # Path to your image headers = {"Content-Type": "application/json","Authorization": f"Bearer {api_key}"} payload = { "model": "gpt-4-vision-preview", #"response_format" : { "type": "json_object" }, "messages": [ { "role": "user", "content": [ { "type": "text", "text": prompt_text }, { "type": "image_url", "image_url": { "url": f"data:image/jpeg;base64,{base64_image}" } } ] } ], "max_tokens": 300 } response = requests.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload) return(response.json())
```

```
# Prompt 1 Formimage_path = "imgs/Vision_Form.png"prompt_text = "what is date start and date end "resp = form_and_table_understanding(image_path, prompt_text)print(resp)# Prompt 2 Formimage_path = "imgs/Vision_Form.png"prompt_text = "what is date start and date end and give output as json with exact values and dont add anything extra "resp = form_and_table_understanding(image_path, prompt_text)print(resp)# Prompt 3 Formimage_path = "imgs/Vision_Form.png"prompt_text = "find all relevant information in terms of key value pairs "resp = form_and_table_understanding(image_path, prompt_text)print(resp)
```

```
# Prompt 1 Tableimage_path = "imgs/Vision_Table.png"prompt_text = "find out all tables"resp = form_and_table_understanding(image_path, prompt_text)print(resp)# Prompt 2 Tableimage_path = "imgs/Vision_Table.png"prompt_text = "find out all tables and give output as json with exact values and dont add anything extra "resp = form_and_table_understanding(image_path, prompt_text)print(resp)
```

**Key Learnings**

For form understanding, GPT-4V works perfectly, but sometimes with JSON responses, it has some troubles. But for extracting tables, it had pretty bad behavior with the completion API. On the GPT4 User Interface, the same table image works better than using the API.

**Resources**

Colab Link : [https://colab.research.google.com/drive/1iKHuCuF5lgIX\_78T9nLMg6XNEneIrZfQ?usp=drive\_link](https://colab.research.google.com/drive/1iKHuCuF5lgIX_78T9nLMg6XNEneIrZfQ?usp=drive_link)

YouTube Link:

[Large Language Models](https://medium.com/tag/large-language-models?source=post_page-----b24ceb3c948b---------------------------------------)

[Gpt 4](https://medium.com/tag/gpt-4?source=post_page-----b24ceb3c948b---------------------------------------)

[Document Ai](https://medium.com/tag/document-ai?source=post_page-----b24ceb3c948b---------------------------------------)

[Chatgpt4](https://medium.com/tag/chatgpt4?source=post_page-----b24ceb3c948b---------------------------------------)

[Table Extraction](https://medium.com/tag/table-extraction?source=post_page-----b24ceb3c948b---------------------------------------)

[**Written by Yogendra Sisodia**](https://medium.com/@scholarly360?source=post_page---post_author_info--b24ceb3c948b---------------------------------------)

[310 followers](https://medium.com/@scholarly360/followers?source=post_page---post_author_info--b24ceb3c948b---------------------------------------)

· [34 following](https://medium.com/@scholarly360/following?source=post_page---post_author_info--b24ceb3c948b---------------------------------------)

AI Leader. Sales-Tech, Mar-Tech and Legal-Tech Specialist.

## No responses yet

[Help](https://help.medium.com/hc/en-us?source=post_page-----b24ceb3c948b---------------------------------------)

[Status](https://medium.statuspage.io/?source=post_page-----b24ceb3c948b---------------------------------------)

[About](https://medium.com/about?autoplay=1&source=post_page-----b24ceb3c948b---------------------------------------)

[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----b24ceb3c948b---------------------------------------)

[Press](mailto:pressinquiries@medium.com)

[Blog](https://blog.medium.com/?source=post_page-----b24ceb3c948b---------------------------------------)

[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----b24ceb3c948b---------------------------------------)

[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----b24ceb3c948b---------------------------------------)

[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----b24ceb3c948b---------------------------------------)

[Text to speech](https://speechify.com/medium?source=post_page-----b24ceb3c948b---------------------------------------)
