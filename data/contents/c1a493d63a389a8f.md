# Build an Enterprise RAG Pipeline Blueprint

**URL:** https://build.nvidia.com/nvidia/build-an-enterprise-rag-pipeline
**Published:** None

---

## Summary

The NVIDIA AI Blueprint for Retrieval-Augmented Generation (RAG) supports **multimodal data ingestion**, including **multimodal PDF data extraction** for text, tables, charts, and infographics. It also features **Optional Vision Language Model (VLM) Support in answer generation** and **Opt-in image captioning with vision language models (VLMs)**.

While the blueprint explicitly mentions support for extracting data from **tables** and **charts** as part of its multimodal data ingestion capabilities, and uses models like **PaddleOCR** for potential text extraction from images/documents, it **does not explicitly mention** specific models like GPT-4V, Claude vision, or Gemini, nor does it detail a specific process for **report generation with LLMs** or **structured document output** beyond the extraction of elements like tables and charts.

---

## Full Content

Build an Enterprise RAG Pipeline Blueprint Blueprint by NVIDIA | NVIDIA NIM
[![NVIDIA](https://build.nvidia.com/_next/image?url=%2Fnvidia-logo.png&amp;w=600&amp;q=75)](https://build.nvidia.com/)
⌘KCtrl+K
**
?
Login
![](https://build.nvidia.com/_next/image?url=https%3A%2F%2Fassets.ngc.nvidia.com%2Fproducts%2Fapi-catalog%2Fimages%2Fbuild-an-enterprise-rag-pipeline.jpg&amp;w=3840&amp;q=75)
## [nvidia](https://build.nvidia.com/nvidia)
# Build an Enterprise RAG Pipeline Blueprint
Power fast, accurate semantic search across multimodal enterprise data with NVIDIA’s RAG Blueprint—built on NeMo Retriever and Nemotron models—to connect your agents to trusted, authoritative sources of knowledge.
[llama-3\_3-nemotron-super-49b-v1\_5](https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5)•[llama-3\_2-nv-embedqa-1b-v2](https://build.nvidia.com/nvidia/llama-3_2-nv-embedqa-1b-v2)•[llama-3\_2-nv-rerankqa-1b-v2](https://build.nvidia.com/nvidia/llama-3_2-nv-rerankqa-1b-v2)•[nemoretriever-page-elements-v2](https://build.nvidia.com/nvidia/nemoretriever-page-elements-v2)•[nemoretriever-table-structure-v1](https://build.nvidia.com/nvidia/nemoretriever-table-structure-v1)•[nemoretriever-graphic-elements-v1](https://build.nvidia.com/nvidia/nemoretriever-graphic-elements-v1)•[paddleocr](https://build.nvidia.com/baidu/paddleocr)
[Blueprint](https://build.nvidia.com/search?q=Blueprint)[NIM](https://build.nvidia.com/search?q=NIM)[NeMo Retriever](https://build.nvidia.com/search?q=NeMo+Retriever)[Nemotron](https://build.nvidia.com/search?q=Nemotron)[Retrieval-Augmented Generation](https://build.nvidia.com/search?q=Retrieval-Augmented+Generation)[Enterprise](https://build.nvidia.com/search?q=Enterprise)[Launchable](https://build.nvidia.com/search?q=Launchable)[NVIDIA AI](https://build.nvidia.com/search?q=NVIDIA+AI)
[View GitHub](https://github.com/NVIDIA-AI-Blueprints/rag)[Deploy on Cloud](https://brev.nvidia.com/launchable/deploy/now?launchableID=env-2zbpu97JjyY3VxlSITsLgiHOoEK)
Blueprint CardNIM
Overview
The NVIDIA AI Blueprint for Retrieval-Augmented Generation (RAG) is a production-ready reference workflow that provides a complete foundation for building scalable, customizable pipelines for both retrieval and generation. Powered by NVIDIA NeMo Retriever models and NVIDIA Llama Nemotron models, the blueprint is optimized for high accuracy, strong reasoning, and enterprise-scale throughput.
With built-in support for multimodal data ingestion, advanced retrieval, reranking, and reflection techniques, and seamless integration into LLM-powered workflows, it connects language models to enterprise data across text, tables, charts, audio, and infographics from millions of documents—enabling truly context-aware and generative responses.
Beyond retrieval and generation, the blueprint includes governance, observability, and safety features to meet enterprise requirements, along with developer-friendly APIs, telemetry, and evaluation frameworks for streamlined experimentation and deployment. GPU acceleration ensures unmatched performance at scale, while flexible plug-ins and customizability let teams adapt the solution to their unique use cases.
Whether you’re building enterprise search, knowledge assistants, generative copilots, or vertical AI workflows, the NVIDIA AI Blueprint for RAG delivers everything needed to move from prototype to production with confidence. It can be used standalone, combined with other NVIDIA Blueprints or integrated into an agentic workflow to support more advanced reasoning-driven applications.For example, this blueprint serves as a foundational building block in the[AI Agent for Enterprise Research](https://build.nvidia.com/nvidia/aiq)
Get started with this reference architecture to ground AI-driven decisions and generation in relevant enterprise data.
## Architecture Diagram
[![](https://assets.ngc.nvidia.com/products/api-catalog/build-an-enterprise-rag-pipeline/diagram.jpg)](https://assets.ngc.nvidia.com/products/api-catalog/build-an-enterprise-rag-pipeline/diagram.jpg)
## Key Features
* Data Ingestion and Processing
* Multimodal PDF data extraction support with text, tables, charts and infographics
* Support for audio file ingestion
* Custom metadata support
* Document summarization
* Vector Database and Retrieval
* Multi-collection searchability
* Hybrid search with dense and sparse search
* Reranking to further improve accuracy
* GPU-accelerated Index creation and search
* Pluggable vector database
* ElasticSearch Support as a Vector Database
* Milvus Support as a Vector Database
* Query Decomposition
* Dynamic metadata filter generation
* Multimodal and Advanced Generation
* Optional Vision Language Model (VLM) Support in answer generation
* Opt-in image captioning with vision language models (VLMs)
* Multi-turn conversations
* Multi-session support
* Improve accuracy with optional reflection
* Governance
* Improve content safety with optional programmable guardrails
* Observability and Telemetry
* Evaluation Scripts included (RAGAS framework)
* OpenTelemetry Support
* Other
* User interface included
* NIM Operator support to allow GPU sharing using DRA
* Native Python library support
* OpenAI-compatible APIs
* Decomposable and customizable## Minimum System Requirements
**Hardware Requirements**
The blueprint offers two primary modes of deployment. By default, it deploys the referenced NIM microservices locally. Each method lists its minimum required hardware. This will change if the deployment turns on optional configuration settings.
* Docker
* 2xRTXPro6000
* 2xH100
* 3xB200
* 3xA100
* Kubernetes
* 8xRTX PRO 6000
* 8xH100-80GB
* 9xB200
* 9xA100-80GB SXM
* 4xH100 (with Multi-Instance GPU / DRA with NIM Operator)
* The blueprint allows for use of NVIDIA NGC-hosted models, in which case one GPU will be required to host the[NVIDIA cuVS](https://developer.nvidia.com/cuvs)-accelerated vector database.
**OS Requirements**
* Ubuntu 22.04 OS
**Deployment Options**
* Docker
* Kubernetes## Software used in this blueprint
**NVIDIA Technology**
* [Llama Nemotron Super 49B](https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5)
* [NeMo Retriever Llama 3.2 embedding NIM](https://build.nvidia.com/nvidia/llama-3_2-nv-embedqa-1b-v2)
* [NeMo Retriever Llama 3.2 reranking NIM](https://build.nvidia.com/nvidia/llama-3_2-nv-rerankqa-1b-v2)
* [NeMo Retriever page elements NIM](https://build.nvidia.com/nvidia/nemoretriever-page-elements-v2)
* [NeMo Retriever table structure NIM](https://build.nvidia.com/nvidia/nemoretriever-table-structure-v1)
* [NeMo Retriever graphic elements NIM](https://build.nvidia.com/nvidia/nemoretriever-graphic-elements-v1)
* [PaddleOCR NIM](https://build.nvidia.com/baidu/paddleocr)
* [Nemotron parse NIM](https://build.nvidia.com/nvidia/nemoretriever-parse)*(optional)*
* [Llama 3.1 NemoGuard 8B Content safety NIM](https://build.nvidia.com/nvidia/llama-3_1-nemoguard-8b-content-safety)*(optional)*
* [Llama 3.1 NemoGuard 8B Topic control NIM](https://build.nvidia.com/nvidia/llama-3_1-nemoguard-8b-topic-control)*(optional)*
* [NVIDIA Riva ASR NIM](https://build.nvidia.com/nvidia/parakeet-ctc-1_1b-asr)*(optional)*
* [Llama Nemotron nano vl 8b](https://build.nvidia.com/nvidia/llama-3.1-nemotron-nano-vl-8b-v1)*(optional)*
* [Nemo Retriever OCR NIM](https://build.nvidia.com/nvidia/nemoretriever-ocr-v1)*(optional)*
* [NeMo Retriever Llama 3.2 vlm embedding NIM](https://build.nvidia.com/nvidia/llama-3_2-nemoretriever-1b-vlm-embed-v1)*(optional)*
**3rd Party Software**
* [LangChain](https://www.langchain.com/)
* Milvus database (accelerated with[NVIDIA**cuVS**](https://github.com/rapidsai/cuvs))
* ElasticSearch Vector Database
* Minio
* Redis Cache## Ethical Considerations
NVIDIA believes Trustworthy AI is a shared responsibility, and we have established policies and practices to enable development for a wide array of AI applications. When downloaded or used in accordance with our terms of service, developers should work with their supporting model team to ensure the models meet requirements for the relevant industry and use case and address unforeseen product misuse. Please report security vulnerabilities or NVIDIA AI concerns[here](https://www.nvidia.com/en-us/support/submit-security-vulnerability/).
## License
Use of the models in this blueprint is governed by the[NVIDIA AI Foundation Models Community License](https://docs.nvidia.com/ai-foundation-models-community-license.pdf).
## Terms of Use
This blueprint is governed by the[NVIDIA Agreements | Enterprise Software | NVIDIA Software License Agreement](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/)and the[NVIDIA Agreements | Enterprise Software | Product Specific Terms for AI Product](https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/). The models are governed by the[NVIDIA Agreements | Enterprise Software | NVIDIA Community Model License](https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/)and the[NVIDIA RAG dataset](https://github.com/NVIDIA-AI-Blueprints/rag/tree/main/data/multimodal)which is governed by the[NVIDIA Asset License Agreement](https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/data/LICENSE.DATA).
The following models that are built with Llama are governed by the[Llama 3.2 Community License Agreement](https://www.llama.com/llama3_2/license/): nvidia/llama-3.2-nv-embedqa-1b-v2 and nvidia/llama-3.2-nv-rerankqa-1b-v2 and llama-3.2-nemoretriever-1b-vlm-embed-v1.
**ADDITIONAL INFORMATION**:
The[Llama 3.1 Community License Agreement](https://www.llama.com/llama3_1/license/)for the llama-3.1-nemotron-nano-vl-8b-v1, llama-3.1-nemoguard-8b-content-safety and llama-3.1-nemoguard-8b-topic-control models. The[Llama 3.2 Community License Agreement](https://www.llama.com/llama3_2/license/)for the nvidia/llama-3.2-nv-embedqa-1b-v2, nvidia/llama-3.2-nv-rerankqa-1b-v2 and llama-3.2-nemoretriever-1b-vlm-embed-v1 models. The[Llama 3.3 Community License Agreement](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/LICENSE)for the llama-3.3-nemotron-super-49b-v1.5 model. Built with Llama. Apache 2.0 for NVIDIA Ingest and for the nemoretriever-page-elements-v2, nemoretriever-table-structure-v1, nemoretriever-graphic-elements-v1, paddleocr and nemoretriever-ocr-v1 models.
