# Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning

**arXiv:** https://arxiv.org/abs/2512.10573v1

## Abstract

Summary: The Information Bottleneck (IB) principle facilitates effective representation learning by preserving label-relevant information while compressing irrelevant information. However, its strong reliance on accurate labels makes it inherently vulnerable to label noise, prevalent in real-world scenarios, resulting in significant performance degradation and overfitting. To address this issue, we propose LaT-IB, a novel Label-Noise ResistanT Information Bottleneck method which introduces a "Minimal-Sufficient-Clean" (MSC) criterion. Instantiated as a mutual information regularizer to retain task-relevant information while discarding noise, MSC addresses standard IB's vulnerability to noisy label supervision. To achieve this, LaT-IB employs a noise-aware latent disentanglement that decomposes the latent representation into components aligned with to the clean label space and the noise space. Theoretically, we first derive mutual information bounds for each component of our objective including prediction, compression, and disentanglement, and moreover prove that optimizing it encourages representations invariant to input noise and separates clean and noisy label information. Furthermore, we design a three-phase training framework: Warmup, Knowledge Injection and Robust Training, to progressively guide the model toward noise-resistant representations. Extensive experiments demonstrate that LaT-IB achieves superior robustness and efficiency under label noise, significantly enhancing robustness and applicability in real-world scenarios with label noise.

## Full Text

Is the Information Bottleneck Robust Enough?
Towards Label-Noise Resistant Information Bottleneck Learning
Yi Huang1, Qingyun Sun1*, Yisen Gao2, Haonan Yuan1, Xingcheng Fu3, Jianxin Li1
1SKLCCSE, School of Computer Science and Engineering, Beihang University, Beijing, China
2Department of Computer Science and Engineering, HKUST, Hong Kong, China
3Key Lab of Education Blockchain and Intelligent Technology, Ministry of Education, Guangxi Normal University, China
{yihuang, sunqy, yuanhn, lijx}@buaa.edu.cn, ygaodi@cse.ust.hk, fuxc@gxnu.edu.cn
Abstract
The Information Bottleneck (IB) principle facilitates effective
representation learning by preserving label-relevant informa-
tion while compressing irrelevant information. However, its
strong reliance on accurate labels makes it inherently vulner-
able to label noise, prevalent in real-world scenarios, result-
ing in significant performance degradation and overfitting. To
address this issue, we propose LaT-IB, a novel Label-Noise
ResistanT Information Bottleneck method which introduces a
â€œMinimal-Sufficient-Cleanâ€ (MSC) criterion. Instantiated as
a mutual information regularizer to retain task-relevant infor-
mation while discarding noise, MSC addresses standard IBâ€™s
vulnerability to noisy label supervision. To achieve this, LaT-
IB employs a noise-aware latent disentanglement that decom-
poses the latent representation into components aligned with
to the clean label space and the noise space. Theoretically, we
first derive mutual information bounds for each component
of our objective including prediction, compression, and dis-
entanglement, and moreover prove that optimizing it encour-
ages representations invariant to input noise and separates
clean and noisy label information. Furthermore, we design
a three-phase training framework: Warmup, Knowledge In-
jection and Robust Training, to progressively guide the model
toward noise-resistant representations. Extensive experiments
demonstrate that LaT-IB achieves superior robustness and ef-
ficiency under label noise, significantly enhancing robustness
and applicability in real-world scenarios with label noise.
1
Introduction
The Information Bottleneck (IB) principle (Tishby, Pereira,
and Bialek 2000) provides a fundamental theoretical frame-
work for balancing compression and relevance in represen-
tation learning. Rooted in information theory, it has increas-
ingly influenced the development of deep learning (Hu et al.
2024). IB encourages representations Z that retain only task-
relevant information while discarding irrelevant or redun-
dant input features using Mutual Information (MI) I(Â·; Â·):
min âˆ’I(Y ; Z) + Î²I(X; Z).
(1)
IB-based methods aim to extract â€œMinimal-Sufficientâ€ rep-
resentations, inherently filtering out input noise and spurious
correlations. This selective encoding mechanism contributes
*Corresponding Author
Copyright Â© 2026, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
CIFAR10
40% asym noise
50% sym noise
ResNet34
77.78%
79.4%
VIB (Î² = 0.01)
73.80%
10.0%
Cora (40% noise)
Epoch: 0 â†’20
Epoch: 20 â†’100
GIB
22.9% â†’69.5%
69.5% â†’55.1%
steady increase â†‘
steady decline â†“
Table 1: Performance of IB methods under noise conditions.
to their notable robustness under noisy or adversarial input
perturbations (Shamir, Sabato, and Tishby 2010).
However, input noise rarely eliminates all useful informa-
tion, allowing IB to extract meaningful features from Y . In
contrast, label noise corrupts the supervisory signal, caus-
ing I(Y ; Z) to mislead Z to fit incorrect labels, thereby re-
ducing robustness. This vulnerability is critical in real-world
settings, where label noise is common and can severely harm
performance, as real graphs are often disturbed by noise and
unexpected factors. (Li et al. 2025). To address this, Label-
Noise Representation Learning (LNRL) (Song et al. 2022)
aims to extract robust features despite label corruption.
To empirically test the hypothesis that IB is inherently
vulnerable to label noise, we conduct preliminary experi-
ments on two tasks: image classification in computer vision
and node classification in graph learning. We evaluate two
representative IB-based methods: VIB (Alemi et al. 2017)
and GIB (Wu et al. 2020). As shown in Table 1, VIB suffers
performance drops and even training collapse, while GIB
exhibits degraded accuracy. See Appendix E.3 for details.
To mitigate this, a simple remedy is to denoise the labels
prior to applying IB. However, this two-stage pipeline is in-
herently suboptimal in both theory and practice.
Theorem 1.1 (Cumulative Degradation). In the two-stage
approach, f1 is used to modify the labels Y â€² = f1(D),
and f2 is responsible for extracting valid information from
D while approximating the prediction result to f1(D) . For
one-stage model g(D), it extracts the relevant information
while removing noise. If the denoising abilities of f1 and g
are the same, the following inequality holds:
P(f2(D) Ì¸= g(D)) â‰¥H(Y â€²|D) âˆ’1
log(|Y| âˆ’1) ,
(2)
arXiv:2512.10573v1  [cs.LG]  11 Dec 2025
Noise Misleading Information.
MSC Information.
Minimal-Sufficient-Clean
Noisy Information. ïŒ
ğ‘Œ
ğ’Ÿ
Clean Information. â˜º
IB =       +       LaT-IB = 
Figure 1: Comparison between LaT-IB and IB Principle.
where Y denotes the support of Y , and |Y| denotes the num-
ber of elements in Y. The two models perform identically iff
f2 achieves the error lower bound and H(Y â€²|D) = 0.
The proof of Theorem 1.1 is given in Appendix C.1. It
demonstrates that cascading a denoising model f1 with an
IB learner f2 leads to cumulative information loss compared
with a unified model g, due to the extended information path.
This phenomenon is further validated by empirical results,
which show a clear degradation in the denoising effect when
models are cascaded. See Appendix E.3 for detailed results.
Core Issue: How can the IB principle be effectively ap-
plied to real-world scenarios with complex and unknown
label noise, in order to learn representations that are both
â€œMinimal-Sufficientâ€ and robust to noisy supervision?
Due to unknown label noise and the difficulty of integrat-
ing denoising with Information Bottleneck, applying IB in
practice requires confronting the following key challenges:
â€¢ How to formulate the IB objective under label noise to
learn clean representation. (â–·Section 4.1)
â€¢ How to optimize MI under label noise that distorts task-
relevant representation learning. (â–·Section 4.2)
â€¢ How to effectively disentangle clean and noisy represen-
tations without knowing noisy samples. (â–·Section 4.3)
Present work. To address the core issue and tackle
the key challenges, we propose a Label-Noise ResistanT
Information Bottleneck (LaT-IB) method. Centered on the
idea of disentangling representations into clean and noisy la-
bel spaces, we formulate an IB training objective tailored for
noisy supervision and theoretically justify its effectiveness
through upper and lower bound analysis. To this end, we
design a three-phase training framework: Warmup, Knowl-
edge Injection and Robust Training, which gradually guides
the model to learn â€œMinimal-Sufficient-Cleanâ€ (MSC) repre-
sentations. A comparison between LaT-IB and standard IB
principle is illustrated in Figure 1. Our contributions are:
â€¢ We identify the inherent vulnerability of IB to label noise
and prove that denoising before IB is suboptimal.
â€¢ We propose a LaT-IB method that introduces MSC crite-
rion of representations to enhance IBâ€™s robustness to la-
bel noise while maintaining its essential characteristics.
â€¢ We provide theoretical upper and lower bounds for LaT-
IB, showing how disentangling clean and noise features
enables robust representation learning. Based on this, we
design a principled model and training framework.
â€¢ Extensive experiments evaluate LaT-IBâ€™s robustness and
efficiency, outperforming baselines under label noise and
adversarial attacks across diverse tasks and domains.
2
Related Work
2.1
Information Bottleneck for Robustness
The IB (Tishby, Pereira, and Bialek 2000) framework in-
troduces a feature learning paradigm grounded in informa-
tion theory. Works such as VIB (Alemi et al. 2017) and
GIB (Wu et al. 2020) have advanced its practical use. Con-
sidering robustness, methods like DisenIB (Pan et al. 2021)
and DGIB (Yuan et al. 2024) show reasonable robustness to
input features, with studies (Xie et al. 2023; Pensia, Jog, and
Loh 2020) further improving resilience to input noise.
Considering the presence of label noise, RGIB (Zhou
et al. 2023) explores structural noise in GNNs to improve
link prediction robustness. However, comprehensive studies
on the vulnerability of IB to label noise still remain lacking.
2.2
Label-Noise Representation Learning
The LNRL aims to improve model robustness and repre-
sentation quality under noisy label conditions. Existing ap-
proaches for learning with noisy labels include sample selec-
tion (Patel and Sastry 2023; Wei et al. 2020), which filters
out likely noisy samples; robust loss functions (Zhang and
Sabuncu 2018; Wang et al. 2019), which modify loss terms
to reduce sensitivity to incorrect labels; noise-robust archi-
tectures (Liu et al. 2020), which use regularization to avoid
overfitting noise; and data augmentation, such as mixup-
based methods (Zhang et al. 2018; Harris et al. 2020), which
interpolates samples to improve generalization.
However, most methods ignore representation-level con-
straints, making it hard to learn task-relevant and noise-
invariant features under severe noise or distribution shifts.
3
Preliminary Analysis
Notation.
We primarily define the input data D. For vision
tasks, D = X, where X âˆˆRNÃ—CÃ—P Ã—Q denotes N sam-
ples with C channels and spatial size P Ã— Q (e.g., height Ã—
width). For graph learning tasks, D = G = (X, A), where
X âˆˆRNÃ—d denotes d-dimensional features for N nodes and
A âˆˆRNÃ—N represents the adjacency matrix. Each sample
Î¾i âˆˆD has a label yi âˆˆY , which may be corrupted by
noise during the labeling process. We denote Yc and Yn as
the clean and noisy counterparts of Y respectively.
Analysis of IB Theory with Label Noise.
In the tradi-
tional IB, I(X; Z) encourages minimal representations by
compressing the input, while I(Y ; Z) ensures sufficiency by
preserving task-relevant information. However, when the la-
bel Y is corrupted by noise, maximizing I(Y ; Z) is equiva-
lent to maximizing I(Yc, Yn; Z), which inadvertently causes
the learned representation Z to capture noise Yn, thus com-
promising robustness and degrading performance.
In this study, we aim to mitigate the negative impact
of label noise on model performance while preserving the
â€œMinimal-Sufficientâ€ property of the IB method. Ideally,
we consider a robust IB method MIB that, given a dataset
(D, Y ) where Y consists of both clean labels yi âˆˆYc and
noisy labels yj âˆˆYn, aims to satisfy the following objective:
min âˆ’I(Z; Yc) + Î²I(Z; D)
s.t. Z = MIB(D, Y ).
(3)
ğœ‡à¯Œ ğœà¯Œ
ğœ‡à¯ ğœà¯
à·œİ•à¯Œ
à·œİ•à¯
ğ‘Œğ‘
ğ‘Œ
Üµ
Ü¶
ğ·ğ½à¯Œ
ğ·ğ½à¯Œ: Reveal the 
difference in 
noise capacity
İİŠÜ¿İ‹İ€İİ
Üµ
İİŠÜ¿İ‹İ€İİ
Ü¶
Üµâˆ¼İáˆºİ|İ”áˆ»
â†’ğ‘áˆºğœ‡à¯Œ, ğœà¯Œáˆ»
Ü¶âˆ¼İáˆºİ|İ”áˆ»
â†’ğ‘áˆºğœ‡à¯, ğœà¯áˆ»
İ€İÜ¿İ‹İ€İİ
Training Path
Inference Path
áˆºğ““, ğ’€áˆ»
Clean Sample
ğ‘¦= ğ‘¦ğ‘
Noisy Sample
ğ‘¦= ğ‘¦ğ‘›
Label-Noise Resistant Information Bottleneck (LaT-IB)
Sufficient
Minimal
Clean
min ğ¼ğ‘Œ; Üµ, Ü¶+ ßšğ¼ğ’Ÿ; Üµ, Ü¶+ ß›ğ¼Üµ; Ü¶ğ‘Œ
s.t. max ğ¼ğ‘Œğ‘›; Üµ, ğ¼ğ‘Œğ‘; Ü¶
â‰¤ğ¾
ğ¾= max ğ¼Üµ; Ü¶, ğœ€
2
Üµ
Clean Label 
Space
Ü¶
Noisy Label 
Space
Preserve
Disentangle
Compress
Progressive Representation
Disentanglement
ğ‘ƒ
ğ‘Œ
ğ‘¦ğ‘
ğ‘¦ğ‘›
ğ‘ƒ
ğ‘Œ
ğ‘¦ğ‘
ğ‘¦ğ‘›
ğ‘ƒ
ğ‘Œ
ğ‘¦ğ‘
ğ‘¦ğ‘›
1. Warmup
3. Robust Training
ğ’Ÿ
Üµ
à·œğ‘¦à¯Œ
ğ‘Œ
2. Knowledge Injection
ğ’Ÿ
Üµ
à·œğ‘¦à¯Œğ‘Œâ€²
Ü¶
à·œğ‘¦à¯
InfoJS
Selector
ğ’Ÿ
Üµ
à·œğ‘¦à¯Œ
ğ‘Œ
Ü¶
à·œğ‘¦à¯
à·œğ‘¦
MSC
Representation
Data
Pipeline
Method
Period1,2
Period3
ğ‘Œ
ğ’Ÿ
Figure 2: Left: The overall LaT-IB model architecture with dual encoders for extracting features from clean (S) and noisy
(T) label spaces, and a shared decoder. Right: An illustration of the LaT-IB method, which disentangles representations to
extract â€œMinimal-Sufficient-Cleanâ€ features. Specifically, its pipeline consists of three period: Warmup, Knowledge Injection
and Robust Training, which transform Eq. (8) from a theoretical formulation into a practical training procedure.
Compared to the traditional IB objective, the goal of Eq. (3)
is to maximize the MI between the learned representation
and the clean labels Yc , rather than with all observed labels
Y . However, whether each label is clean or noisy is un-
known. In the next section, we introduce a concrete solution
to mitigate IBâ€™s vulnerability to label noise.
4
Methodology
In this paper, we propose Label-Noise Resistant Informa-
tion Bottleneck (LaT-IB), along with theoretical formula-
tion, model architecture and a tailored training framework,
as illustrated in Figure 2. We begin by presenting the formal
objective of LaT-IB and interpreting its theoretical implica-
tions. To enable efficient optimization, we derive upper and
lower bounds that simplify the objective, effectively bridg-
ing the gap between theory and practice. Finally, drawing on
key insights, we design a three-phase training framework:
Warmup, Knowledge Injection and Robust Training, clarify
the role of each phase and facilitate the progressive disen-
tanglement of clean and noise-related representations.
4.1
Label-Noise Resistant Information Bottleneck
In real-world datasets, each training sample may have either
a clean or a corrupted label, and sometimes both possibili-
ties coexist probabilistically. Using a unified representation
for all samples under such ambiguity can cause conflicting
features and hurt downstream tasks. To mitigate this, we dis-
entangle the representation into two parts: S under the clean
label space, and T under the noise space. Under this disen-
tanglement, the objective in Eq. (3) can be reformulated as:
min âˆ’I(S; Yc) + I(D; S, T).
(4)
Since only Y are available in the dataset, we implicitly as-
sociate it with the joint representation of S and T, where dis-
entanglement is encouraged by min I(S; T|Y ). A successful
disentanglement implies that S and T encode conditionally
independent given Y , capturing distinct semantics. With Î²
and Î³ as balancing factors, the LaT-IB is formulated as:
min âˆ’I(Y ; S, T)
|
{z
}
prediction term
+Î² I(D; S, T)
|
{z
}
compression term
+Î³
I(S; T|Y )
|
{z
}
disentanglement term
, (5)
However, Eq. (5) still cannot map S to clean features and
T to noise features. To address this and further explore its
representational meaning, we introduce two lemmas below.
Lemma 4.1 (Nuisance Invariance). Taking the part of D
that does not contribute to Y as Dn (Dn is independent of
Y ), and considering the Markov chain (Y, Dn) â†’D â†’
(S, T), the following inequality holds:
I(Dn; S, T) â‰¤âˆ’I(Y ; S, T) + I(D; S, T).
(6)
Lemma 4.2 (Feature Convergence). Assuming that Y can
potentially contain all information about Yc and Yn, the fol-
lowing inequality holds when max(I(Yn; S), I(Yc; T)) â‰¤
max(I(S; T), Îµ)/2 = K, Îµ > 0, Îµ âˆˆR is satisfied:
âˆ’I(Yc; S)âˆ’I(Yn; T)âˆ’Îµ â‰¤âˆ’I(Y ; S, T)+I(S; T|Y ). (7)
The detailed proofs of these lemmas can be found in
Appendix C.2. Lemma 4.1 demonstrates that optimizing
min âˆ’I(Y ; S, T)+I(D; S, T) in Eq. (5) (Î² = 1) essentially
reduces the modelâ€™s tendency to learn features irrelevant to
Y (denoted as Dn). Lemma 4.2 further indicates that, when
the MI terms I(Yn, S) and I(Yc, T) are sufficiently small,
optimizing min âˆ’I(Y ; S, T)+I(S, T|Y ) in Eq. (5) (Î³ = 1)
effectively strengthens the mapping relationships S â†’Yc
and T â†’Yn. Based on these insights, we can first ensure
the conditions in Lemma 4.2 then optimize the main objec-
tive in Eq. (5) as a form of progressive representation dis-
entanglement. This enables the model to separate clean and
noisy features while avoiding learning irrelevant noise Dn.
By combining Lemma 4.1 and Lemma 4.2, we obtain a
principled training objective that integrates sufficiency, com-
pression, and clean-noise disentanglement:
min âˆ’I(Y ; S, T)
|
{z
}
Sufficient
+Î² I(D; S, T)
|
{z
}
Minimal
+Î³ I(S; T|Y )
|
{z
}
Clean
s.t. max(I(Yn; S), I(Yc; T)) â‰¤K
|
{z
}
Clean
.
(8)
4.2
Bound Analysis and Implementation
Building on the formulation introduced in the previous sec-
tion, we now turn to the optimization of the proposed ob-
jective in Eq. (8). Since directly optimizing the multivariate
MI is intractable, we first simplify the original objective by
analyzing upper and lower bounds of MI, and then present
the implementation strategy for each term. All proposition
proofs are provided in the Appendix C.3.
Proposition 4.1 (The upper bound of âˆ’I(Y ; S, T)). Given
the label Y and the variable S, T that learns the charac-
teristics of the clean label space and the noisy label space
respectively, we have:
âˆ’I(Y ; S, T) â‰¤âˆ’max (I(Y ; S), I(Y ; T)) .
(9)
Intuitively, Eq. (9) encourages encoders to focus on learn-
ing its own knowledge, ensuring consistency in the learned
representation. Further, since MI terms are intractable, each
I(Y, Z) with Z âˆˆ{S, T} is lower-bounded by the cross-
entropy loss using a variational approximation qÎ¸(y|z):
I(Y ; Z) â‰¥Ep(y,z) (log(qÎ¸(y|z))) := âˆ’LCE(Z, Y ), (10)
Proposition 4.2 (The upper bound of I(D; S, T)). Let D, S,
T be random variables. Assume the probabilistic mapping
p(D, S, T) follows the Markov chain S â†”D â†”T. Then:
I(D; S, T) â‰¤I(D; S) + I(D; T).
(11)
The implementation of each term I(D; Â·) remains consis-
tent with that in VIB (Alemi et al. 2017) and GIB (Wu et al.
2020), achieved by minimizing the KL divergence between
the variational posterior q(Â·|D) and the prior p(Â·).
Proposition 4.3 (Reformulation of I(S, T|Y )). Given the
label Y and the variable S, T, minimizing I(S; T|Y ) is
equivalent to minimize I(S, Y ; T, Y ).
The Proposition 4.3 achieves the tractable transformation
of conditional MI theoretically. However, minimizing the
term I(S, Y ; T, Y ) = DKL

q(S, T, Y )||q(S, Y )q(T, Y )

is
intractable since both distributions involve mixtures with
many components. Therefore, we use the density-ratio
trick (Sugiyama, Suzuki, and Kanamori 2012) by introduc-
ing a discriminator d, that learns to distinguish between sam-
ples from the joint distribution q(s, t, y) and those from the
product of marginals q(s, y)q(t, y). In particular, we sam-
ple negative pairs ((s, y), (t, yâ€²)) from q(s, y)q(t, y), where
(s, y) and (t, yâ€²) are drawn independently, and positive pairs
((s, y), (t, y)) from the joint distribution q(s, t, y), where
both s and t correspond to the same sample. The discrimina-
tor d((s, y), (t, yâ€²)) is trained to output the probability that a
given pair comes from the joint distribution, and the objec-
tive is to minimize the MI by solving the following problem:
min
q
max
d
Eq(s,y)q(t,y) log d((s, y), (t, yâ€²))
+Eq(s,t,y) log(1 âˆ’d((s, y), (t, y))).
(12)
When the discriminator cannot distinguish between joint and
independent samples, the MI is effectively minimized.
Proposition 4.4 (Reformulation of the condition in Eq. (8):
max(I(Yn; S), I(Yc; T)) â‰¤K). Minimizing I(Yc; T) and
I(Yn; S) is equivalent to maximize I(Yn; T) and I(Yc; S).
Proposition 4.4 relaxes the condition in Eq. (8). Since the
original MI calculation is mismatched and thus intractable,
the relaxed formulation provides a tractable alternative that
can be optimized efficiently, as described in Eq. (10).
4.3
Principle to Practice: LaT-IB Framework
Based on the theoretical analysis above, this section intro-
duces the practical implementation of LaT-IB. To optimize
the objective in Eq. (8), we adopt a three-phase training
framework to progressively disentangle the representa-
tion. Specifically, we first introduce a Warmup period to
provide the model with initial discriminative ability. Build-
ing on this, a Knowledge Injection period enforces the con-
straint by applying InfoJS selector, guiding the learning of
encoderS/T via selected samples. Finally the Robust Train-
ing period focuses on optimizing the complete objective
with prior knowledge, refining the modelâ€™s robustness.
Feature-Decomposed Dual Encoder Architecture De-
sign.
Based on the Observation 4.1, we adopt the Jensen-
Shannon (JS) divergence as a metric to evaluate the noise
retention capacity of the two encoders.
Observation 4.1. With the decoder kept fixed, we train the
encoder using datasets that share the same input X but dif-
fer in the level of label noise in Y . As the noise gap between
the two datasets increases, the divergence between the re-
sulting encodings from the encoder also becomes larger.
Accordingly, Figure 2 illustrates the overall architecture
of the LaT-IB: the model is designed with a dual-encoder,
single-decoder framework, where the two encoders extract
features S and T, respectively. Each encoder maps the input
features to a high-dimensional Gaussian distribution, and the
embeddings are sampled using the reparameterization trick.
Phase 1: Warmup with Discriminative Learning under
Noise.
To address the problem of noise memorization dur-
ing training, we introduce a Warmup phase where the model
builds basic discriminative ability. Specifically, we pre-
train the clean encoder encoderS using the full dataset, pro-
viding a foundation for more effective separation of clean
and noisy samples in subsequent stages. The loss function
in Warmup period is defined based on prediction Ë†yS:
LW armup = LCE(decoder(S), Y ) = LCE(Ë†yS, y).
(13)
Noise-Aware Sample Selection.
Since the variables Yc
and Yn are unobservable, we approximate the constraint
max(I(Yn; S), I(Yc; T)) â‰¤K in Eq. (8) by selecting a par-
tial set of confident samples to act as proxies for clean and
noisy labels. Samples are then grouped into three categories
for training: Clean Set, Noise Set, and Uncertain Set.
Observation 4.2. For two different encoders, samples with
more consistent predictions after passing through the de-
coder tend to have smaller divergence between their em-
beddings. In contrast, samples with inconsistent predictions
correspond to larger embedding divergence.
Observation 4.2 suggests that the divergence between en-
coders can be used to identify clean samples. Moreover,
prior studies (Arpit et al. 2017; Song et al. 2019) have shown
that models tend to fit clean samples earlier. Based on these
insights, we designed the InfoJS selector as detailed in Al-
gorithm B.2, which identifies clean (noisy) samples as those
with MI between S and Y being in the top Î´% (bottom Î´%)
and JS divergence between S and T in the bottom Î´% (top
Î´%), respectively. Unselected samples are treated as the un-
certain set. Labels are assigned as follows: yâ€² = y for Clean
and Noise Sets, and yâ€² = g(Ë†yS)/g(Ë†yT ) for Uncertain Set
when training the encoderS/T , where g denotes either a de-
biasing function (Menon et al. 2020) or one-hot mapping.
However, the InfoJS selector performs selection based on
relative feature scores. To improve the quality of each set,
we further enrich the sample composition by incorporating
predicted confidence scores as an absolute criterion.
Phase 2: Knowledge Injection to Disentangle Represen-
tations.
Once the model has acquired basic discrimina-
tive ability, we proceed to optimize the objective in Eq. (8).
Given the condition and its reformulated form:
max(I(Yn; S), I(Yc; T)) â‰¤K
|
{z
}
The original constraint in Eq. (8)
â‡’max(I(Yn; T)), max(I(Yc; S))
|
{z
}
The reformulated constraint in Proposition 4.4
,
(14)
to satisfy the constraint, we introduce a Knowledge Injec-
tion phase to encourage the encoderS,T to learn disentangled
representations. Furthermore, to enforce difference in noise
representation between the two encoders, we incorporate the
JS divergence DJS based on Observation 4.1:
ï£±
ï£´
ï£²
ï£´
ï£³
LClean = LCE(Ë†yS, yâ€²) âˆ’DJS(s âˆ¥t),
LUncertain = LCE(Ë†yS, yâ€²) + LCE(Ë†yT , yâ€²) + DJS(s âˆ¥t),
LNoise = LCE(Ë†yT , yâ€²) âˆ’DJS(s âˆ¥t),
(15)
For Clean and Noise Sets, divergence is maximized to in-
crease encoder discrepancy; and for the Uncertain set, diver-
gence is minimized to guide T towards meaningful patterns.
It is worth noting that the Uncertain set is much smaller, thus
has limited influence on the encodersâ€™ training process.
Empirically, minimizing the I(D; S, T) helps to leading
to a more robust encoding space. To progressively disentan-
gle the representation and achieve a minimal representation,
we introduce a regularization term LMinimal that approxi-
mates the min I(D; S, T) term base on Proposition 4.2, and
incorporate it into the loss function during the Knowledge
Injection period to learn a compact representation:
LInjection = LClean + LUncertain + LNoise + LMinimal.
(16)
This facilitates a smoother transition to the third Robust
Training stage. The implementation details of LMinimal are
provided in the Appendix D.1.
Phase 3: Robust Training for Representation Consis-
tency.
The Warmup stage establishes initial discrimina-
tive ability, while Knowledge Injection realized constraint
to guide the model toward informative and reliable samples.
To further disentangle and enhance representation robust-
ness under label noise, this period focuses on optimizing the
full objective in Eq. (5): min âˆ’I(Y ; S, T) + I(D; S, T) +
I(S; T|Y ), aiming to learn noise consistent representations.
Section 4.2 has introduced the implementation of each ob-
jective term. Among them we propose LConCE to optimize
the term I(Y ; S, T) based Eq. (9) and (10):
LConCE â†
X
min(LCE(Ë†yS, y), LCE(Ë†yT , y)),
(17)
encouraging consistency between encoders and clean/noisy
labels. Detailed formulations are provided in Appendix B.1.
The loss function for the Robust Training period is:
LRobust = 1
|B|
B
X
i=1
[ LConCE(Ë†yS, Ë†yT , y)
|
{z
}
Eq. (17)
+Î² LMinimal
|
{z
}
Eq. (11)
âˆ’Î³ log d(si, yi; ti, yi)
|
{z
}
Proposition 4.3, Eq. (12)
],
(18)
where B denotes a training batch. In addition, we alternately
update the discriminator d based on Eq. (12), using a random
permutation Ï€ to approximate the marginal distribution:
Ld = 1
|B|
B
X
i=1
âˆ’log(1 âˆ’d(si, yi; tÏ€(i), yÏ€(i)))
âˆ’log d(si, yi; ti, yi).
(19)
5
Experiment
In this section, we conduct extensive experiments to evaluate
the robustness and efficiency of the LaT-IB under diverse
tasks and various types of noise, including real-world and
synthetic label noise, as well as adversarial perturbation. 1
5.1
Experimental Settings
Datasets.
We evaluate the proposed LaT-IB method on
multiple datasets. For image classification, we utilize the CI-
FARN (Wei et al. 2022), Animal-10N (Song, Kim, and Lee
2019) and CIFAR (Krizhevsky, Hinton et al. 2009) datasets.
For node classification tasks, we evaluate on Cora, Citeseer,
Pubmed (Sen et al. 2008), and DBLP (Pan et al. 2016). More
descriptions about datasets are provided in Appendix E.1.
Baselines.
We compare our LaT-IB with four categories,
16 baselines in two scenarios: â‘ Classic IB methods; â‘¡IB
with robust loss functions; â‘¢Improved IB variants; â‘£Two-
stage denoising + IB methods. They comprehensively eval-
uate our LaT-IBâ€™s performance from multiple perspectives.
Label Noise Settings.
To evaluate the robustness of LaT-
IB and baselines against label noise, we conduct exper-
iments in both image and graph classification tasks. For
image classification, we evaluate on both real-world noisy
datasets and synthetic settings with symmetric and asym-
metric label noise, simulated using custom transition matri-
ces as described in (Xiao et al. 2023). For node classifica-
tion, we follow the protocol in (Wang et al. 2024) to inject
uniform and pairwise label noise into graph labels.
1Code available at: https://github.com/RingBDStack/LaT-IB
Method
Model
CIFAR-10N
CIFAR-100N
Animal
-10N
aggre
rand1
rand2
rand3
worst
noisy100
Classic
IB
VIB
86.11Â±0.34
83.69Â±0.50
83.69Â±0.46
83.76Â±0.29
73.80Â±0.59
53.29Â±0.09
76.28Â±0.51
NIB
85.21Â±0.44
84.03Â±1.43
81.98Â±0.68
82.39Â±0.43
73.51Â±0.82
48.11Â±0.40
75.62Â±0.64
Robust
Loss
VIB (LGCE)
85.70Â±0.08
84.32Â±0.50
83.97Â±0.38
84.25Â±0.68
78.88Â±0.27
â€”
81.72Â±1.77
VIB (LSCE)
83.95Â±0.10
82.65Â±0.25
82.84Â±0.31
82.50Â±0.24
73.81Â±1.54
50.71Â±0.14
77.17Â±0.44
Improved
IB
SIB
89.99Â±0.08
84.75Â±1.04
85.07Â±0.72
85.39Â±0.50
70.58Â±0.50
50.82Â±0.41
83.95Â±0.14
DT-JSCC
85.46Â±0.44
81.85Â±0.66
81.14Â±0.55
81.03Â±0.34
69.73Â±1.15
43.61Â±0.19
78.98Â±0.23
Deniose
+ IB
JoCoR+VIB
86.39Â±0.18
86.45Â±0.02
86.53Â±0.29
86.60Â±0.11
81.65Â±0.15
54.24Â±0.18
75.45Â±0.27
(ELR+)+VIB
92.65Â±0.27
92.09Â±0.25
92.01Â±0.20
91.93Â±0.15
86.68Â±0.25
61.06Â±0.34
85.87Â±0.15
Promix+VIB
92.35Â±0.38
92.59Â±0.40
92.42Â±0.17
92.54Â±0.21
91.24Â±0.28
63.91Â±0.19
85.47Â±0.51
Ours
LaT-IB
94.17Â±0.12
93.25Â±0.11
93.19Â±0.09
93.03Â±0.11
87.95Â±0.22
63.59Â±0.67
88.49Â±0.11
Table 2: Classification accuracy (%) on the CIFAR-10N/100N and Animal-10N dataset. All the best results are highlighted in
bold, and the second-best results are underlined.
Method
Model
Clean
Uniform Noise
Pair Noise
10%
20%
30%
40%
10%
20%
30%
40%
Classic
GIB
71.57Â±1.18 70.50Â±1.85
64.30Â±6.45
63.90Â±3.51
62.67Â±1.35
68.67Â±3.47
61.30Â±14.57 67.53Â±4.77 55.57Â±14.33
Robust
Loss
GIB (LGCE)
69.93Â±0.69 67.43Â±3.21
61.67Â±7.19
47.80Â±18.62 43.47Â±14.50
50.93Â±0.52
55.33Â±11.23 62.37Â±6.99 36.90Â±15.23
GIB (LSCE)
72.53Â±0.12 70.17Â±2.10
71.63Â±2.05
62.90Â±8.09
51.87Â±6.03
69.30Â±1.66
68.23Â±3.41
65.13Â±5.02 51.13Â±11.30
Improv-
ed IB
CurvGIB
64.63Â±5.28 65.67Â±5.85 54.67Â±10.09
54.00Â±2.41
54.97Â±2.78
59.97Â±9.00
62.07Â±5.15
66.63Â±1.94
54.57Â±1.25
IS-GIB
71.00Â±1.22 69.97Â±1.41
64.30Â±2.30
59.77Â±3.70
53.77Â±4.41
64.83Â±2.34
62.50Â±1.51
62.50Â±1.31
55.40Â±4.74
Denoise
+ IB
RNCGLN+GIB 70.57Â±0.99 69.50Â±0.86
63.43Â±5.90
62.83Â±4.15
53.27Â±14.47
69.90Â±1.69
68.20Â±2.14
66.47Â±3.21 56.77Â±15.11
CGNN+GIB
71.87Â±1.99 68.97Â±3.09
65.47Â±4.77
64.93Â±2.46
48.83Â±6.48
59.03Â±12.67
69.77Â±1.77
68.50Â±2.83 53.93Â±13.85
Ours
LaT-IB
74.97Â±0.68 74.90Â±2.09
73.40Â±2.62
70.50Â±3.86
72.20Â±4.22
75.63Â±0.46
73.03Â±1.77
70.07Â±3.20
68.77Â±2.29
Table 3: Classification accuracy (%) on the Pubmed dataset under different noise types and noise rates. All the best results are
highlighted in bold, and the second-best results are underlined.
Adversarial Attack Settings.
As discussed in Appendix
D.1, the implementation of I(D; S, T) in our LaT-IB frame-
work aligns with prior work VIB and GIB, thereby theoret-
ically inheriting their robustness properties. To empirically
verify this claim, we evaluate LaT-IBâ€™s performance under
adversarial perturbations in the image classification setting.
Specifically, we adopt the FGSM (Goodfellow, Shlens, and
Szegedy 2015) attack to perturb input images with Îµ âˆˆ
{0.05, 0.1, 0.2}, controlling the perturbation strength. Com-
bined with noisy labels during training, this setup evaluate
the robustness of model under compound noise conditions.
5.2
Robustness Against Label Noise
In this section, we evaluate the representation capability of
our proposed method under various label noise conditions.
Specifically, we investigate whether the LaT-IB model can
effectively learn robust representations when trained on data
corrupted by different types and levels of label noise.
Results. In most scenarios, our proposed LaT-IB method
outperforms other baseline approaches as shown in Table 2
and 3. In certain cases, however, methods that first perform
denoising and then apply IB achieve better results, likely
due to the strong denoising capacity of those models. Nev-
ertheless, such two-stage methods involve longer training
pipelines and are more vulnerable to adversarial attacks, as
will be demonstrated in the next section. Additional experi-
mental results on label noise are shown in Appendix E.
5.3
Robustness Against Adversarial
Perturbations
In this section, to further validate the â€œMinimal-Sufficientâ€
property in MSC of the proposed LaT-IB method, we ap-
ply perturbations to the input data D. The perturbed data is
then fed into models trained under noisy label settings. This
setup enables a comprehensive evaluation of model robust-
ness against diverse noise, including inputs and labels.
Results. The results demonstrate that the LaT-IB method
exhibits strong robustness against adversarial attacks, signif-
icantly outperforming other approaches, as shown in Table
4. Notably, two-stage methods suffer a substantial perfor-
mance drop under attack due to the increased number of vul-
nerable components, further highlighting their limitations.
5.4
Ablation Study
In this section, we analyze the effectiveness of different
training stages in the LaT-IB framework. To investigate the
Model
CIFAR-10N (aggre)
CIFAR-10N (worst)
No attack
Îµ = 0.05
Îµ = 0.1
Îµ = 0.2
No attack
Îµ = 0.05
Îµ = 0.1
Îµ = 0.2
VIB
86.11Â±0.34
52.33Â±1.55
43.18Â±2.10
36.63Â±1.10
73.80Â±0.59
43.29Â±2.36
36.56Â±3.28
32.17Â±3.27
VIB (LGCE)
85.70Â±0.08
54.15Â±1.85
44.84Â±3.00
34.72Â±2.43
78.88Â±0.27
43.27Â±1.56
31.24Â±1.42
24.23Â±1.45
SIB
89.99Â±0.08
56.48Â±2.50
46.62Â±2.41
38.14Â±2.37
70.58Â±0.50
43.39Â±2.83
33.40Â±2.87
27.89Â±2.93
(ELR+)+VIB
92.65Â±0.27
39.88Â±0.74
23.16Â±0.40
14.60Â±0.39
86.68Â±0.25
42.72Â±0.24
26.44Â±0.64
14.70Â±0.70
Promix+VIB
92.35Â±0.38
51.27Â±1.53
36.43Â±0.65
20.49Â±1.79
91.24Â±0.28
52.88Â±1.46
36.05Â±0.68
23.79Â±0.14
LaT-IB
94.17Â±0.12
69.38Â±1.23
60.66Â±2.03
49.64Â±2.27
87.95Â±0.22
64.36Â±1.67
54.18Â±2.53
43.91Â±3.05
Table 4: Classification accuracy (%) on CIFAR-10N (aggre and worst) under different adversarial perturbation levels. For
Denoise + IB methods, adversarial attacks are applied in both stages: the VIB model is trained using the output of a denoising
model that has itself been attacked. All the best results are highlighted in bold, and the second-best results are underlined.
rand1
CIFAR10N
worst
sym0.2
CIFAR100
noisy100
55
60
65
70
75
80
85
90
95
Accuracy (%)
LaT-IB
LaT-IB w/o KI
LaT-IB w/o RT
uniform0.2
DBLP
pair0.2uniform0.4 pair0.4
45
50
55
60
65
70
75
80
Accuracy (%)
LaT-IB
LaT-IB w/o KI
LaT-IB w/o RT
Pubmed
Figure 3: Ablation study.
role of each phase in enhancing model robustness, we design
two ablated variants:
â€¢ LaT-IB (w/o KI): We remove the Knowledge Injection
period, thus max(I(Yn; S), I(Yc; T)) â‰¤K is not satis-
fied. weakening the ability to map S â†’Yc and T â†’Yn.
â€¢ LaT-IB (w/o RT): We remove the Robust Training pe-
riod, meaning no further enhancement is applied to the
representations from S, T. The LaT-IB model can only
gain partial information from the three subsets.
Note that we do not design an ablation variant without
the Warmup period, as it is essential for establishing basic
classification capability and stable later training.
Results. Overall, the full LaT-IB method achieves the best
performance under all noisy label settings as shown in Fig-
ure 3, demonstrating the importance of different periods in
the framework. For image classification tasks (with larger
samples), the Robust Training stage is particularly criti-
cal, while for graph-based tasks (with fewer samples), the
Knowledge Injection stage proves more influential. These
findings highlight the necessity of each training stage in
achieving robust representations under noisy supervision.
5.5
Hyperparameter Sensitivity Analysis
We analyze the sensitivity of the model to the hyperpa-
rameter Î², Î³ and Î´. The coefficient Î² controls the feature
compression term I(D; S, T), which encourages the model
to learn noise invariant features. The coefficient Î³ con-
trols the feature separation term I(S; T|Y ), which encour-
ages the encoderS,T to capture clean and noisy represen-
tations respectively. Î´ regulates how much information the
encoderS,T learns during the Knowledge Injection phase.
1e-1
1e-2
1e-3
1e-4
1e-5
Î²
0
20
40
60
80
Accuracy (%)
CIFAR-10N (worst)
CIFAR-100 (sym 0.5)
1e0
1e-1
1e-2
1e-3
1e-4
Î³
65
70
75
80
85
Accuracy (%)
CIFAR-10N (worst)
CIFAR-100 (sym 0.5)
Figure 4: The influence of Î² and Î³.
Results. We observe that a large Î² can dominate train-
ing and cause collapse as shown in Figure 4, indicating that
I(D; S, T) partially limits the modelâ€™s expressiveness. How-
ever, our method is more tolerant to Î² than the original VIB,
which fails to train on CIFAR-10 with 50% symmetric noise
at Î² = 0.01. In contrast, our model performs better as Î²
decreases because the input compression level is reduced.
We also observe that the modelâ€™s sensitivity to Î³ varies
across noisy settings, highlighting the importance of the sep-
aration term I(S; T|Y ) under different types of noise.
For Î´, a too-small Î´ limits the encoderâ€™s training data ex-
posure, while a too-large Î´ causes the encoders to converge,
reducing their ability to separate clean and noisy informa-
tion. More detailed results in Appendix E.6.
6
Conclusion
In this work, we propose LaT-IB, a novel yet principled IB
framework that enables robust representation learning under
label noise while preserving the principle of learning min-
imally sufficient representations. We disentangle features
into representations related to clean and noisy label spaces,
and theoretically demonstrate the noise-separating effect of
our method through upper and lower bounds analysis. Fur-
thermore, we design a three-phase training framework com-
prising Warmup, Knowledge Injection and Robust Training,
that facilitates the extraction of â€œMinimal-Sufficient-Cleanâ€
representations. Extensive experiments across diverse noisy
environments validate the superior performance of LaT-IB
compared to existing IB-based methods, highlighting its po-
tential to efficiently advance the practical application of IB
theory in real-world learning scenarios with label noise.
Acknowledgments
The corresponding author is Qingyun Sun. This work
is supported by NSFC under grants No.62427808 and
No.62225202, and by the Fundamental Research Funds for
the Central Universities. We extend our sincere thanks to all
reviewers for their valuable efforts.
References
Alemi, A. A.; Fischer, I.; Dillon, J. V.; and Murphy, K. 2017.
Deep Variational Information Bottleneck. In International
Conference on Learning Representations.
Arpit, D.; Jastrzebski, S.; Ballas, N.; Krueger, D.; Bengio,
E.; Kanwal, M. S.; Maharaj, T.; Fischer, A.; Courville, A.;
Bengio, Y.; et al. 2017.
A closer look at memorization
in deep networks. In International conference on machine
learning, 233â€“242. PMLR.
Fano, R. 1952. Class notes for course 6.574: Transmission
of information. Lecture Notes.
Fu, X.; Wang, J.; Gao, Y.; Sun, Q.; Yuan, H.; Li, J.; and Li,
X. 2025. Discrete curvature graph information bottleneck.
In Proceedings of the AAAI Conference on Artificial Intelli-
gence, volume 39, 16666â€“16673.
Goodfellow, I. J.; Shlens, J.; and Szegedy, C. 2015. Explain-
ing and Harnessing Adversarial Examples. In Bengio, Y.;
and LeCun, Y., eds., 3rd International Conference on Learn-
ing Representations, ICLR 2015, San Diego, CA, USA, May
7-9, 2015, Conference Track Proceedings.
Harris, E.; Marcu, A.; Painter, M.; Niranjan, M.; PrÂ¨ugel-
Bennett,
A.;
and
Hare,
J.
2020.
Fmix:
Enhanc-
ing mixed sample data augmentation.
arXiv preprint
arXiv:2002.12047.
Hu, S.; Lou, Z.; Yan, X.; and Ye, Y. 2024. A survey on infor-
mation bottleneck. IEEE Transactions on Pattern Analysis
and Machine Intelligence.
Kolchinsky, A.; Tracey, B. D.; and Wolpert, D. H. 2019.
Nonlinear information bottleneck. Entropy, 21(12): 1181.
Krizhevsky, A.; Hinton, G.; et al. 2009. Learning multiple
layers of features from tiny images.
Li, B.; Xie, X.; Lei, H.; Fang, R.; and Kang, Z. 2025. Simpli-
fied PCNet with robustness. Neural Networks, 184: 107099.
Liu, S.; Niles-Weed, J.; Razavian, N.; and Fernandez-
Granda, C. 2020.
Early-learning regularization prevents
memorization of noisy labels. Advances in neural informa-
tion processing systems, 33: 20331â€“20342.
Menon, A. K.; Jayasumana, S.; Rawat, A. S.; Jain, H.; Veit,
A.; and Kumar, S. 2020. Long-tail learning via logit adjust-
ment. arXiv preprint arXiv:2007.07314.
Pan, S.; Wu, J.; Zhu, X.; Zhang, C.; and Wang, Y. 2016. Tri-
party deep network representation. In International Joint
Conference on Artificial Intelligence 2016, 1895â€“1901. As-
sociation for the Advancement of Artificial Intelligence
(AAAI).
Pan, Z.; Niu, L.; Zhang, J.; and Zhang, L. 2021. Disentan-
gled information bottleneck.
In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 35, 9285â€“
9293.
Patel, D.; and Sastry, P. 2023. Adaptive sample selection
for robust learning under label noise. In Proceedings of the
IEEE/CVF Winter Conference on Applications of Computer
Vision, 3932â€“3942.
Pensia, A.; Jog, V.; and Loh, P.-L. 2020.
Extracting ro-
bust and accurate features via a robust information bottle-
neck. IEEE Journal on Selected Areas in Information The-
ory, 1(1): 131â€“144.
Sen, P.; Namata, G.; Bilgic, M.; Getoor, L.; Galligher, B.;
and Eliassi-Rad, T. 2008. Collective classification in net-
work data. AI magazine, 29(3): 93â€“93.
Shamir, O.; Sabato, S.; and Tishby, N. 2010. Learning and
generalization with the information bottleneck. Theoretical
Computer Science, 411(29-30): 2696â€“2711.
Song, H.; Kim, M.; and Lee, J.-G. 2019. Selfie: Refurbishing
unclean samples for robust deep learning. In International
conference on machine learning, 5907â€“5915. PMLR.
Song, H.; Kim, M.; Park, D.; and Lee, J.-G. 2019. How does
early stopping help generalization against label noise? arXiv
preprint arXiv:1911.08059.
Song, H.; Kim, M.; Park, D.; Shin, Y.; and Lee, J.-G. 2022.
Learning from noisy labels with deep neural networks: A
survey. IEEE transactions on neural networks and learning
systems, 34(11): 8135â€“8153.
Sugiyama, M.; Suzuki, T.; and Kanamori, T. 2012. Density-
ratio matching under the bregman divergence: a unified
framework of density-ratio estimation. Annals of the Insti-
tute of Statistical Mathematics, 64: 1009â€“1044.
Tishby, N.; Pereira, F. C.; and Bialek, W. 2000. The infor-
mation bottleneck method. arXiv preprint physics/0004057.
Wang, Y.; Ma, X.; Chen, Z.; Luo, Y.; Yi, J.; and Bailey, J.
2019.
Symmetric cross entropy for robust learning with
noisy labels. In Proceedings of the IEEE/CVF international
conference on computer vision, 322â€“330.
Wang, Z.; Sun, D.; Zhou, S.; Wang, H.; Fan, J.; Huang,
L.; and Bu, J. 2024. NoisyGL: A Comprehensive Bench-
mark for Graph Neural Networks under Label Noise. arXiv
preprint arXiv:2406.04299.
Wei, H.; Feng, L.; Chen, X.; and An, B. 2020. Combating
noisy labels by agreement: A joint training method with co-
regularization. In Proceedings of the IEEE/CVF conference
on computer vision and pattern recognition, 13726â€“13735.
Wei, J.; Zhu, Z.; Cheng, H.; Liu, T.; Niu, G.; and Liu, Y.
2022. Learning with Noisy Labels Revisited: A Study Us-
ing Real-World Human Annotations. In International Con-
ference on Learning Representations.
Wu, T.; Ren, H.; Li, P.; and Leskovec, J. 2020. Graph in-
formation bottleneck. Advances in Neural Information Pro-
cessing Systems, 33: 20437â€“20448.
Xiao, R.; Dong, Y.; Wang, H.; Feng, L.; Wu, R.; Chen, G.;
and Zhao, J. 2023. ProMix: combating label noise via max-
imizing clean sample utility. In Proceedings of the Thirty-
Second International Joint Conference on Artificial Intelli-
gence, 4442â€“4450.
Xie, S.; Ma, S.; Ding, M.; Shi, Y.; Tang, M.; and Wu, Y.
2023. Robust information bottleneck for task-oriented com-
munication with digital modulation. IEEE Journal on Se-
lected Areas in Communications, 41(8): 2577â€“2591.
Yang, H.; Wu, Y.; Wen, D.; Zhou, Y.; and Shi, Y. 2025.
Structured IB: Improving Information Bottleneck with
Structured Feature Learning. In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 39, 21922â€“
21928.
Yang, L.; Zheng, J.; Wang, H.; Liu, Z.; Huang, Z.; Hong,
S.; Zhang, W.; and Cui, B. 2023. Individual and structural
graph information bottlenecks for out-of-distribution gener-
alization. IEEE Transactions on Knowledge and Data Engi-
neering, 36(2): 682â€“693.
Yuan, H.; Sun, Q.; Fu, X.; Ji, C.; and Li, J. 2024. Dynamic
graph information bottleneck. In Proceedings of the ACM
Web Conference 2024, 469â€“480.
Yuan, J.; Luo, X.; Qin, Y.; Zhao, Y.; Ju, W.; and Zhang, M.
2023. Learning on graphs under label noise. In ICASSP
2023-2023 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), 1â€“5. IEEE.
Zhang, H.; Cisse, M.; Dauphin, Y. N.; and Lopez-Paz, D.
2018. mixup: Beyond Empirical Risk Minimization. In In-
ternational Conference on Learning Representations.
Zhang, Z.; and Sabuncu, M. 2018. Generalized cross en-
tropy loss for training deep neural networks with noisy la-
bels. Advances in neural information processing systems,
31.
Zhou, Z.; Yao, J.; Liu, J.; Guo, X.; Yao, Q.; He, L.; Wang,
L.; Zheng, B.; and Han, B. 2023. Combating bilateral edge
noise for robust link prediction. Advances in Neural Infor-
mation Processing Systems, 36: 21368â€“21414.
Zhu, Y.; Feng, L.; Deng, Z.; Chen, Y.; Amor, R.; and Wit-
brock, M. 2024. Robust node classification on graph data
with graph and label noise. In Proceedings of the AAAI con-
ference on artificial intelligence, volume 38, 17220â€“17227.
A
Code Source
The
code
for
LaT-IB
is
publicly
available
at:
https://github.com/RingBDStack/LaT-IB.
B
Algorithms and Complexity Analysis
B.1
The Overall Process of LaT-IB
The overall training pipeline of LaT-IB is outlined in Algo-
rithm B.1.
Algorithm B.1: The Overall Process of LaT-IB
Input: Input data D with label Y , epoch number of each pe-
riod EW armup, EInjection, ERobust, overall epoch number
E
Output: Predicted label Ë†Y
1: Parameter initialization
2: for epoch i = 1, . . . , E do
3:
Encode inputs to obtain (ÂµS, ÏƒS), (ÂµT , ÏƒT )
4:
Decode the reparameterized embedding to generate
predictions (Ë†yS, Ë†yT )
5:
if i â‰¤EW armup then
6:
Optimize the encoderS with Eq. (13)
7:
end if
8:
if EW armup < i â‰¤EInjection then
9:
Obtain Clean/Noise/Uncertain Set using InfoJS se-
lector
10:
Optimize the LaT-IB model with Eq. (15) and (16)
11:
end if
12:
if i > EInjection then
13:
Optimize the LaT-IB model with Eq. (18)
14:
Optimize the discriminator with Eq. (19)
15:
end if
16: end for
B.2
InfoJS Selector Algorithms Details
Algorithm B.2 implements a sample selection scheme based
on MI and JS divergence.
B.3
LConCE Algorithms Details
Proposition 4.1 states:
âˆ’I(Y ; S, T) â‰¤âˆ’max(I(Y ; S), I(Y ; T)).
(B.1)
Further reformulated as a cross-entropy loss, this provides
an implementation method for I(Y ; S, T):
âˆ’I(Y ; S, T) â‰¤
X
i
min(L(Ë†yS,i, yi), L(Ë†yT,i, yi)).
(B.2)
In the loss function design, we tailor the loss for two sce-
narios: image classification (many samples) and node clas-
sification (few samples).
Graph Tasks.
First, we present the loss function design
for the node classification task under the few-sample condi-
tion, as it is closest to Equation (B.2). Since the min function
is not continuous and may hinder model learning, we instead
use the smooth approximation:
f(a, b) = 1
Î² Â· log (exp(âˆ’Î² Â· a) + exp(âˆ’Î² Â· b)) .
(B.3)
Algorithm B.2: InfoJS Selector
Input: Trained model fÎ¸, data (D, Y ), selection ratio Î´
Output: Binary selection mask: maskS, maskT
1: Run fÎ¸ to obtain (ÂµS, ÏƒS), (ÂµT , ÏƒT ) and predictions
(Ë†yS, Ë†yT )
2: Compute I(S; Y ): â„“S â†LCE(Ë†yS, y) {Eq. (10)}
3: Compute JS divergence: JS â†DJS(ÂµS, ÏƒS, ÂµT , ÏƒT )
4: Initialize maskS, maskT
5: for each class j = 1, . . . , C do
6:
Ij â†indices of class-j samples in M
7:
kj â†max(1, min(âŒˆÎ´ Â· |Ij|âŒ‰, |D|/C))
8:
Select top-kj and bottom-kj samples by â„“S and up-
date maskS, maskT
9:
Select top-kj and bottom-kj samples by JS and up-
date maskS, maskT
10: end for
11: return maskS, maskT {maskS for clean set; maskT for
noise set}
Notably, as b â†’+âˆ, this expression becomes equivalent to
min(a, b).
Algorithm B.3: LConCE for node classification
Input: Predictions prob1, prob2; Labels y; Threshold Î²
Output: Final loss value LConCE
1: a â†LCE(prob1, y) {Per-sample LCE}
2: b â†LCE(prob2, y)
3: L â†1
Î² Â· log (exp(âˆ’Î² Â· a) + exp(âˆ’Î² Â· b)) {Eq. (B.3)}
4: return Mean(L)
Image Tasks.
We then directly apply Algorithm B.3 to
the image classification task and observe that it causes lazy
training, where the model tends to produce identical out-
puts. We hypothesize that this behavior arises because: as
the number of training samples increases, the gradient con-
tributions from noisy samples become diluted. Meanwhile,
Algorithm B.3 imposes a strict separation, causing each en-
coder to receive only a limited portion of the input data. As
a result, when the predictions from the two encoders be-
come overly similar, the model lacks sufficient supervision
signals, potentially leading to training collapse.
To address this issue, we train both encoders on the sam-
ples where the two prediction heads produce consistent out-
puts, rather than assigning them to a single encoder. This
significantly increases the amount of usable information for
each encoder. Moreover, we relax the condition in Equa-
tion B.2 to:
âˆ’I(Y ; S, T) â‰¤
X
i
min(L(Ë†yS,i, yi), L(Ë†yT,i, yi))
â‰¤
X
i
max(L(Ë†yS,i, yi), L(Ë†yT,i, yi))
(B.4)
The final loss function is shown in Algorithm B.4.
Algorithm B.4: LConCE for image classification
Input: Predictions prob1, prob2; Labels y; Threshold t
Output: Final loss value LConCE
1: Compute a â†LCE(prob1.copy(), y)
2: Compute b â†LCE(prob2.copy(), y)
3: pred1 â†arg max(prob1.copy()) {Per-sample LCE}
4: pred2 â†arg max(prob2.copy())
5: maska â†(a < b)
6: maskb â†(a > b)âˆ¨(pred1 = pred2) {The second part
prevents T from learning nothing.}
7: if P(pred1 = pred2)/|y| > t then
8:
maska â†(a < b) âˆ¨(pred1 = pred2)
9:
maskb â†(a > b)
10: end if
11: Initialize y1 â†y, y2 â†y
12: Replace y1[maska] â†pred1[maska] {Focus on clean
samples}
13: Replace y2[maskb] â†pred2[maskb] {Focus on noise
samples}
14: loss1 â†LCE(prob1, y1)
15: loss2 â†LCE(prob2, y2)
16: return (loss1 + loss2)/2
B.4
Time Consumption
We adopt the constant definitions from Section 3. For Al-
gorithm B.2, the LCE has a time complexity of O(NC).
The JS divergence, computed between all sample pairs, re-
quires O(N 2k) operations, where k is the dimensionality
of the Gaussian embeddings. Assuming class-balanced data,
the per-class selection of top-k and bottom-k samples in-
volves sorting subsets of size approximately N/C, giving
a total sorting complexity of O(N log(N/C)). Overall, the
dominant term is O(N 2k), since typically C â‰ªN, mak-
ing the pairwise divergence computation the main computa-
tional bottleneck.
Algorithms B.3 and B.4 perform a finite number of cross-
entropy loss computations. Therefore, their overall time
complexity is equivalent to that of the cross-entropy loss,
which is O(NC).
To further assess the efficiency of different methods,
we report the training time consumption of several top-
performing approaches.
Image Classification.
We selected three baselines includ-
ing VIB, (ELR+)+VIB and (Promix2)+VIB as well as com-
pared their time consumption under the condition of achiev-
ing a performance like Table 2 on CIFAR-10N dataset, as
shown in the Table B.1. The results demonstrate that al-
though our model incurs higher computation than VIB, it
achieves better performance within fewer epochs, and over-
all outperforms two-stage models in terms of efficiency.
2For the Promix method, strictly following the original exper-
imental setup results in a runtime exceeding 24 hours, leading to
out-of-time (OOT) termination. To address this, we reduced the
number of training epochs, with only a minor performance drop,
to ensure timely completion.
Method
VIB
(ELR+)+VIB
(Promix)+VIB
LaT-IB
Time (h)
1.6
4.9+1.6
12.9+1.6
5.18
Epoch
100
200+100
300+100
200
Per Epoch (min)
0.94
1.30
2.18
1.55
Table B.1: Comparison of training time consumption (IC)
Node Classification.
We selected GIB, GIB (LGCE) and
RNCGLN+GIB as baselines. Table B.2 presents the results
on the DBLP dataset, supporting similar conclusions as in
the image classification task. Notably, although RNCGLN
achieves strong performance, it incurs significant time over-
head, as also reported in NoisyGL (Wang et al. 2024).
Method
GIB
GIB (LGCE)
RNCGLN+GIB
LaT-IB
Time (s)
37.8
37.8
3445.4+37.8
55.9
Epoch
100
100
500+100
100
Per Epoch (s)
0.38
0.38
5.80
0.56
Table B.2: Comparison of training time consumption (NC)
We evaluate the time cost at each period of the pipeline.
The results are shown in Figure B.1. The results indicate that
for image tasks with a large number of samples, Knowledge
Injection consumes the most time, which aligns with our
theoretical time complexity analysis. In contrast, for graph
tasks with fewer samples, the time cost of Knowledge In-
jection is slightly lower than that of Robust Training. We
speculate that this is due to lower actual time complexity
than the theoretical value, possibly resulting from low-level
computational optimizations, and the relatively small sam-
ple size helps offset part of the time overhead.
Period 1
Period 2
Period 3
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
Avg. Time (min)
(a) CIFAR-10N (worst)
Period 1
Period 2
Period 3
0.0
0.1
0.2
0.3
0.4
0.5
0.6
Avg. Time (s)
(b) DBLP
Figure B.1: Time Consumption Analysis
C
Proofs
In this section, we present the relevant proofs from the pa-
per. We first restate the statements to be proved, followed by
detailed proofs.
C.1
The proof of Theorem 1.1
Theorem C.1 (Cumulative Degradation). In the two-stage
approach, f1 is used to modify the labels Y â€² = f1(D),
and f2 is responsible for extracting valid information from
D while approximating the prediction result to f1(D) . For
one-stage model g(D), it extracts the relevant information
while removing noise. If the denoising abilities of f1 and g
are the same, the following inequality holds:
P(f2(D) Ì¸= g(D)) â‰¥H(Y â€²|D) âˆ’1
log(|Y| âˆ’1) ,
(C.1)
where Y denotes the support of Y , and |Y| denotes the num-
ber of elements in Y. The two models perform identically iff
f2 achieves the error lower bound and H(Y â€²|D) = 0.
Proof. Without loss of generality, we illustrate this using the
image classification task, where D = X.
We begin by introducing Fanoâ€™s inequality (Fano 1952):
Let the discrete random variables X and Y denote the in-
put and output messages, respectively, with joint distribution
P(x, y). Let e represent the event of an error, i.e., X Ì¸= ËœX,
where ËœX = f(Y ) is an estimate of X. Then Fanoâ€™s inequal-
ity states:
H(X|Y ) â‰¤Hb(e) + P(e) log(|X| âˆ’1),
(C.2)
where X denotes the support set of the random variable X,
and |X| is its cardinality (i.e., the number of elements in
X). Here, H(X|Y ) = âˆ’P
i,j P(xi, yj) log P(xi|yj) is the
conditional entropy, P(e) = P(X Ì¸= Ë†X) is the probability
of a communication error, and Hb(e) = âˆ’P(e) log P(e) âˆ’
(1 âˆ’P(e)) log(1 âˆ’P(e)) is the binary entropy.
Part 1: Consider the second stage f2 of the two-stage
model, whose input Y â€² serves as a reference for the final
model output f2(x). According to the inequality above, we
have:
H(Y â€²|X) â‰¤Hb(e) + P(e) log(|Y| âˆ’1),
(C.3)
where P(e) := P(f2(x) Ì¸= f1(x)). Since the binary entropy
has an upper bound of 1, the lower bound of the error prob-
ability is:
H(Y â€²|X) â‰¤Hb(e) + P(e) log(|Y| âˆ’1)
â‰¤1 + P(e) log(|Y| âˆ’1),
(C.4)
Given the assumption that f1 and g have the same denois-
ing capability, we can, without loss of generality, assume
f1(x) = g(x), thus:
P(f2(x) Ì¸= g(x)) = P(e) â‰¥H(Y â€²|X) âˆ’1
log(|Y| âˆ’1) .
(C.5)
Part 2: When the two models behave identically, i.e.,
P(f2(x) Ì¸= g(x)) = 0, from inequality C.3 we know that
H(Y â€²|X) â‰¤0. Since entropy is non-negative, it follows that
H(Y â€²|X) = 0. At this point, f2 has optimized its classifica-
tion error to the theoretical lower bound.
When H(Y â€²|X) = 0, it is easy to see that P(f2(x) Ì¸=
g(x))
=
0 satisfies inequality C.3. Since P(f2(x)
Ì¸=
g(x)) â‰¥0, and 0 is the lower bound of the error rate, if
f2 reaches this bound, the performance of the two models is
exactly the same.
C.2
The proof of Lemma 4.1 and 4.2
Lemma C.1 (Nuisance Invariance). Taking the part of D
that does not contribute to Y as Dn (Dn is independent of
Y ), and considering the Markov chain (Y, Dn) â†’D â†’
(S, T), the following inequality holds:
I(Dn; S, T) â‰¤âˆ’I(Y ; S, T) + I(D; S, T).
(C.6)
Proof. We proof this lemma in three steps.
Step 1: According to the property of the Markov chain,
we have:
I(S, T; Dn, Y |D) = 0.
(C.7)
And because:
I(S, T; Dn, Y |D)
= I(S, T; Dn|D)
|
{z
}
â‰¥0
+ I(S, T; Y |Dn, D)
|
{z
}
â‰¥0
=0.
(C.8)
So we have:
I(S, T; Dn|D) = I(S, T; Y |Dn, D) = 0
(C.9)
By expanding I(S, T; D, Dn), we obtain:
I(S, T; D, Dn) = I(S, T; D) + I(S, T; Dn|D)
= I(S, T; D).
(C.10)
By an alternative expansion, we obtain:
I(S, T; D, Dn) = I(S, T; Dn) + I(S, T; D|Dn).
(C.11)
Combining Eq. (C.10) and (C.11), we obtain the follow-
ing equality:
I(S, T; D) = I(S, T; Dn) + I(S, T; D|Dn).
(C.12)
Step 2: By expanding I(S, T; Y, D|Dn), we obtain:
I(S, T; Y, D|Dn) = I(S, T; D|Dn) + I(S, T; Y |D, Dn).
(C.13)
Since we have I(S, T; Y |D, Dn) = 0:
I(S, T; Y, D|Dn) = I(S, T; D|Dn).
(C.14)
Similarly, by expanding in another way:
I(S, T; Y, D|Dn) = I(S, T; Y |Dn) + I(S, T; D|Y, Dn).
(C.15)
Combining Eq. (C.14) and (C.15), we obtain
I(S, T; D|Dn) = I(S, T; Y |Dn) + I(S, T; D|Y, Dn)
â‡’I(S, T; D|Dn) â‰¥I(S, T; Y |Dn).
(C.16)
Step 3: Substituting Eq. (C.16) into Eq. (C.12), we obtain:
I(S, T; D) â‰¥I(S, T; Dn) + I(S, T; Y |Dn)
= I(S, T; Dn) + I(S, T; Y ).
(C.17)
Therefore, we obtain the conclusion:
I(Dn; S, T) â‰¤âˆ’I(Y ; S, T) + I(D; S, T).
(C.18)
Lemma C.2 (Feature Convergence). Assuming that Y can
potentially contain all information about Yr and Yn, the fol-
lowing inequality holds when max(I(Yn; S), I(Yr; T)) â‰¤
max(I(S; T), Îµ)/2 = K, Îµ âˆˆR is satisfied:
âˆ’I(Yr; S) âˆ’I(Yn; T) âˆ’Îµ â‰¤âˆ’I(Y ; S, T) + I(S; T|Y ).
(C.19)
Proof. By expanding the mutual information and combining
the assumptions, we have:
I(Y ; S, T)
=I(Y ; S) + I(Y ; T) âˆ’I(Y ; S; T)
=I(Y ; S) + I(Y ; T) âˆ’(I(S; T) âˆ’I(S; T|Y ))
=I(Y ; S) + I(Y ; T) âˆ’I(S; T) + I(S; T|Y )
=I(Yr, Yn; S) + I(Yr, Yn; T) âˆ’I(S; T) + I(S; T|Y )
â‰¤I(Yr; S) + I(Yn; S) + I(Yr; T) + I(Yn; T)
âˆ’I(S; T) + I(S; T|Y ).
(C.20)
Rearranging the terms, we obtain:
âˆ’I(Y ; S, T) + I(S; T|Y )
â‰¥âˆ’I(Yr; S) âˆ’I(Yn; T) + (I(S; T) âˆ’I(Yn; S) âˆ’I(Yr; T)) .
(C.21)
Now, we consider two cases:
Case 1: When I(S, T) â‰¥Îµ:
âˆ’I(Y ; S, T) + I(S; T|Y )
â‰¥âˆ’I(Yr; S) âˆ’I(Yn; T) + (I(S; T) âˆ’I(Yn; S) âˆ’I(Yr; T))
â‰¥âˆ’I(Yr; S) âˆ’I(Yn; T).
(C.22)
Case 2: When I(S, T) < Îµ:
âˆ’I(Y ; S, T) + I(S; T|Y )
â‰¥âˆ’I(Yr; S) âˆ’I(Yn; T) + (I(S; T) âˆ’I(Yn; S) âˆ’I(Yr; T))
â‰¥âˆ’I(Yr; S) âˆ’I(Yn; T) âˆ’I(Yn; S) âˆ’I(Yr; T)
â‰¥âˆ’I(Yr; S) âˆ’I(Yn; T) âˆ’Îµ.
(C.23)
Thus, the conclusion is proven.
C.3
The proof of Proposition 4.1 âˆ¼4.4
Proposition C.1 (The upper bound of âˆ’I(Y ; S, T)). Given
the label Y and the variable S, T that learns the charac-
teristics of the real label space and the noise label space
respectively, we have:
âˆ’I(Y ; S, T) â‰¤âˆ’max (I(Y ; S), I(Y ; T)) .
(C.24)
Proof. Expand directly using the definition of mutual infor-
mation:
I(Y ; S, T) = I(Y ; S) + I(Y ; T|S)
= I(Y ; T) + I(Y ; S|T)
â‰¥max(I(Y ; S), I(Y ; T))
(C.25)
So that âˆ’I(Y ; S, T) â‰¤âˆ’max (I(Y ; S), I(Y ; T)).
Proposition C.2 (The upper bound of I(D; S, T)). Let D,
S, T be random variables. Assume the probabilistic map-
ping p(D, S, T) follows the Markov chain S â†”D â†”T.
Then:
I(D; S, T) â‰¤I(D; S) + I(D; T).
(C.26)
Proof. Without loss of generality, here we take D = X as
an example to prove it.
Expanded by definition and processed over the probability
distributions, we can obtain:
I(D; S, T)
=Ep(x,s,t) log p(s, t, x)
p(x)p(s, t)
=Ep(x,s,t) log p(x)p(s|x)p(t|x)
p(x)p(s, t)
=Ep(x,s,t) log
p(s|x)p(x)
p(x)p(s) Â· p(t|x)p(x)
p(x)p(t) Â· p(s)p(t)
p(s, t)

=I(D; S) + I(D; T) âˆ’I(S; T)
â‰¤I(D; S) + I(D; T)
(C.27)
Proposition C.3 (Reformulation of I(S, T|Y )). Given the
label Y and the variable S, T, minimizing I(S; T|Y ) is
equivalent to minimize I(S, Y ; T, Y ).
Proof.
I(S; T|Y )
=
Z
y
p(y)
ZZ
s,t
p(s, t|y) log
p(s, t|y)
p(s|y)p(t|y) ds dt dy
=
ZZZ
(s,t,y)
p(s, t, y) log
p(s, t, y)
p(s, y)p(t, y) p(y) ds dt dy
=Ep(s,t,y) log
p(s, t, y)
p(s, y)p(t, y) + Ep(y) log p(y)
=I(S, Y ; T, Y ) âˆ’H(Y )
(C.28)
Since H(Y ) is a constant, it follows that I(S; T|Y ) âˆ
I(S, Y ; T, Y ), thus proved.
Proposition C.4 (Reformulation of the condition in Eq. (8):
max(I(Yn; S), I(Yc; T)) â‰¤K). Minimizing I(Yr; T) and
I(Yn; S) is equivalent to increase I(Yn; T) and I(Yr; S).
Proof. For S, with limited capacity (I(Y ; S) â‰¤A), we
have:
I(Yr; S) + I(Yn; S) â‰¤I(Y ; S) + I(Yr; Yn) â‰¤A + const
(C.29)
Similarly, for T, enlarging one part constrains the other
under limited capacity.
C.4
The proof of Eq. (10): max I(Y ; Z) is
equivalent to min LCE
Proof.
I(Y ; Z) =
ZZ
(y,z)
p(y, z) log p(y, z)
p(y)p(z) dy dz
=
ZZ
(y,z)
p(y, z) log p(y|z)
p(y) dy dz
= Ep(y,z) (log(qÎ¸(y|z))) +
Ep(z)(DKL(p(y|z)âˆ¥qÎ¸(y|z))) + H(Y )
â‰¥Ep(y,z) (log(qÎ¸(y|z))) = âˆ’LCE(Z, Y ),
(C.30)
where qÎ¸i(Â·) is variational approximation of p(Â·).
D
Implement Details
D.1
Implement Details of LMinimal
As established in Proposition 4.2, minimizing the I(D; S, T)
objective reduces to minimizing I(D; Z), where Z
âˆˆ
{S, T}. We now discuss the methodology for estimating and
optimizing I(D; Z).
The input is an image.
In this case, D = X, i.e., the input
to the model consists solely of image features. Therefore,
minimizing I(D; Z) reduces to minimizing the divergence
between the approximate posterior and a fixed prior.
Proof. Expanded via the definition of mutual information:
I(X; Z)
=
ZZ
(x,z)
p(x, z) log p(x, z)
p(x)p(z) dx dz
=
Z
x
p(x)
Z
z
p(z|x) log p(z|x)
q(z) dz

dx âˆ’
Z
z
p(z) log p(z)
q(z) dz
=
Z
x
p(x) [DKL[p(z|x) âˆ¥q(z)]] dx âˆ’DKL[p(z) âˆ¥q(z)]
â‰¤Ep(x) [DKL[p(z|x) âˆ¥q(z)]] .
(D.1)
Since q(z) represents the marginal distribution of the la-
tent variable and is not constrained during training, we can
assume without loss of generality that q(z) âˆ¼N(0, In). The
encoder maps input features to a Gaussian distribution, i.e.,
p(z|x) âˆ¼N(Âµn, Ïƒn). In this case, the KL divergence be-
tween two Gaussian distributions admits a closed-form so-
lution and can be computed as:
DKL[p(z|x)|q(z)] = 1
2
n
X
i=1
 Âµ2
i + Ïƒ2
i âˆ’log Ïƒ2
i âˆ’1

.
(D.2)
The input is a graph.
In this case, the input data is the
graph D = G = (X, A), where X denotes node features and
A denotes the adjacency matrix. As a result, the estimation
of the mutual information I(D; Z) becomes more intricate
compared to scenarios with only feature inputs.
Following the framework of Graph Information Bottle-
neck (GIB), we consider two groups of indices SX, SA âŠ†
[L] that satisfy the Markovian dependence. Specifically, we
assume D âŠ¥Z(L)
X
\ {Z(l)
X }lâˆˆSX âˆª{Z(l)
A }lâˆˆSA, where Z(l)
X
denotes the node feature representation at layer l, and Z(l)
A
denotes the structural representation at layer l. Based on this
condition, for any set of distributions Q(Z(l)
X ) with l âˆˆSX,
and Q(Z(l)
A ) with l âˆˆSA, the following upper bound holds:
I(D; Z(L)
X ) â‰¤
X
lâˆˆSA
AIB(l) +
X
lâˆˆSX
XIB(l),
(D.3)
where AIB(l) and XIB(l) denote the information contribu-
tions from the adjacency and feature paths, respectively, and
are defined as:
AIB(l) = E
"
log P(Z(l)
A |A, Z(lâˆ’1)
X
)
Q(Z(l)
A )
#
,
XIB(l) = E
"
log P(Z(l)
X |Z(lâˆ’1)
X
, Z(l)
A )
Q(Z(l)
X )
#
.
(D.4)
For the structural branch, we adopt a Bernoulli-based KL
divergence estimator:
d
AIB
(l) =
X
vâˆˆV,tâˆˆ[T ]
DKL

Bernoulli(Ï•(l)
v,t)||Bernoulli(Î±)

,
(D.5)
where Ï•(l)v, t denotes the probability of an edge between
node v and its t-hop neighbors, and Î± is the prior class prob-
ability.
To estimate XIB(l), we model Q(Z(l)
X ) as a mixture of
Gaussians with learnable parameters. For any node v, we
assume Z(l)
X,v âˆ¼Pm
i=1 wiN(Âµ0,i, Ïƒ2
0,i), where wi, Âµ0,i and
Ïƒ0,i are shared parameters across all nodes, and ZX,v âŠ¥
ZX,u if v Ì¸= u. We compute:
d
XIB
(l) = log P(Z(l)
X | Z(lâˆ’1)
X
, Z(l)
A )
Q(Z(l)
X )
=
X
vâˆˆV
log Î¦(Z(l)
X,v; Âµv, Ïƒ2
v)
âˆ’log
 m
X
i=1
wiÎ¦(Z(l)
X,v; Âµi, Ïƒ2
0,i)
!
,
(D.6)
where Î¦(Â·) denotes the probability density function of a
Gaussian distribution.
In conclusion, we select proper sets of indices SX, SA and
use substitution:
I(D, Z) â†
X
lâˆˆSA
d
AIB
(l) +
X
lâˆˆSX
d
XIB
(l).
(D.7)
More detailed content and proof can be found in GIB (Wu
et al. 2020).
D.2
Implement Details of Knowledge Injection
Building on the proven success of mixup-based techniques
in computer vision, we apply FMix (Harris et al. 2020) for
image data augmentation across both clean and noisy sub-
sets. To counteract potential class bias during training, we
incorporate Debiased Margin-based Loss (Xiao et al. 2023)
and Debiased Pseudo Labeling (Menon et al. 2020), foster-
ing unbiased model predictions.
D.3
Implement Details of Robust Training
To further improve model performance, we perform certain
modifications to the label Y during robust training period.
For image classification, every k epochs, the model pre-
dictions are combined with the original labels using expo-
nential moving average to replace the original labels.
For node classification, at each epoch, the labels of sam-
ples with prediction confidence higher than a threshold Ï„ are
replaced with the modelâ€™s predicted results.
E
Experiments Details and Results
E.1
Data
Image Classification.
We select CIFAR-based datasets to
simulate both synthetic and real-world label noise. To miti-
gate the risk of overfitting to a specific dataset, we also in-
clude the Animal-10N dataset. Specifically:
â€¢ CIFAR-10/100 (Krizhevsky, Hinton et al. 2009)3:
These are classic image classification datasets with 10
and 100 categories, respectively. By constructing a noise
transition matrix, we introduce symmetric noise (Sym
Noise, where each noisy label is uniformly sampled from
all classes) and asymmetric noise (Asym Noise, where
each class is flipped to a specific incorrect class based
on semantic similarity). In our experiments, we consider
symmetric noise with noise rates of 20% and 50%, which
are independent of the input features. Additionally,
based on class-wise correlations, we design a 40% asym-
metric noise setting on CIFAR-10.
â€¢ CIFAR-10N/100N(Wei et al. 2022)4: These datasets in-
troduce real-world label noise based on standard CIFAR-
10 and CIFAR-100. Each image is annotated by multi-
ple human workers, and the final label is obtained via
majority voting, thereby reflecting more natural and re-
alistic label noise. Previous studies have shown that the
noise is not independent of the input features. CIFAR-
10N includes five noise levels (Aggregate: 9.03%, Ran-
dom 1: 17.23%, Random 2: 18.12%, Random 3: 17.64%,
Worst: 40.21%), while CIFAR-100N includes one noise
level (40.20%).
â€¢ Animal-10N(Song, Kim, and Lee 2019)5: This dataset
is constructed based on animal categories from Ima-
geNet. It consists of images from 10 common animal
classes collected and labeled by non-expert annotators.
The label noise mainly stems from confusion between
3https://www.cs.toronto.edu/Ëœkriz/cifar.html
4https://github.com/UCSC-REAL/cifar-10-100n/tree/main
5https://dm.kaist.ac.kr/datasets/animal-10n/
fine-grained categories, such as dog vs. wolf or cow vs.
horse. The estimated noise rate is around 8%.
A more intuitive comparison of the selected datasets is
presented in Table E.1.
Dataset
# Class
Noise Type
Noise Ratio
CIFAR
10 / 100
Sym/Asym
20%, 40%, 50%
CIFARN
10 / 100
Real-world
9.03% âˆ¼40.21%
Animal-10N
10
Real-world
â‰ˆ8%
Table E.1: Comparison of image datasets
Node Classification.
We select three classic citation net-
work datasets: Cora, Citeseer, and Pubmed. In addition, we
include the one author collaboration network DBLP for eval-
uation. To ensure consistency across methods, we randomly
sample 20 nodes per class for training. For validation and
testing, 500 and 1000 nodes are randomly selected from the
graph, respectively. Specifically:
â€¢ Cora, Citeseer and Pubmed (Sen et al. 2008)6: These
citation network datasets are widely adopted in graph
learning research involving label noise. In each dataset,
nodes correspond to academic papers, and edges repre-
sent citation connections among them. The node features
consist of binary word vectors indicating whether partic-
ular words from a vocabulary are present or absent. Each
node is labeled according to the research topic category
of the corresponding paper.
â€¢ DBLP (Pan et al. 2016)7: This dataset represents an au-
thor collaboration network within the field of computer
science. Nodes represent documents, while edges corre-
spond to citation relationships between these documents.
Node features are derived from word vectors extracted
from the text, and labels reflect the category of the re-
search topic.
A more intuitive comparison of the selected datasets is
presented in Table E.2.
Dataset
# Class
# Node
# Edge
# Feat.
Cora
7
2,708
5,278
1,433
Citeseer
6
3,327
4,552
3,703
Pubmed
3
19,717
44,324
500
DBLP
4
17,716
52,867
1,639
Table E.2: Comparison of graph datasets
E.2
Baselines
We compare with four categories, 16 baselines in two sce-
narios: â‘ Classic IB methods; â‘¡IB with robust loss func-
tions; â‘¢Improved IB variants; â‘£Two-stage denoising + IB
methods. They comprehensively evaluate our LaT-IBâ€™s per-
formance from multiple perspectives. Specifically:
6https://github.com/kimiyoung/planetoid/tree/master/data
7https://github.com/abojchevski/graph2gauss/raw/master/data
Image Classification.
â€¢ Classical IB Models: This paper selects two IB methods,
VIB (Alemi et al. 2017) and NIB (Kolchinsky, Tracey,
and Wolpert 2019), as baseline approaches. The core idea
of VIB is to approximate the optimization of the IB ob-
jective using variational inference. NIB further extends
the original IB principle to address the limitations of KL
divergence estimation in VIB, which is restricted by the
assumptions and simplicity of the prior distribution. In-
stead of relying on an analytical KL computation, NIB
adopts kernel density estimation (KDE) for learning.
â€¢ IB with robust loss functions: In the IB framework, the
mutual information I(Z; Y ) is typically optimized via
cross-entropy. The Generalized Cross-Entropy (GCE)
loss (Zhang and Sabuncu 2018) combines cross-entropy
and mean absolute error to enhance robustness. The
Symmetric Cross-Entropy (SCE) loss (Wang et al.
2019) integrates standard cross-entropy with reverse
cross-entropy, improving resistance to label noise. By re-
placing the original loss with these robust alternatives,
new IB variants are constructed under robust loss func-
tions.
â€¢ Improved IB Methods: Many subsequent studies have en-
hanced the feature extraction capability and robustness
of IB. The SIB (Yang et al. 2025) framework leverages
an auxiliary encoder to capture missing structural infor-
mation, improving learning performance. DT-JSCC (Xie
et al. 2023) proposes a robust encoding architecture
based on the IB principle to improve transmission re-
silience under varying communication channels. These
two methods represent improved IB frameworks and are
included in the baseline comparisons.
â€¢ Two-Stage Denoise + IB Methods: Although Theorem
3.1 indicates that denoising followed by IB may not
yield optimal results, this study further explores this
approach. Three representative denoising methods are
adopted: JoCoR (Wei et al. 2020), a robust learning
method based on co-training; ELR+ (Liu et al. 2020),
which uses noise-robust regularization for label correc-
tion; and ProMix (Xiao et al. 2023), which integrates
Mixup data augmentation and dynamic confidence mod-
eling, representing a state-of-the-art denoising approach.
These denoised datasets are subsequently used for IB
training.
Node Classification.
â€¢ Classical IB Models: This paper selects the GIB (Wu
et al. 2020) method as the classical IB baseline. GIB
leverages the IB principle by learning graph represen-
tations that compress input feature and structure while
preserving label-relevant information.
â€¢ IB with robust loss functions: Consistent with the robust
loss settings used in the image classification task.
â€¢ Improved IB Methods: Two representative improvements
are included. CurvGIB (Fu et al. 2025) introduces dis-
crete Ricci curvature into the IB framework to better cap-
ture topological structures in graphs, enabling the model
to discard spurious connectivity information and pre-
serve label-relevant substructures. IS-GIB (Yang et al.
2023) enhances generalization under distribution shifts
by jointly modeling individual and structural information
bottlenecks, improving the robustness and transferability
of graph representations.
â€¢ Two-Stage Denoise + IB Methods: For denoise model,
RNCGLN
(Zhu
et
al.
2024)
first
applies
graph
contrastive learning and multi-head self-attention to
learn local-global representations, followed by pseudo-
labeling strategies to address graph and label noise.
CGNN (Yuan et al. 2023) performs neighborhood-based
label correction and contrastive learning to smooth repre-
sentations across graph views. It iteratively corrects noisy
labels using neighborsâ€™ predictions before applying the
IB objective for final node classification.
E.3
Preliminary Experiment
Vulnerability of IB Methods to Noisy Labels.
To investi-
gate the sensitivity of IB methods to label noise, we first con-
duct preliminary experiments on image classification and
node classification to examine the relationship between IB
performance and label corruption.
For image classification, Figure E.1a demonstrates that
the VIB (Alemi et al. 2017) framework suffers performance
degradation on the CIFAR-10N (Wei et al. 2022) dataset as
label noise increases. Moreover, the decline becomes more
pronounced with higher noise levels. In extreme cases, ex-
cessive noise can even lead to training collapse under the IB
framework as shown in Figure E.1b.
aggre
rand1
worst
65
70
75
80
85
90
Accuracy (%)
ResNet34
VIB ( =0.01)
(a) With feature-dependent noise
sym-0.2
sym-0.5
0
20
40
60
80
Accuracy (%)
Training
Crash
ResNet34
VIB ( =0.01)
(b) With symmetric noise
Figure E.1: Preliminary Experiments on Image Classifica-
tion.
For node classification, Figure E.2a shows that GIB (Wu
et al. 2020) gradually fits the noisy labels during training,
leading to a steady decline in performance on the testing set.
Furthermore, Figure E.2b, using the Cora dataset as an ex-
ample, illustrates that this trend becomes increasingly severe
as the level of label noise increases.
Performance Degradation in Cascaded Models.
Theo-
rem 3.1 shows that cascading models weakens the denoising
effect of the first stage. This phenomenon is further illus-
trated in Figure E.3, where the data is first denoised using
the ELR+ model and then used to train with the IB method.
The resulting performance often falls short of the accuracy
achieved after denoising alone.
0
20
40
60
80
100
Epoch
20
30
40
50
60
70
80
90
100
Accuracy (%)
Cora Train Acc
Cora Test Acc
DBLP Train Acc
DBLP Test Acc
(a) With 40% uniform noise
0
20
40
60
80
100
Epoch
10
20
30
40
50
60
70
80
Accuracy (%)
Noise Rate 0.0
Noise Rate 0.1
Noise Rate 0.2
Noise Rate 0.3
Noise Rate 0.4
(b) Cora (varying noise levels)
Figure E.2: Preliminary Experiments on Node Classifica-
tion.
cifar-10N (worst)
cifar-10 (sym-0.5)
animal-10N
70
75
80
85
90
95
Accuracy (%)
2.17%
1.84%
2.47%
ELR+
(ELR+) + IB
Figure E.3: Performance degradation.
E.4
Additional Results
Table E.3, E.4 and E.5 presents a broader comparison of
various LaT-IB methods under different types and levels of
noise. We use a dash (â€“) to denote cases where the model
fails or produces invalid results. Classification accuracy (%)
is used as the evaluation metric, where a higher value indi-
cates better model performance.
For image classification, the model does not consistently
outperform denoise + IB approaches in some cases. A pos-
sible explanation is that the denoising models are particu-
larly effective on the CIFAR dataset, thereby significantly
enhancing the IB performance. To further validate this, we
also evaluated on the Animal-10N dataset, as shown in Table
2, where LaT-IB achieves the best performance. Moreover,
Table 4 demonstrates that our method substantially outper-
forms two-stage approaches under adversarial attacks, fur-
ther confirming the superiority of LaT-IB.
For the node classification task, it is evident that under
high noise conditions, our model significantly outperforms
other competitive baselines as shown in Table E.4 and E.5,
indicating the strong robustness of LaT-IB to label noise.
E.5
Analysis of Sample Selection Strategy
Our proposed sample selection strategy is based on two key
components: mutual information and divergence. Mutual in-
formation is indirectly measured through the cross-entropy
loss, whose effectiveness has been validated in numerous
prior works (Arpit et al. 2017; Song et al. 2019). As for
divergence, following Observation 4.2, we adopt Jensen-
Shannon (JS) divergence as a criterion to filter samples.
This section primarily investigates how divergence affects
the learning behavior of the encoder.
Figure E.4a shows the training process during the knowl-
edge injection stage on the CIFAR-10N (worst) dataset,
comparing the original method (sel all) with a variant
that excludes divergence-based selection (sel w/o div). Fig-
ure E.4b presents the final performance of both methods.
Experimental results demonstrate that removing divergence
leads to a larger accuracy gap between the two encoders but
ultimately worse performance. We attribute this to encoder
T failing to learn meaningful representations of noisy sam-
ples, rendering its predictions less informative. As a result, it
is unable to provide effective guidance for feature separation
in the third stage. These findings confirm that divergence-
based sample selection plays a critical role in training the
encoder effectively.
20
30
40
50
60
70
80
90 100
Epoch
10
20
30
40
50
60
70
80
Accuracy (%)
Acc S
Acc T
Acc S (w/o div)
Acc T (w/o div)
(a) Training Process of Knowl-
edge Injection
sel_all
sel_w/o div
Selection strategy
0
20
40
60
80
Accuracy (%)
(b) Training Accuracy under
Different Select Strategy.
Figure E.4: The influence of DJS
E.6
Hyperparameter Sensitivity Analysis of Î´ in
Algorithm B.2
In this section, we investigate the effect of the hyperparam-
eter Î´, which controls the amount of knowledge the encoder
(S, T) acquires during the Knowledge Injection phase. Fig-
ure E.5 illustrates the modelâ€™s performance on the Cora and
Citeseer datasets under various noise types and levels.
The results show that neither excessively high nor low val-
ues of Î´ yield optimal performance. We hypothesize that a
too-small Î´ limits the encoderâ€™s exposure to training data,
impairing its ability to learn useful representations. Con-
versely, a too-large Î´ causes the two encoders to converge in
their learning, reducing their ability to distinguish between
clean and noisy information effectively.
Furthermore, the influence of Î´ varies across datasets, in-
dicating that the modelâ€™s capacity to separate clean and noisy
information is dataset-dependent.
E.7
Analysis of Model Learning Behavior
To further investigate the learning behavior of the en-
coder, we perform a t-SNE dimensionality reduction anal-
ysis on the embeddings obtained from models trained on the
CIFAR-10N (worst) dataset. For a comprehensive compar-
ison, we analyze the embeddings under the following four
Method
Model
CIFAR-10
CIFAR-100
20%(sym)
50%(sym)
40%(asym)
20%(sym)
50%(sym)
Classic
IB
VIB
81.49Â±1.00
72.58Â±1.63
79.27Â±1.13
53.86Â±0.47
44.25Â±0.98
NIB
83.44Â±0.83
76.16Â±1.27
78.16Â±1.32
55.99Â±0.79
46.20Â±0.77
Robust
Loss
VIB (LGCE)
88.43Â±0.17
84.82Â±0.33
81.32Â±1.61
â€”
â€”
VIB (LSCE)
84.36Â±0.13
77.67Â±1.40
76.59Â±0.73
53.06Â±1.83
â€”
Improved
IB
SIB
86.40Â±0.55
65.52Â±1.53
80.06Â±1.52
57.64Â±1.92
35.01Â±1.23
DT-JSCC
84.51Â±0.41
72.49Â±0.77
80.95Â±0.41
49.58Â±0.13
35.80Â±0.96
Deniose
+ IB
JoCoR+VIB
88.71Â±0.18
81.71Â±0.21
60.66Â±0.08
62.61Â±0.27
53.69Â±0.11
(ELR+)+VIB
93.16Â±0.23
91.28Â±0.06
84.75Â±0.11
71.44Â±0.93
54.12Â±0.20
Promix+VIB
92.98Â±0.14
92.40Â±0.10
91.87Â±0.05
71.89Â±0.16
69.77Â±0.56
Ours
LaT-IB
94.56Â±0.12
91.13Â±0.16
88.89Â±0.73
75.79Â±0.19
67.28Â±0.55
Table E.3: Classification accuracy (%) of CIFAR under Symmetric/Asymmetric Noise. All the best results are highlighted in
bold, and the second-best results are underlined.
Method
Model
Clean
Uniform Noise
Pair Noise
10%
20%
30%
40%
10%
20%
30%
40%
ClassicIB
GIB
75.33Â±3.19
75.10Â±2.48
73.03Â±5.67
72.77Â±2.36
57.17Â±7.83
74.73Â±4.39
69.80Â±6.18
66.30Â±6.60
46.60Â±5.45
Robust
Loss
GIB (LGCE)
75.03Â±2.79
74.43Â±3.01
72.03Â±6.91
72.27Â±4.07
57.57Â±6.42
73.67Â±3.85
71.03Â±4.62
62.60Â±6.99
43.63Â±6.69
GIB (LSCE)
74.23Â±3.56
72.67Â±2.55
71.10Â±6.45
70.63Â±4.03
58.47Â±5.17
73.33Â±4.64
70.07Â±4.93
59.87Â±6.40
43.10Â±6.80
Improved
IB
CurvGIB
70.67Â±3.23
67.67Â±2.71
64.63Â±6.52
61.97Â±4.46
54.47Â±6.13
66.93Â±1.79
64.03Â±4.55
56.27Â±7.96
45.03Â±1.68
IS-GIB
54.73Â±0.15
53.17Â±1.48
42.93Â±2.46
45.53Â±0.79
38.77Â±6.34
49.73Â±0.82
46.97Â±1.19
40.33Â±3.64
38.80Â±1.22
Denoise
+ IB
RNCGLN+GIB
74.70Â±2.65
73.37Â±0.65
72.97Â±5.09
70.80Â±2.57
52.27Â±6.65
75.00Â±3.45
69.93Â±3.40
64.67Â±6.10
39.83Â±7.13
CGNN+GIB
73.17Â±1.86
69.37Â±6.01
67.67Â±5.28
67.70Â±1.85
54.70Â±5.06
66.53Â±5.74
64.80Â±6.16
52.00Â±5.40
44.33Â±4.74
Ours
LaT-IB
74.57Â±0.99
75.87Â±0.33
71.13Â±2.22
75.60Â±0.71
62.53Â±7.56
75.43Â±1.04
73.70Â±3.10
68.57Â±3.02
53.00Â±7.26
Table E.4: Classification accuracy (%) on the DBLP dataset under different noise types and noise rates. All the best results are
highlighted in bold, and the second-best results are underlined.
Method
Model
Cora
Citeseer
Uniform
Pair
Uniform
Pair
20%
40%
20%
40%
20%
40%
20%
40%
ClassicIB
GIB
75.37Â±2.47
71.60Â±1.51
73.73Â±0.39
65.27Â±3.84
60.00Â±3.37
48.20Â±2.20
57.50Â±2.35
43.67Â±2.90
Robust
Loss
GIB (LGCE)
74.77Â±0.76
70.47Â±2.25
75.00Â±1.77
65.27Â±2.52
60.20Â±3.93
50.80Â±2.14
58.73Â±2.31
41.03Â±1.25
GIB (LSCE)
74.40Â±0.45
69.17Â±1.09
75.97Â±2.02
66.73Â±4.08
58.83Â±5.19
50.93Â±0.84
59.10Â±3.61
41.40Â±1.35
Improved
IB
CurvGIB
65.90Â±3.69
52.63Â±3.23
67.17Â±2.11
52.00Â±3.19
49.80Â±4.19
46.20Â±1.69
48.77Â±2.09
38.70Â±3.70
IS-GIB
69.20Â±0.62
54.73Â±1.28
70.30Â±0.99
56.47Â±4.54
55.73Â±3.44
39.03Â±1.10
54.90Â±4.28
40.13Â±2.36
Denoise
+ IB
RNCGLN+GIB
74.53Â±1.58
71.67Â±1.49
73.57Â±1.59
63.60Â±3.40
60.90Â±2.95
52.83Â±4.82
55.77Â±3.17
46.00Â±3.01
CGNN+GIB
70.53Â±4.69
64.73Â±6.75
73.57Â±1.37
59.00Â±3.29
57.53Â±3.73
45.73Â±4.29
54.43Â±3.30
41.57Â±1.90
Ours
LaT-IB
74.30Â±2.01
74.07Â±1.46
76.87Â±1.06
66.80Â±3.14
61.63Â±2.24
55.17Â±3.86
58.93Â±2.77
46.00Â±0.71
Table E.5: Classification accuracy (%) on the Cora and Citeseer dataset under different noise types and noise rates. All the best
results are highlighted in bold, and the second-best results are underlined.
settings: â‘ VIB without the I(X; Z) constraint, which is
approximately equivalent to a standard ResNet34 model;
â‘¡Standard VIB model; â‘¢LaT-IB model at the end of
Knowledge Injection, referred to as LaT-IB KI; â‘£Full LaT-
IB model.
Figure E.6a and E.6b show that IB methods produce more
compact embeddings by minimizing I(X; Z), reducing the
encoding space and slightly lowering performance. Figure
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
45
50
55
60
65
70
75
Accuracy (%)
Cora (uniform 0.4)
Citeseer (uniform 0.4)
(a) Under 40% Uniform Noise
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
45
50
55
60
65
70
75
80
Accuracy (%)
Cora (pair 0.2)
Citeseer (pair 0.2)
(b) Under 20% Pair Noise
Figure E.5: The influence of Î´
E.6c and E.6d illustrate that the third robust training stage
of LaT-IB further restricts I(D; S, T) and improves noise
robustness. In particular, Figure E.6d shows embeddings
similar to IBâ€™s minimal sufficient property (Figure E.6b),
while clearer class boundaries demonstrate LaT-IBâ€™s ability
to learn cleaner representations.
100
75
50
25
0
25
50
75
75
50
25
0
25
50
75
100
(a) VIB w.o I(X; Z)
40
20
0
20
40
40
20
0
20
40
(b) VIB
30
20
10
0
10
20
30
40
20
0
20
40
(c) LaT-IB KI
40
30
20
10
0
10
20
30
40
30
20
10
0
10
20
30
40
(d) LaT-IB
Figure E.6: The embedding distributions of different models
To investigate the learning process of the two encoders S
and T, Figure E.7 shows their prediction accuracy on train-
ing and test sets with 40% uniform noise on the Cora dataset,
where vertical dashed lines divide the process into three pe-
riods. Encoder T gradually fits all (noisy) data, while S, in-
fluenced by T, achieves about 65% accuracy on the training
set by fitting mostly clean data.
E.8
Hyperparameter settings
Image Classification.
For CIFAR-related datasets, we set
the batch size to 256, and each image is reshaped to a size
of (32, 32). For the Animal-10N dataset, the batch size is set
0
20
40
60
80
100
Epoch
0
20
40
60
80
100
Accuracy (%)
Cora Train Acc (S)
Cora Test Acc (S)
Cora Train Acc (T)
Cora Test Acc (T)
Figure E.7: The learning behavior of (S, T)
to 128, and each image is reshaped to (68, 68). We use SGD
as the optimizer with a learning rate of 0.005, momentum
of 0.9, and a weight decay of 5e-4. A cosine learning rate
scheduler is applied.
The dimension of the encoderâ€™s latent space is set to 128.
Each experiment is repeated three times, and we report the
mean and standard deviation of the results.
Node Classification.
For node classification tasks, we use
the Adam optimizer with a learning rate of 0.001. To en-
able the computation of structural KL divergence, the model
backbone is configured as a two-layer GAT. In our hyperpa-
rameter settings, the KL divergence weight for the features
is set to 0.001, and the weight for the structural KL diver-
gence is set to 0.01. The dimension of the encoderâ€™s latent
space is set to 16 or 20. Each experiment is repeated three
times, and we report the mean and standard deviation of the
results.
In the experiments, the Algorithm B.2 uses Î´
âˆˆ
{0.1, 0.2, Â· Â· Â· , 0.9}. Besides, we set Î² âˆˆ{1eâˆ’1, Â· Â· Â· , 1eâˆ’5}
and Î³ =âˆˆ{1e0, Â· Â· Â· , 1eâˆ’4} in our hyperparameter configu-
ration. The predicted confidence scores are set based on the
learning behavior of Warmup samples for each dataset, en-
suring that the upper confidence bound is greater than 0.5,
while the lower confidence bound is less than 0.5.
E.9
Hardware and Software Configurations
We conduct the experiments with:
â€¢ Operating System: Ubuntu 22.04.4 LTS.
â€¢ CPU: Intel(R) Xeon(R) Silver 4110 CPU @ 2.10GHz.
â€¢ GPU: NVIDIA Tesla V100 SMX2 with 32GB of Mem-
ory.
â€¢ Software: CUDA 12.8, Python 3.10.12, PyTorch8 2.2.0,
PyTorch Geometric9 2.6.1.
8https://github.com/pytorch/pytorch
9https://github.com/pyg-team/pytorch geometric

