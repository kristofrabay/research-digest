# MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search

**URL:** https://arxiv.org/abs/2503.20757
**Published:** 2025-03-26T00:00:00.000Z

---

## Summary

The webpage describes **MCTS-RAG**, a novel approach that enhances the reasoning capabilities of small language models (LMs) on knowledge-intensive tasks by combining **Retrieval-Augmented Generation (RAG)** with **Monte Carlo Tree Search (MCTS)**.

Key points related to your query:

*   **Reasoning LLMs & Planning with LLMs:** MCTS-RAG enhances reasoning by using MCTS to refine reasoning paths through an iterative decision-making process, integrating structured reasoning with adaptive retrieval.
*   **MCTS (Monte Carlo Tree Search) for language models:** The core of the method is leveraging MCTS to guide the integration of retrieval and reasoning.
*   **Inference-time compute:** The method achieves performance comparable to frontier LLMs like GPT-4o by effectively scaling inference-time compute.
*   **Hallucination reduction and detection & Grounding, factuality:** MCTS-RAG is shown to reduce hallucinations and ensure improved factual accuracy and response consistency by dynamically integrating retrieval and reasoning, unlike standard RAG or MCTS methods that rely solely on internal knowledge.

The paper focuses on improving reasoning and factuality in LMs using MCTS and RAG.

---

## Full Content

# Computer Science > Computation and Language

**arXiv:2503.20757** (cs)

\[Submitted on 26 Mar 2025\]

# Title:MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search

Authors: [Yunhai Hu](https://arxiv.org/search/cs?searchtype=author&query=Hu,+Y), [Yilun Zhao](https://arxiv.org/search/cs?searchtype=author&query=Zhao,+Y), [Chen Zhao](https://arxiv.org/search/cs?searchtype=author&query=Zhao,+C), [Arman Cohan](https://arxiv.org/search/cs?searchtype=author&query=Cohan,+A)

View a PDF of the paper titled MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search, by Yunhai Hu and 3 other authors

[View PDF](https://arxiv.org/pdf/2503.20757) [HTML (experimental)](https://arxiv.org/html/2503.20757v1)

> Abstract:We introduce MCTS-RAG, a novel approach that enhances the reasoning capabilities of small language models on knowledge-intensive tasks by leveraging retrieval-augmented generation (RAG) to provide relevant context and Monte Carlo Tree Search (MCTS) to refine reasoning paths. MCTS-RAG dynamically integrates retrieval and reasoning through an iterative decision-making process. Unlike standard RAG methods, which typically retrieve information independently from reasoning and thus integrate knowledge suboptimally, or conventional MCTS reasoning, which depends solely on internal model knowledge without external facts, MCTS-RAG combines structured reasoning with adaptive retrieval. This integrated approach enhances decision-making, reduces hallucinations, and ensures improved factual accuracy and response consistency. The experimental results on multiple reasoning and knowledge-intensive datasets datasets (i.e., ComplexWebQA, GPQA, and FoolMeTwice) show that our method enables small-scale LMs to achieve performance comparable to frontier LLMs like GPT-4o by effectively scaling inference-time compute, setting a new standard for reasoning in small-scale models.

| | |
| --- | --- |
| Subjects: | Computation and Language (cs.CL) |
| Cite as: | [arXiv:2503.20757](https://arxiv.org/abs/2503.20757) \[cs.CL\] |
| | (or [arXiv:2503.20757v1](https://arxiv.org/abs/2503.20757v1) \[cs.CL\] for this version) |
| | [https://doi.org/10.48550/arXiv.2503.20757](https://doi.org/10.48550/arXiv.2503.20757) Focus to learn more arXiv-issued DOI via DataCite (pending registration) |

## Submission history

From: Yunhai Hu Mr. \[ [view email](https://arxiv.org/show-email/3a2c0b45/2503.20757)\]

**\[v1\]**
Wed, 26 Mar 2025 17:46:08 UTC (10,474 KB)

Full-text links:

## Access Paper:

View a PDF of the paper titled MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search, by Yunhai Hu and 3 other authors

- [View PDF](https://arxiv.org/pdf/2503.20757)
- [HTML (experimental)](https://arxiv.org/html/2503.20757v1)
- [TeX Source](https://arxiv.org/src/2503.20757)
- [Other Formats](https://arxiv.org/format/2503.20757)

[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)

Current browse context:

cs.CL

[< prev](https://arxiv.org/prevnext?id=2503.20757&function=prev&context=cs.CL)  \|  [next >](https://arxiv.org/prevnext?id=2503.20757&function=next&context=cs.CL)

[new](https://arxiv.org/list/cs.CL/new) \| [recent](https://arxiv.org/list/cs.CL/recent) \| [2025-03](https://arxiv.org/list/cs.CL/2025-03)

Change to browse by:

[cs](https://arxiv.org/abs/2503.20757?context=cs)

### References & Citations

- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2503.20757)
- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2503.20757)
- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2503.20757)

[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...

## BibTeX formatted citation

×

Data provided by:

### Bookmark

[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2503.20757&description=MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2503.20757&title=MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree Search)

Bibliographic Tools

# Bibliographic and Citation Tools

Bibliographic Explorer Toggle

Bibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_

Connected Papers Toggle

Connected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_

Litmaps Toggle

Litmaps _( [What is Litmaps?](https://www.litmaps.co/))_

scite.ai Toggle

scite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_

Code, Data, Media

# Code, Data and Media Associated with this Article

alphaXiv Toggle

alphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_

Links to Code Toggle

CatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_

DagsHub Toggle

DagsHub _( [What is DagsHub?](https://dagshub.com/))_

GotitPub Toggle

Gotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_

Huggingface Toggle

Hugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_

Links to Code Toggle

Papers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_

ScienceCast Toggle

ScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_

Demos

# Demos

Replicate Toggle

Replicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_

Spaces Toggle

Hugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_

Spaces Toggle

TXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_

Related Papers

# Recommenders and Search Tools

Link to Influence Flower

Influence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_

Core recommender toggle

CORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_

- Author
- Venue
- Institution
- Topic

About arXivLabs

# arXivLabs: experimental projects with community collaborators

arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.

Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.

Have an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).

[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2503.20757) \|
[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))
