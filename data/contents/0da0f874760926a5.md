# OpenAI SDK compatibility

**URL:** https://docs.anthropic.com/en/api/openai-sdk
**Published:** 2023-12-21T00:00:00.000Z

---

## Summary

The webpage describes **OpenAI SDK compatibility** with the Anthropic Claude API, which allows users to test Claude capabilities using the OpenAI SDK with minor code adjustments (changing the base URL, API key, and model name).

Key points relevant to your query:

*   **Tool Use/Function Calling:** The `strict` parameter for function calling is **ignored**, meaning tool use JSON is not guaranteed to follow the supplied schema. For guaranteed schema conformance, the native Claude API with **Structured Outputs** is recommended.
*   **Agent Memory/Agent Frameworks/Orchestration:** The page does not discuss general agent infrastructure components like MCP servers, agent memory, agentic memory, agent frameworks (LangChain, LlamaIndex), or orchestration tools beyond the specific compatibility layer for SDKs.
*   **SDKs Mentioned:** It focuses on using the **OpenAI SDK** to interface with Claude. It recommends the native **Claude API** for full feature access (including PDF processing, citations, extended thinking, and prompt caching).
*   **Structured Outputs:** Mentioned as the solution for guaranteed JSON output conformance, contrasting with the ignored `response_format` field when using the OpenAI SDK compatibility layer.

**Summary in relation to your query:**

The page details how to use the **OpenAI SDK** to interface with the Claude API via a compatibility layer. It specifically notes that **tool use** (function calling) is supported but the `strict` parameter is ignored, recommending **Structured Outputs** via the native Claude API for guaranteed schema conformance. It does **not** provide information on **MCP servers, agent memory, agentic memory, agent frameworks (LangChain, LlamaIndex), OpenAI Agents SDK, Anthropic Agents SDK, Google SDK, or agent orchestration** beyond the basic SDK compatibility setup.

---

## Full Content

OpenAI SDK compatibility - Claude Docs
Loading...
[](https://docs.anthropic.com/docs/en/home)
English
[Log in](https://docs.anthropic.com/login?returnTo=/docs/en/api/openai-sdk)
Search...
⌘K
Using the API
[Features overview](https://docs.anthropic.com/docs/en/api/overview)[Client SDKs](https://docs.anthropic.com/docs/en/api/client-sdks)[Beta headers](https://docs.anthropic.com/docs/en/api/beta-headers)[Errors](https://docs.anthropic.com/docs/en/api/errors)
[
Messages
](https://docs.anthropic.com/docs/en/api/messages)
[
Create a Message
](https://docs.anthropic.com/docs/en/api/messages/create)[
Count tokens in a Message
](https://docs.anthropic.com/docs/en/api/messages/count_tokens)
Batches
[
Models
](https://docs.anthropic.com/docs/en/api/models)
[
List Models
](https://docs.anthropic.com/docs/en/api/models/list)[
Get a Model
](https://docs.anthropic.com/docs/en/api/models/retrieve)
[
Beta
](https://docs.anthropic.com/docs/en/api/beta)
Models
Messages
Files
Skills
[
Admin
](https://docs.anthropic.com/docs/en/api/admin)
Organizations
Invites
Users
Workspaces
API Keys
Usage Report
Cost Report
[
Completions
](https://docs.anthropic.com/docs/en/api/completions)
[
Create a Text Completion
](https://docs.anthropic.com/docs/en/api/completions/create)
Support &amp; configuration
[Rate limits](https://docs.anthropic.com/docs/en/api/rate-limits)[Service tiers](https://docs.anthropic.com/docs/en/api/service-tiers)[Versions](https://docs.anthropic.com/docs/en/api/versioning)[IP addresses](https://docs.anthropic.com/docs/en/api/ip-addresses)[Supported regions](https://docs.anthropic.com/docs/en/api/supported-regions)[OpenAI SDK compatibility](https://docs.anthropic.com/docs/en/api/openai-sdk)
[
Console
](https://docs.anthropic.com/)
[
Log in
](https://docs.anthropic.com/login)
Support &amp; configuration
OpenAI SDK compatibility
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Loading...
Support &amp; configuration
# OpenAI SDK compatibility
Copy page
Anthropic provides a compatibility layer that enables you to use the OpenAI SDK to test the Claude API. With a few code changes, you can quickly evaluate Anthropic model capabilities.
Copy page
This compatibility layer is primarily intended to test and compare model capabilities, and is not considered a long-term or production-ready solution for most use cases. While we do intend to keep it fully functional and not make breaking changes, our priority is the reliability and effectiveness of the[Claude API](https://docs.anthropic.com/docs/en/api/overview).
For more information on known compatibility limitations, see[Important OpenAI compatibility limitations](#important-openai-compatibility-limitations).
If you encounter any issues with the OpenAI SDK compatibility feature, please let us know[here](https://forms.gle/oQV4McQNiuuNbz9n8).
For the best experience and access to Claude API full feature set ([PDF processing](https://docs.anthropic.com/docs/en/build-with-claude/pdf-support),[citations](https://docs.anthropic.com/docs/en/build-with-claude/citations),[extended thinking](https://docs.anthropic.com/docs/en/build-with-claude/extended-thinking), and[prompt caching](https://docs.anthropic.com/docs/en/build-with-claude/prompt-caching)), we recommend using the native[Claude API](https://docs.anthropic.com/docs/en/api/overview).
## Getting started with the OpenAI SDK
To use the OpenAI SDK compatibility feature, you&#x27;ll need to:
1. Use an official OpenAI SDK
2. Change the following
* Update your base URL to point to the Claude API
* Replace your API key with an[Claude API key](https://docs.anthropic.com/settings/keys)
* Update your model name to use a[Claude model](https://docs.anthropic.com/docs/en/about-claude/models/overview)
* Review the documentation below for what features are supported### Quick start example
Python
```
`fromopenaiimportOpenAIclient=OpenAI(api\_key="ANTHROPIC\_API\_KEY",# Your Claude API keybase\_url="https://api.anthropic.com/v1/"# the Claude API endpoint)response=client.chat.completions.create(model="claude-sonnet-4-5",# Anthropic model namemessages=[{"role":"system","content":"You are a helpful assistant."},{"role":"user","content":"Who are you?"}],)print(response.choices[0].message.content)`
```
## Important OpenAI compatibility limitations
#### API behavior
Here are the most substantial differences from using OpenAI:
* The`strict`parameter for function calling is ignored, which means the tool use JSON is not guaranteed to follow the supplied schema. For guaranteed schema conformance, use the native[Claude API with Structured Outputs](https://docs.anthropic.com/docs/en/build-with-claude/structured-outputs).
* Audio input is not supported; it will simply be ignored and stripped from input
* Prompt caching is not supported, but it is supported in[the Anthropic SDK](https://docs.anthropic.com/docs/en/api/client-sdks)
* System/developer messages are hoisted and concatenated to the beginning of the conversation, as Anthropic only supports a single initial system message.
Most unsupported fields are silently ignored rather than producing errors. These are all documented below.
#### Output quality considerations
If you’ve done lots of tweaking to your prompt, it’s likely to be well-tuned to OpenAI specifically. Consider using our[prompt improver in the Claude Console](https://docs.anthropic.com/dashboard)as a good starting point.
#### System / Developer message hoisting
Most of the inputs to the OpenAI SDK clearly map directly to Anthropic’s API parameters, but one distinct difference is the handling of system / developer prompts. These two prompts can be put throughout a chat conversation via OpenAI. Since Anthropic only supports an initial system message, we take all system/developer messages and concatenate them together with a single newline (`\\n`) in between them. This full string is then supplied as a single system message at the start of the messages.
#### Extended thinking support
You can enable[extended thinking](https://docs.anthropic.com/docs/en/build-with-claude/extended-thinking)capabilities by adding the`thinking`parameter. While this will improve Claude&#x27;s reasoning for complex tasks, the OpenAI SDK won&#x27;t return Claude&#x27;s detailed thought process. For full extended thinking features, including access to Claude&#x27;s step-by-step reasoning output, use the native Claude API.
Python
```
`response=client.chat.completions.create(model="claude-sonnet-4-5",messages=...,extra\_body={"thinking": {"type":"enabled","budget\_tokens":2000}})`
```
## Rate limits
Rate limits follow Anthropic&#x27;s[standard limits](https://docs.anthropic.com/docs/en/api/rate-limits)for the`/v1/messages`endpoint.
## Detailed OpenAI Compatible API Support
### Request fields
#### Simple fields
|Field|Support status|
`model`|Use Claude model names|
`max\_tokens`|Fully supported|
`max\_completion\_tokens`|Fully supported|
`stream`|Fully supported|
`stream\_options`|Fully supported|
`top\_p`|Fully supported|
`parallel\_tool\_calls`|Fully supported|
`stop`|All non-whitespace stop sequences work|
`temperature`|Between 0 and 1 (inclusive). Values greater than 1 are capped at 1.|
`n`|Must be exactly 1|
`logprobs`|Ignored|
`metadata`|Ignored|
`response\_format`|Ignored. For JSON output, use[Structured Outputs](https://docs.anthropic.com/docs/en/build-with-claude/structured-outputs)with the native Claude API|
`prediction`|Ignored|
`presence\_penalty`|Ignored|
`frequency\_penalty`|Ignored|
`seed`|Ignored|
`service\_tier`|Ignored|
`audio`|Ignored|
`logit\_bias`|Ignored|
`store`|Ignored|
`user`|Ignored|
`modalities`|Ignored|
`top\_logprobs`|Ignored|
`reasoning\_effort`|Ignored|
#### `tools`/`functions`fields
### Show fields
#### `messages`array fields
### Show fields
### Response fields
|Field|Support status|
`id`|Fully supported|
`choices[]`|Will always have a length of 1|
`choices[].finish\_reason`|Fully supported|
`choices[].index`|Fully supported|
`choices[].message.role`|Fully supported|
`choices[].message.content`|Fully supported|
`choices[].message.tool\_calls`|Fully supported|
`object`|Fully supported|
`created`|Fully supported|
`model`|Fully supported|
`finish\_reason`|Fully supported|
`content`|Fully supported|
`usage.completion\_tokens`|Fully supported|
`usage.prompt\_tokens`|Fully supported|
`usage.total\_tokens`|Fully supported|
`usage.completion\_tokens\_details`|Always empty|
`usage.prompt\_tokens\_details`|Always empty|
`choices[].message.refusal`|Always empty|
`choices[].message.audio`|Always empty|
`logprobs`|Always empty|
`service\_tier`|Always empty|
`system\_fingerprint`|Always empty|
### Error message compatibility
The compatibility layer maintains consistent error formats with the OpenAI API. However, the detailed error messages will not be equivalent. We recommend only using the error messages for logging and debugging.
### Header compatibility
While the OpenAI SDK automatically manages headers, here is the complete list of headers supported by the Claude API for developers who need to work with them directly.
|Header|Support Status|
`x-ratelimit-limit-requests`|Fully supported|
`x-ratelimit-limit-tokens`|Fully supported|
`x-ratelimit-remaining-requests`|Fully supported|
`x-ratelimit-remaining-tokens`|Fully supported|
`x-ratelimit-reset-requests`|Fully supported|
`x-ratelimit-reset-tokens`|Fully supported|
`retry-after`|Fully supported|
`request-id`|Fully supported|
`openai-version`|Always`2020-10-01`|
`authorization`|Fully supported|
`openai-processing-ms`|Always empty|
