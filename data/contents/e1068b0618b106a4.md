# Chain-of-Thought (CoT) in Large Language Models: Introduction and Applications

**URL:** https://medium.com/@myschang/chain-of-thought-cot-in-large-language-models-introduction-and-applications-910363d82431
**Published:** 2023-04-26T05:31:09.000Z

---

## Summary

The provided webpage focuses on **Chain-of-Thought (CoT)** in Large Language Models (LLMs) as a technique to enhance their **reasoning ability**.

Key points related to your query include:

*   **Reasoning LLMs:** The text highlights that sufficiently large LLMs exhibit "emerging abilities" like human-like reasoning, allowing them to break down complex tasks.
*   **Chain-of-Thought (CoT):** This is the central topic, described as a method to "excite the reasoning ability of LLMs" by providing reasoning examples (Few-shot CoT) or simple prompts like "Let’s think step by step" (Zero-shot CoT), enabling models to generate explicit reasoning steps.
*   **Planning with LLMs:** The reasoning ability of LLMs is noted as being applicable as a "planer or decomposer in many downstream tasks." An example is given where an LLM is prompted to suggest possible goals for an RL agent (ELLM method).

The page **does not explicitly discuss** the following terms from your query: *inference-time compute, self-reflection, MCTS (Monte Carlo Tree Search) for language models, test-time scaling, hallucination reduction and detection, grounding, or factuality*.

---

## Full Content

Chain-of-Thought (CoT) in Large Language Models: Introduction and Applications | by Michael X | Medium
[Sitemap](https://medium.com/sitemap/sitemap.xml)
[Open in app](https://rsci.app.link/?$canonical_url=https://medium.com/p/910363d82431&amp;~feature=LoOpenInAppButton&amp;~channel=ShowPostUnderUser&amp;~stage=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)
Sign up
[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@myschang/chain-of-thought-cot-in-large-language-models-introduction-and-applications-910363d82431&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)
[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)
[
Write
](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)
[
Search
](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)
Sign up
[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@myschang/chain-of-thought-cot-in-large-language-models-introduction-and-applications-910363d82431&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)
![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)
# Chain-of-Thought (CoT) in Large Language Models: Introduction and Applications
[
![Michael X](https://miro.medium.com/v2/resize:fill:64:64/1*sLyhAgQPOBuyMe8evUmymA.jpeg)
](https://medium.com/@myschang?source=post_page---byline--910363d82431---------------------------------------)
[Michael X](https://medium.com/@myschang?source=post_page---byline--910363d82431---------------------------------------)
6 min read
·Apr 26, 2023
[
](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/910363d82431&amp;operation=register&amp;redirect=https://medium.com/@myschang/chain-of-thought-cot-in-large-language-models-introduction-and-applications-910363d82431&amp;user=Michael+X&amp;userId=1ebc4afb2861&amp;source=---header_actions--910363d82431---------------------clap_footer------------------)
--
[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/910363d82431&amp;operation=register&amp;redirect=https://medium.com/@myschang/chain-of-thought-cot-in-large-language-models-introduction-and-applications-910363d82431&amp;source=---header_actions--910363d82431---------------------bookmark_footer------------------)
Listen
Share
## Abstract
In recent years, Large Language Models (LLM) have made significant progress in the fields of natural language processing, such as GPT-3 and Chat-GPT. These models, trained on large datasets, demonstrate the ability to reason like humans. This paper provides a review of recent progress in Chain-of-Thought (CoT), a technique to excite the reasoning ability of LLMs. The basics of Chain-of-Thought and their applications will be discussed, as well as related methods.
## Introduction
In recent years, the advancements in large language models (LLMs) have been remarkable, mainly due to their capacity to utilize vast amounts of data and advanced transformer architecture. As shown in Figure 1, there has been a tremendous growth in the size of LLMs over the past three years, which is measured by the number of parameters in the model. The number of parameters indicates the size of the matrix that represents each word in an LLM. The more parameters, the greater the model’s understanding of the nuanced meaning and context of each word. Although parameters do not provide a complete picture of the model’s performance, they are closely correlated with performance within a specific model family.
Press enter or click to view image in full size
![]()
Figure 1 Size of language model
What’s particularly noteworthy is that as LLMs become large enough, they exhibit “emerging abilities” that were previously unattainable with smaller models. One of the most compelling of these emerging abilities is their capacity for human-like reasoning. This means that LLMs can effectively break down complex tasks into smaller, more manageable sub-tasks, or even provide step-by-step reasoning processes that mimic human thought processes.
This remarkable feature of LLMs has opened up new horizons for research and innovation in numerous fields, including natural language processing, machine learning, and artificial intelligence. Already, the reasoning abilities of LLMs have shown immense promise in a variety of applications, such as question answering, language translation, and text summarization. For instance, LLMs can help answer complex questions by breaking them down into smaller, more manageable components and then providing coherent, accurate answers. Additionally, in language translation tasks, LLMs can identify subtle nuances in meaning and accurately convey them across different languages. All of these developments are paving the way for a more sophisticated and nuanced understanding of language and human reasoning, with countless potential applications across a wide range of industries and sectors.
Press enter or click to view image in full size
![]()
Figure2 Few-shot CoT
Compare with traditional methods that only put few-shot examples in the prompts, Chain-of-thought methods provide a more natural way of prompting LLMs to reason through complex problems. Traditional methods often involve providing the model with a few-shot example to prompt a response, which can be limiting in terms of the complexity of problems that the model can solve. Chain-of-thought methods, on the other hand, allow the model to reason through a series of examples, building upon the information provided in each step to arrive at a final answer. This approach enables LLMs to perform tasks that were previously considered too challenging for artificial intelligence systems, such as solving complex math problems or generating detailed explanations for scientific phenomena. With the ability to reason through complex problems, LLMs have the potential to revolutionize many fields, including education, healthcare, and scientific research. However, there is still much work to be done to improve the accuracy and reliability of these models, and researchers are actively working to address these challenges.
As an illustration, when large language models (LLMs) are provided with a “chain of thoughts,” which consists of reasoning examples as in Figure 2, or even a simple prompt such as “Let’s think step by step,” as in Figure 3, they can generate responses that explicitly outline the reasoning steps taken to arrive at an answer. For example, if an LLM is asked to answer the question “Why is the sky blue? Let’s think step by step!”, the model might generate an explanation like “The sun emits light in all colors, but the atmosphere scatters shorter blue wavelengths more than longer red wavelengths. This is why we see the sky as blue during the day.” This kind of reasoning is a hallmark of human intelligence, and the fact that LLMs can now perform similar tasks represents a significant breakthrough in artificial intelligence research. This newfound ability has generated considerable excitement within the research community, as reasoning is often viewed as a key feature of human intelligence that is currently lacking in many artificial intelligence systems.
Press enter or click to view image in full size
![]()
Figure 3 Zero-shot CoT## Applications
The reasoning ability of LLMs is a powerful tool that can be applied as a planer or decomposer in many downstream tasks. By breaking down complex problems into a series of smaller, more manageable steps, LLMs can help streamline the decision-making process and provide more accurate and nuanced results.
For example, ELLM[3], a new intrinsically motivated RL method, leverages the knowledge from text corpora to prompt an LLM to suggest possible goals given an agent’s current context, which encourages exploration biased towards completing goals that are diverse, context-sensitive, and human-meaningful. As shown in Figure 4, this novel approach to exploration has been shown to yield meaningful exploratory rewards in two challenging domains: Crafter, an open-ended environment with a large state-action space, and Housekeep, an embodied manipulation environment. The ELLM-trained agents exhibited better coverage of useful behaviors during pretraining, and they outperformed or matched baselines when fine-tuned on downstream tasks. This indicates that ELLM is a promising method for improving the efficiency and effectiveness of RL agents, particularly in environments where hand-defining reward functions would require significant engineering efforts. By tapping into the rich information encoded in LLMs, this paper expand the scope of what RL agents can learn and achieve, bringing us closer to more human-like intelligent behavior.
Press enter or click to view image in full size
![]()
Figure 4 ELLM
For another, one of the key advantages of using language as an internal representation for visual recognition is that it allows for greater flexibility in how query the model. Instead of being limited to the standard zero-shot classification method, where the model computes similarity between the query image and the embedded words for each category, we can ask the model to check for specific features or attributes that are important for identifying the object in question. This allows us to provide additional cues to the model that encourage it to look at the specific features, making the decision-making process more transparent and interpretable.
However, manually specifying the relevant features or attributes for each object can be time-consuming and difficult to scale to large numbers of classes. To overcome this challenge, the authors of [4] propose a novel approach that leverages the knowledge contained in large language models (LLMs) such as GPT-3. These models can be thought of as implicit knowledge bases that condense the collective knowledge of the internet, including knowledge of visual descriptors. By querying an LLM with natural language, the model can provide descriptions of the features that are most relevant for identifying a particular object, much like a child asking their parent what something looks like. This approach is not only more efficient than manually specifying features, but it also allows for greater coverage of objects and features, since LLMs have access to a vast corpus of information.
The authors demonstrate the effectiveness of their approach on several datasets, achieving a significant increase in accuracy on top-1 ImageNet accuracy, even in the face of distribution shifts. Importantly, the approach also provides a clear understanding of the model’s reasoning process, making it more transparent and interpretable for human users. Overall, the use of language as an internal representation for visual recognition has the potential to revolutionize machine learning and computer vision, by providing a more flexible, efficient, and interpretable way of identifying and classifying objects in images.
Press enter or click to view image in full size
![]()
Figure 5 Visual Classification with LLM
（TO BE CONTINUED）
[
Large Language Models
](https://medium.com/tag/large-language-models?source=post_page-----910363d82431---------------------------------------)
[
Gpt 4
](https://medium.com/tag/gpt-4?source=post_page-----910363d82431---------------------------------------)
[
Chain Of Thought
](https://medium.com/tag/chain-of-thought?source=post_page-----910363d82431---------------------------------------)
[
![Michael X](https://miro.medium.com/v2/resize:fill:96:96/1*sLyhAgQPOBuyMe8evUmymA.jpeg)
](https://medium.com/@myschang?source=post_page---post_author_info--910363d82431---------------------------------------)
[
![Michael X](https://miro.medium.com/v2/resize:fill:128:128/1*sLyhAgQPOBuyMe8evUmymA.jpeg)
](https://medium.com/@myschang?source=post_page---post_author_info--910363d82431---------------------------------------)
[## Written byMichael X
](https://medium.com/@myschang?source=post_page---post_author_info--910363d82431---------------------------------------)
[264 followers](https://medium.com/@myschang/followers?source=post_page---post_author_info--910363d82431---------------------------------------)
·[19 following](https://medium.com/@myschang/following?source=post_page---post_author_info--910363d82431---------------------------------------)
Co-Founder of[maadaa.ai](http://maadaa.ai)| Data-Centric AI | Open Innovation[https://www.linkedin.com/in/michael-zhang-36400a14/](https://www.linkedin.com/in/michael-zhang-36400a14/)
## No responses yet
[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--910363d82431---------------------------------------)
[
Help
](https://help.medium.com/hc/en-us?source=post_page-----910363d82431---------------------------------------)
[
Status
](https://status.medium.com/?source=post_page-----910363d82431---------------------------------------)
[
About
](https://medium.com/about?autoplay=1&amp;source=post_page-----910363d82431---------------------------------------)
[
Careers
](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----910363d82431---------------------------------------)
[
Press
](mailto:pressinquiries@medium.com)
[
Blog
](https://blog.medium.com/?source=post_page-----910363d82431---------------------------------------)
[
Privacy
](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----910363d82431---------------------------------------)
[
Rules
](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----910363d82431---------------------------------------)
[
Terms
](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----910363d82431---------------------------------------)
[
Text to speech
](https://speechify.com/medium?source=post_page-----910363d82431---------------------------------------)
