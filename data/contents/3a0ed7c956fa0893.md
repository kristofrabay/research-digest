# Agents - OpenAI Agents SDK

**URL:** https://openai.github.io/openai-agents-python/agents/
**Published:** 2011-06-09T00:00:00.000Z

---

## Summary

The provided web page details the **OpenAI Agents SDK**, focusing on the core building block: the **Agent**.

Here is a summary of the concepts mentioned in your query that are covered by the page:

*   **Agent Frameworks/SDKs:** The page describes the **OpenAI Agents SDK** itself.
*   **Agent Configuration:** Agents are configured with a `name`, `instructions` (system prompt), `model`, and **`tools`**.
*   **Tool Use/Function Calling:** Agents can be equipped with tools (defined via `@function_tool`). The page discusses how to force tool use using the `tool_choice` setting (options include `auto`, `required`, or specifying a tool name).
*   **Structured Outputs:** Agents can be configured to produce specific output types using the `output_type` parameter, which leverages Pydantic objects and forces the model to use **structured outputs** instead of plain text.
*   **Agent Orchestration (Multi-agent systems):** Two design patterns are described:
    1.  **Manager (agents as tools):** A central agent invokes specialized sub-agents exposed as tools.
    2.  **Handoffs:** Peer agents delegate control to a specialized agent that takes over the conversation.
*   **Agent Memory/Context:** The concept of **`context`** is introduced as a dependency-injection tool that serves as a "grab bag of dependencies and state for the agent run," passed to every agent, tool, and handoff.

**Concepts from your query *not* explicitly detailed or named in the text:**

*   MCP servers
*   Agent memory (though context serves as state)
*   Agentic memory
*   LangChain
*   LlamaIndex
*   Anthropic Agents SDK
*   Google SDK

**Summary:**

The OpenAI Agents SDK defines an Agent as an LLM configured with instructions and tools. It supports **tool use** (function calling) and **structured outputs** via Pydantic models. Multi-agent systems can be designed using **manager/orchestration** patterns or **handoffs**. Agents maintain state and dependencies through a configurable **context** object.

---

## Full Content

Agents - OpenAI Agents SDK
[Skip to content](#agents)
# Agents
Agents are the core building block in your apps. An agent is a large language model (LLM), configured with instructions and tools.
## Basic configuration
The most common properties of an agent you'll configure are:
* `name`: A required string that identifies your agent.
* `instructions`: also known as a developer message or system prompt.
* `model`: which LLM to use, and optional`model\_settings`to configure model tuning parameters like temperature, top\_p, etc.
* `tools`: Tools that the agent can use to achieve its tasks.
```
`[](#__codelineno-0-1)fromagentsimportAgent,ModelSettings,function\_tool[](#__codelineno-0-2)[](#__codelineno-0-3)@function\_tool[](#__codelineno-0-4)defget\_weather(city:str)-&gt;str:[](#__codelineno-0-5)&quot;&quot;&quot;returns weather info for the specified city.&quot;&quot;&quot;[](#__codelineno-0-6)returnf&quot;The weather in{city}is sunny&quot;[](#__codelineno-0-7)[](#__codelineno-0-8)agent=Agent([](#__codelineno-0-9)name=&quot;Haiku agent&quot;,[](#__codelineno-0-10)instructions=&quot;Always respond in haiku form&quot;,[](#__codelineno-0-11)model=&quot;gpt-5-nano&quot;,[](#__codelineno-0-12)tools=[get\_weather],[](#__codelineno-0-13))`
```
## Context
Agents are generic on their`context`type. Context is a dependency-injection tool: it's an object you create and pass to`Runner.run()`, that is passed to every agent, tool, handoff etc, and it serves as a grab bag of dependencies and state for the agent run. You can provide any Python object as the context.
```
`[](#__codelineno-1-1)@dataclass[](#__codelineno-1-2)classUserContext:[](#__codelineno-1-3)name:str[](#__codelineno-1-4)uid:str[](#__codelineno-1-5)is\_pro\_user:bool[](#__codelineno-1-6)[](#__codelineno-1-7)asyncdeffetch\_purchases()-&gt;list[Purchase]:[](#__codelineno-1-8)return...[](#__codelineno-1-9)[](#__codelineno-1-10)agent=Agent[UserContext]([](#__codelineno-1-11)...,[](#__codelineno-1-12))`
```
## Output types
By default, agents produce plain text (i.e.`str`) outputs. If you want the agent to produce a particular type of output, you can use the`output\_type`parameter. A common choice is to use[Pydantic](https://docs.pydantic.dev/)objects, but we support any type that can be wrapped in a Pydantic[TypeAdapter](https://docs.pydantic.dev/latest/api/type_adapter/)- dataclasses, lists, TypedDict, etc.
```
`[](#__codelineno-2-1)frompydanticimportBaseModel[](#__codelineno-2-2)fromagentsimportAgent[](#__codelineno-2-3)[](#__codelineno-2-4)[](#__codelineno-2-5)classCalendarEvent(BaseModel):[](#__codelineno-2-6)name:str[](#__codelineno-2-7)date:str[](#__codelineno-2-8)participants:list[str][](#__codelineno-2-9)[](#__codelineno-2-10)agent=Agent([](#__codelineno-2-11)name=&quot;Calendar extractor&quot;,[](#__codelineno-2-12)instructions=&quot;Extract calendar events from text&quot;,[](#__codelineno-2-13)output\_type=CalendarEvent,[](#__codelineno-2-14))`
```
Note
When you pass an`output\_type`, that tells the model to use[structured outputs](https://platform.openai.com/docs/guides/structured-outputs)instead of regular plain text responses.
## Multi-agent system design patterns
There are many ways to design multi‑agent systems, but we commonly see two broadly applicable patterns:
1. Manager (agents as tools): A central manager/orchestrator invokes specialized sub‑agents as tools and retains control of the conversation.
2. Handoffs: Peer agents hand off control to a specialized agent that takes over the conversation. This is decentralized.
See[our practical guide to building agents](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf)for more details.
### Manager (agents as tools)
The`customer\_facing\_agent`handles all user interaction and invokes specialized sub‑agents exposed as tools. Read more in the[tools](../tools/#agents-as-tools)documentation.
```
`[](#__codelineno-3-1)fromagentsimportAgent[](#__codelineno-3-2)[](#__codelineno-3-3)booking\_agent=Agent(...)[](#__codelineno-3-4)refund\_agent=Agent(...)[](#__codelineno-3-5)[](#__codelineno-3-6)customer\_facing\_agent=Agent([](#__codelineno-3-7)name=&quot;Customer-facing agent&quot;,[](#__codelineno-3-8)instructions=([](#__codelineno-3-9)&quot;Handle all direct user communication. &quot;[](#__codelineno-3-10)&quot;Call the relevant tools when specialized expertise is needed.&quot;[](#__codelineno-3-11)),[](#__codelineno-3-12)tools=[[](#__codelineno-3-13)booking\_agent.as\_tool([](#__codelineno-3-14)tool\_name=&quot;&quot;booking\_expert&quot;&quot;,[](#__codelineno-3-15)tool\_description=&quot;Handles booking questions and requests.&quot;,[](#__codelineno-3-16)),[](#__codelineno-3-17)refund\_agent.as\_tool([](#__codelineno-3-18)tool\_name=&quot;&quot;refund\_expert&quot;&quot;,[](#__codelineno-3-19)tool\_description=&quot;Handles refund questions and requests.&quot;,[](#__codelineno-3-20))[](#__codelineno-3-21)],[](#__codelineno-3-22))`
```
### Handoffs
Handoffs are sub‑agents the agent can delegate to. When a handoff occurs, the delegated agent receives the conversation history and takes over the conversation. This pattern enables modular, specialized agents that excel at a single task. Read more in the[handoffs](../handoffs/)documentation.
```
`[](#__codelineno-4-1)fromagentsimportAgent[](#__codelineno-4-2)[](#__codelineno-4-3)booking\_agent=Agent(...)[](#__codelineno-4-4)refund\_agent=Agent(...)[](#__codelineno-4-5)[](#__codelineno-4-6)triage\_agent=Agent([](#__codelineno-4-7)name=&quot;Triage agent&quot;,[](#__codelineno-4-8)instructions=([](#__codelineno-4-9)&quot;Help the user with their questions. &quot;[](#__codelineno-4-10)&quot;If they ask about booking, hand off to the booking agent. &quot;[](#__codelineno-4-11)&quot;If they ask about refunds, hand off to the refund agent.&quot;[](#__codelineno-4-12)),[](#__codelineno-4-13)handoffs=[booking\_agent,refund\_agent],[](#__codelineno-4-14))`
```
## Dynamic instructions
In most cases, you can provide instructions when you create the agent. However, you can also provide dynamic instructions via a function. The function will receive the agent and context, and must return the prompt. Both regular and`async`functions are accepted.
```
`[](#__codelineno-5-1)defdynamic\_instructions([](#__codelineno-5-2)context:RunContextWrapper[UserContext],agent:Agent[UserContext][](#__codelineno-5-3))-&gt;str:[](#__codelineno-5-4)returnf&quot;The user&#39;s name is{context.context.name}. Help them with their questions.&quot;[](#__codelineno-5-5)[](#__codelineno-5-6)[](#__codelineno-5-7)agent=Agent[UserContext]([](#__codelineno-5-8)name=&quot;Triage agent&quot;,[](#__codelineno-5-9)instructions=dynamic\_instructions,[](#__codelineno-5-10))`
```
## Lifecycle events (hooks)
Sometimes, you want to observe the lifecycle of an agent. For example, you may want to log events, or pre-fetch data when certain events occur. You can hook into the agent lifecycle with the`hooks`property. Subclass the[`AgentHooks`](../ref/lifecycle/#agents.lifecycle.AgentHooks)class, and override the methods you're interested in.
## Guardrails
Guardrails allow you to run checks/validations on user input in parallel to the agent running, and on the agent's output once it is produced. For example, you could screen the user's input and agent's output for relevance. Read more in the[guardrails](../guardrails/)documentation.
## Cloning/copying agents
By using the`clone()`method on an agent, you can duplicate an Agent, and optionally change any properties you like.
```
`[](#__codelineno-6-1)pirate\_agent=Agent([](#__codelineno-6-2)name=&quot;Pirate&quot;,[](#__codelineno-6-3)instructions=&quot;Write like a pirate&quot;,[](#__codelineno-6-4)model=&quot;gpt-5.2&quot;,[](#__codelineno-6-5))[](#__codelineno-6-6)[](#__codelineno-6-7)robot\_agent=pirate\_agent.clone([](#__codelineno-6-8)name=&quot;Robot&quot;,[](#__codelineno-6-9)instructions=&quot;Write like a robot&quot;,[](#__codelineno-6-10))`
```
## Forcing tool use
Supplying a list of tools doesn't always mean the LLM will use a tool. You can force tool use by setting[`ModelSettings.tool\_choice`](../ref/model_settings/#agents.model_settings.ModelSettings.tool_choice). Valid values are:
1. `auto`, which allows the LLM to decide whether or not to use a tool.
2. `required`, which requires the LLM to use a tool (but it can intelligently decide which tool).
3. `none`, which requires the LLM to*not*use a tool.
4. Setting a specific string e.g.`my\_tool`, which requires the LLM to use that specific tool.
```
`[](#__codelineno-7-1)fromagentsimportAgent,Runner,function\_tool,ModelSettings[](#__codelineno-7-2)[](#__codelineno-7-3)@function\_tool[](#__codelineno-7-4)defget\_weather(city:str)-&gt;str:[](#__codelineno-7-5)&quot;&quot;&quot;Returns weather info for the specified city.&quot;&quot;&quot;[](#__codelineno-7-6)returnf&quot;The weather in{city}is sunny&quot;[](#__codelineno-7-7)[](#__codelineno-7-8)agent=Agent([](#__codelineno-7-9)name=&quot;Weather Agent&quot;,[](#__codelineno-7-10)instructions=&quot;Retrieve weather details.&quot;,[](#__codelineno-7-11)tools=[get\_weather],[](#__codelineno-7-12)model\_settings=ModelSettings(tool\_choice=&quot;&quot;get\_weather&quot;&quot;)[](#__codelineno-7-13))`
```
## Tool Use Behavior
The`tool\_use\_behavior`parameter in the`Agent`configuration controls how tool outputs are handled:
* `"run\_llm\_again"`: The default. Tools are run, and the LLM processes the results to produce a final response.
* `"stop\_on\_first\_tool"`: The output of the first tool call is used as the final response, without further LLM processing.
```
`[](#__codelineno-8-1)fromagentsimportAgent,Runner,function\_tool,ModelSettings[](#__codelineno-8-2)[](#__codelineno-8-3)@function\_tool[](#__codelineno-8-4)defget\_weather(city:str)-&gt;str:[](#__codelineno-8-5)&quot;&quot;&quot;Returns weather info for the specified city.&quot;&quot;&quot;[](#__codelineno-8-6)returnf&quot;The weather in{city}is sunny&quot;[](#__codelineno-8-7)[](#__codelineno-8-8)agent=Agent([](#__codelineno-8-9)name=&quot;Weather Agent&quot;,[](#__codelineno-8-10)instructions=&quot;Retrieve weather details.&quot;,[](#__codelineno-8-11)tools=[get\_weather],[](#__codelineno-8-12)tool\_use\_behavior=&quot;&quot;stop\_on\_first\_tool&quot;&quot;[](#__codelineno-8-13))`
```
* `StopAtTools(stop\_at\_tool\_names=[...])`: Stops if any specified tool is called, using its output as the final response.
```
`[](#__codelineno-9-1)fromagentsimportAgent,Runner,function\_tool[](#__codelineno-9-2)fromagents.agentimportStopAtTools[](#__codelineno-9-3)[](#__codelineno-9-4)@function\_tool[](#__codelineno-9-5)defget\_weather(city:str)-&gt;str:[](#__codelineno-9-6)&quot;&quot;&quot;Returns weather info for the specified city.&quot;&quot;&quot;[](#__codelineno-9-7)returnf&quot;The weather in{city}is sunny&quot;[](#__codelineno-9-8)[](#__codelineno-9-9)@function\_tool[](#__codelineno-9-10)defsum\_numbers(a:int,b:int)-&gt;int:[](#__codelineno-9-11)&quot;&quot;&quot;Adds two numbers.&quot;&quot;&quot;[](#__codelineno-9-12)returna+b[](#__codelineno-9-13)[](#__codelineno-9-14)agent=Agent([](#__codelineno-9-15)name=&quot;Stop At Stock Agent&quot;,[](#__codelineno-9-16)instructions=&quot;Get weather or sum numbers.&quot;,[](#__codelineno-9-17)tools=[get\_weather,sum\_numbers],[](#__codelineno-9-18)tool\_use\_behavior=StopAtTools(stop\_at\_tool\_names=[&quot;&quot;get\_weather&quot;&quot;])[](#__codelineno-9-19))`
```
* `ToolsToFinalOutputFunction`: A custom function that processes tool results and decides whether to stop or continue with the LLM.
```
`[](#__codelineno-10-1)fromagentsimportAgent,Runner,function\_tool,FunctionToolResult,RunContextWrapper[](#__codelineno-10-2)fromagents.agentimportToolsToFinalOutputResult[](#__codelineno-10-3)fromtypingimportList,Any[](#__codelineno-10-4)[](#__codelineno-10-5)@function\_tool[](#__codelineno-10-6)defget\_weather(city:str)-&gt;str:[](#__codelineno-10-7)&quot;&quot;&quot;Returns weather info for the specified city.&quot;&quot;&quot;[](#__codelineno-10-8)returnf&quot;The weather in{city}is sunny&quot;[](#__codelineno-10-9)[](#__codelineno-10-10)defcustom\_tool\_handler([](#__codelineno-10-11)context:RunContextWrapper[Any],[](#__codelineno-10-12)tool\_results:List[FunctionToolResult][](#__codelineno-10-13))-&gt;ToolsToFinalOutputResult:[](#__codelineno-10-14)&quot;&quot;&quot;Processes tool results to decide final output.&quot;&quot;&quot;[](#__codelineno-10-15)forresultintool\_results:[](#__codelineno-10-16)ifresult.outputand&quot;sunny&quot;inresult.output:[](#__codelineno-10-17)returnToolsToFinalOutputResult([](#__codelineno-10-18)is\_final\_output=True,[](#__codelineno-10-19)final\_output=f&quot;Final weather:{result.output}&quot;[](#__codelineno-10-20))[](#__codelineno-10-21)returnToolsToFinalOutputResult([](#__codelineno-10-22)is\_final\_output=False,[](#__codelineno-10-23)final\_output=None[](#__codelineno-10-24))[](#__codelineno-10-25)[](#__codelineno-10-26)agent=Agent([](#__codelineno-10-27)name=&quot;Weather Agent&quot;,[](#__codelineno-10-28)instructions=&quot;Retrieve weather details.&quot;,[](#__codelineno-10-29)tools=[get\_weather],[](#__codelineno-10-30)tool\_use\_behavior=custom\_tool\_handler[](#__codelineno-10-31))`
```
Note
To prevent infinite loops, the framework automatically resets`tool\_choice`to "auto" after a tool call. This behavior is configurable via[`agent.reset\_tool\_choice`](../ref/agent/#agents.agent.Agent.reset_tool_choice). The infinite loop is because tool results are sent to the LLM, which then generates another tool call because of`tool\_choice`, ad infinitum.
