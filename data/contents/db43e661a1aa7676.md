# Yet Another PDF Parsing Article using LLMs (OpenAI o1 vs Deepseek R1)

**URL:** https://medium.com/@haliterdoan/yet-another-pdf-parsing-article-using-llms-openai-o1-vs-deepseek-r1-41fa97550b20
**Published:** 2025-01-25T09:32:17.000Z

---

## Summary

The webpage details an experiment comparing two reasoning Large Language Models (LLMs), **OpenAI o1** and **DeepSeek R1**, for the task of **PDF parsing** to extract structured data, which is critical for **multimodal RAG** systems.

The approach involved:
1.  **Preprocessing with Spatial Analysis:** Using `pdfplumber` to extract text blocks and their coordinates from a messy test report PDF. Spatial relationships (distance and angle) between blocks were calculated to determine alignment (rows/columns) and create contextual "links" stored in a markdown table.
2.  **Leveraging Reasoning LLMs:** The LLMs were prompted with a system instruction, a **GraphQL schema** defining the desired structured output, and the markdown table of spatial links.

**Conclusion:** **DeepSeek R1** significantly outperformed the much more expensive **OpenAI o1** (which cost 30 times more). DeepSeek correctly mapped all fields and produced clean, structured output, while GPT-4 mixed up some fields. The author concludes that spatial analysis preprocessing is powerful, and DeepSeek R1 is a cost-effective and accurate game-changer for unstructured data tasks like PDF parsing.

---

## Full Content

Yet Another PDF Parsing Article using LLMs (OpenAI o1 vs Deepseek R1) | by Halit Erdoğan | Medium
[Sitemap](https://medium.com/sitemap/sitemap.xml)
[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)
Sign up
[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@haliterdoan/yet-another-pdf-parsing-article-using-llms-openai-o1-vs-deepseek-r1-41fa97550b20&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)
[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)
[
Write
](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)
[
Search
](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)
Sign up
[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@haliterdoan/yet-another-pdf-parsing-article-using-llms-openai-o1-vs-deepseek-r1-41fa97550b20&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)
![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)
# Yet Another PDF Parsing Article using LLMs (OpenAI o1 vs Deepseek R1)
[
![Halit Erdoğan](https://miro.medium.com/v2/resize:fill:64:64/1*RVxWtyGOjMg6k-n3w9HfSQ.jpeg)
](https://medium.com/@haliterdoan?source=post_page---byline--41fa97550b20---------------------------------------)
[Halit Erdoğan](https://medium.com/@haliterdoan?source=post_page---byline--41fa97550b20---------------------------------------)
3 min read
·Jan 25, 2025
[
](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/41fa97550b20&amp;operation=register&amp;redirect=https://medium.com/@haliterdoan/yet-another-pdf-parsing-article-using-llms-openai-o1-vs-deepseek-r1-41fa97550b20&amp;user=Halit+Erdo%C4%9Fan&amp;userId=9e1c2afd3d52&amp;source=---header_actions--41fa97550b20---------------------clap_footer------------------)
--
3
[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/41fa97550b20&amp;operation=register&amp;redirect=https://medium.com/@haliterdoan/yet-another-pdf-parsing-article-using-llms-openai-o1-vs-deepseek-r1-41fa97550b20&amp;source=---header_actions--41fa97550b20---------------------bookmark_footer------------------)
Listen
Share
## Introduction
PDF parsing is a critical task for many applications, especially in Retrieval-Augmented Generation (RAG) systems. Everyone wants to extract structured data from PDFs, but it’s notoriously difficult. Programmatic parsing often falls short because it relies on PDFs being perfectly structured —something that’s rarely the case in real-world documents. Non-reasoning LLMs can help, but they’re not always reliable for complex tasks like this.
Enter reasoning models. These advanced LLMs promise better performance, but they come with a catch: they’re expensive. OpenAI’s o1, for example, costs $60 per 1 million tokens.
DeepSeek’s new release R1, on the other hand, offers a reasoning model at just $2 per 1 million tokens —a fraction of the cost. Naturally, I wanted to see how they stack up in a real-world scenario: parsing a messy, unstructured test report PDF.
## The Data: A Test Report
The input file is a test report. Due to confidentiality, I censored almost all of it but you can still understand the messy layout
Press enter or click to view image in full size
![]()
## The Approach: Preprocessing and Reasoning LLMs
### Step 1: Preprocessing with Spatial Analysis
The first step was to extract the text blocks from the PDF using`pdfplumber`. Each text block came with its coordinates, which allowed me to analyze their spatial relationships.
```
import pdfplumber
with pdfplumber.open(&quot;report.pdf&quot;) as pdf:
for page in pdf.pages:
for block in page.extract\_words():
print(block)
```
Next, I created a “window” around each text block to capture its surrounding context. For each pair of blocks, I calculated the distance and angle between them. The angle helped determine if the blocks were horizontally aligned (likely part of the same row) or vertically aligned (likely part of a column).
```
import math
def calculate\_distance\_and\_angle(block1, block2):
x1, y1 = block1[&#x27;x0&#x27;], block1[&#x27;top&#x27;]
x2, y2 = block2[&#x27;x0&#x27;], block2[&#x27;top&#x27;]
dx, dy = x2 - x1, y2 - y1
distance = math.hypot(dx, dy)
angle = math.degrees(math.atan2(dy, dx)) % 360
return distance, angle
```
Using this information, I created unique “links” between blocks that were close enough to each other. Each link included the start block, end block, distance, and angle. These links were stored in a markdown table for easy reference.
```
| Start Block | End Block | Distance | Angle |
|----------------------|----------------------|----------|-------|
| Project No. | 2025-001 | 16 | 0 |
| Client / Owner | Global Company | 14 | 10 |
| Name of Item | Example Item | 15 | 5 |
```
### Step 2:**Leveraging Reasoning LLMs for Structured Output**
With the preprocessed data in hand, I crafted a human message for the LLM. This message included:
1. A system prompt describing the task.
2. A GraphQL schema defining the desired output format.
3. The markdown table of links.
Here’s an example of the GraphQL schema I used:
```
type TestReport {
projectNo: String
reportNo: String
client: String
itemName: String
dateOfInspection: Date
location: String
...
}
```
I sent this message to two LLMs: DeepSeek-R1 and OpenAI o1. The results were surprising.
## Conclusion
DeepSeek nailed the task. It correctly mapped all the fields, including tricky ones like “inspectedBy” and “reviewedBy,” and produced a clean, structured output. OpenAI GPT-4, on the other hand, mixed up some fields and missed a few details, despite being 30 times more expensive.
I got two things from this experience:
1. **Spatial analysis is powerful.**Quality data is always crucial. By preprocessing the data and calculating spatial relationships, I was able to provide the LLM with meaningful context.
2. **DeepSeek is not messing around.**R1 might just be a game changer for tasks like this. Its affordability and accuracy make it a compelling option for anyone working with unstructured data. If you’re wrestling with PDF parsing or similar challenges, it’s worth giving DeepSeek a try. You might find, as I did, that the best solution isn’t always the most expensive one.
[
LLM
](https://medium.com/tag/llm?source=post_page-----41fa97550b20---------------------------------------)
[
Unstructured Data
](https://medium.com/tag/unstructured-data?source=post_page-----41fa97550b20---------------------------------------)
[
Deepseek
](https://medium.com/tag/deepseek?source=post_page-----41fa97550b20---------------------------------------)
[
OpenAI
](https://medium.com/tag/openai?source=post_page-----41fa97550b20---------------------------------------)
[
Data Preprocessing
](https://medium.com/tag/data-preprocessing?source=post_page-----41fa97550b20---------------------------------------)
[
![Halit Erdoğan](https://miro.medium.com/v2/resize:fill:96:96/1*RVxWtyGOjMg6k-n3w9HfSQ.jpeg)
](https://medium.com/@haliterdoan?source=post_page---post_author_info--41fa97550b20---------------------------------------)
[
![Halit Erdoğan](https://miro.medium.com/v2/resize:fill:128:128/1*RVxWtyGOjMg6k-n3w9HfSQ.jpeg)
](https://medium.com/@haliterdoan?source=post_page---post_author_info--41fa97550b20---------------------------------------)
[## Written byHalit Erdoğan
](https://medium.com/@haliterdoan?source=post_page---post_author_info--41fa97550b20---------------------------------------)
[41 followers](https://medium.com/@haliterdoan/followers?source=post_page---post_author_info--41fa97550b20---------------------------------------)
·[23 following](https://medium.com/@haliterdoan/following?source=post_page---post_author_info--41fa97550b20---------------------------------------)
Data scientist working on AI Agents, RAG, getting unstructured data LLM-ready.
## Responses (3)
[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--41fa97550b20---------------------------------------)
See all responses
[
Help
](https://help.medium.com/hc/en-us?source=post_page-----41fa97550b20---------------------------------------)
[
Status
](https://status.medium.com/?source=post_page-----41fa97550b20---------------------------------------)
[
About
](https://medium.com/about?autoplay=1&amp;source=post_page-----41fa97550b20---------------------------------------)
[
Careers
](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----41fa97550b20---------------------------------------)
[
Press
](mailto:pressinquiries@medium.com)
[
Blog
](https://blog.medium.com/?source=post_page-----41fa97550b20---------------------------------------)
[
Privacy
](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----41fa97550b20---------------------------------------)
[
Rules
](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----41fa97550b20---------------------------------------)
[
Terms
](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----41fa97550b20---------------------------------------)
[
Text to speech
](https://speechify.com/medium?source=post_page-----41fa97550b20---------------------------------------)
