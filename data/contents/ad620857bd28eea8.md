# Agent Memory: How to Build Agents that Learn and Remember

**URL:** https://www.letta.com/blog/agent-memory?amp%3Butm_medium=newsletter
**Published:** 2025-07-07T00:00:00.000Z

---

## Summary

The provided webpage focuses on **Agent Memory**, detailing how to build agents that learn and remember over time by managing their context window.

Key concepts discussed include:
*   **Agent Memory as Context Management:** Designing memory is essentially context engineering—determining what information enters the agent's context window.
*   **Types of Agent Memory:**
    *   **Message Buffer:** Stores recent messages for immediate conversational context.
    *   **Core Memory:** In-context, editable memory blocks focused on specific topics (user, persona, task).
    *   **Recall Memory:** Stores and allows searching of the complete conversational history.
    *   **Archival Memory:** Explicitly formulated, indexed knowledge stored in external databases (like vector or graph DBs).
*   **Techniques for Memory Management:** Message eviction, recursive summarization, managing structured memory blocks, and using external storage/retrieval (RAG).
*   **Engineering Systems:** Mentions **MemGPT** (treating context as a constrained resource with memory tiers) and **Sleep-Time Compute** (using asynchronous agents for proactive memory refinement).

**Regarding your specific query:**

The query lists several technical components related to the agent stack: 'agent\_infrastructure: MCP servers, tool use, agent memory, agentic memory, agent frameworks, LangChain, LlamaIndex, OpenAI Agents SDK, Anthropic Agents SDK, Google SDK, function calling, structured outputs, agent orchestration'.

The webpage directly addresses **agent memory** and **agentic memory**, **tool use** (via tool calling for retrieval), and mentions **agent frameworks** implicitly through concepts like MemGPT and the discussion of context engineering. It also touches upon **structured outputs** via memory blocks.

However, the page **does not mention or discuss**:
*   MCP servers
*   LangChain
*   LlamaIndex
*   OpenAI Agents SDK
*   Anthropic Agents SDK
*   Google SDK
*   Agent orchestration

Since the page does not cover the majority of the specific infrastructure and SDK components listed in your query, a complete summary addressing all points is not possible.

**No answer found** for the full scope of the query.

---

## Full Content

Agent Memory: How to Build Agents that Learn and Remember | Letta
[
](https://www.letta.com/)
[
11.3K
](https://github.com/cpacker/MemGPT)
Menu
Close
[
19K
](https://github.com/letta-ai/letta)[Docs](https://docs.letta.com)[Sign In](https://app.letta.com)
Light
Dark
Company
# Agent Memory: How to Build Agents that Learn and Remember
July 7, 2025
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/686b5e988ad87717a55fca3f_letta_graphs_2x.webp)
Traditional LLMs operate in a stateless paradigm —each interaction exists in isolation, with no knowledge carried forward from previous conversations. While this approach works basic tasks and short-lived agents, it fundamentally limits what AI systems can achieve. The shift from stateless LLMs to[stateful agents](https://www.letta.com/blog/stateful-agents)represents an evolution towards systems that can actually learn and adapt over time.
## What is Agent Memory?
Agent memory is what and how your agent remembers information over time. While basic memory might simply involve recalling previous interactions, advanced memory systems enable agents to learn and improve over time, adapting their behavior based on accumulated experience.
### Agent Memory as Context Management
What your agent &quot;remembers&quot; is fundamentally determined by what exists in its context window at any given moment. Think of the context window as the agent&#x27;s working memory —the information immediately available for answering questions, reasoning, and taking actions.
Therefore, designing an agent&#x27;s memory is essentially[context engineering](https://www.letta.com/blog/guide-to-context-engineering): determining which tokens enter the context window and how they&#x27;re organized. Memory systems compose multiple techniques (such as summarization, context rewriting, and retrieval) to manage various memory components (messages, memory blocks, and external databases).
## Types of Agent Memory
Agent memory systems typically consist of several distinct components, each serving different purposes:
### Message Buffer: Recent Messages
The message buffer stores the most recent messages in a conversation. In Letta, every agent maintains a single perpetual thread, which represents a continuous sequence of messages. This provides immediate conversational context and maintains dialogue flow.
### Core Memory: In-Context Memory Blocks
Core memory consists of in-context memory blocks that can be managed by the agent itself or by other agents. These blocks focus on specific topics such as memories about the user, organization, or the current task. For example, one block might contain user preferences, while another maintains the agent&#x27;s persona or current objectives. The key feature is that these blocks are editable via APIs and remain pinned to the agent&#x27;s context window, providing an abstraction for managed context units.
### Recall Memory: Conversational History
Recall memory preserves the complete history of interactions that can be searched and retrieved when needed, even when not in the active context window (i.e., in the message buffer). In Letta, recall memory saves to disk automatically, while other frameworks require developers to handle persistence manually.
### Archival Memory: Explicitly Stored Knowledge
Archival memory represents explicitly formulated knowledge stored in external databases. Unlike recall memory, which stores raw conversation history, archival memory contains processed and indexed information. It can utilize different storage formats, such as vector databases or graph databases, with specialized tools that query and retrieve data back into the context window.
## Techniques for Agent Memory
### Message Eviction &amp; Summarization
One fundamental challenge in agent memory is managing the limited context window. Summarization techniques help compress information while preserving essential details:
**Eviction Methods:**When the context window reaches capacity, intelligent eviction strategies determine what information to remove. This might involve summarizing and storing important details before removing them from active context. Generally, you should evict only a portion (e.g., 70%) of messages to ensure continuity.
**Recursive Summarization:**Evicted messages undergo recursive summarization—they&#x27;re summarized along with existing summaries from previously summarized messages. As conversations grow longer, older messages have progressively less influence on the summary than recent messages.
### Managing Memory Blocks
[Memory blocks](https://www.letta.com/blog/memory-blocks)provide structured, editable storage within the agent&#x27;s context window. Each block contains:
* A**label**
* A**description**(explaining what&#x27;s stored in the block)
* A**value**(the actual tokens placed in context)
* A**character**limit (defining how much context window space is allocated)
Memory blocks abstract the context window for automated management. Agents can update their own memory blocks based on new information, using tools to rewrite specific blocks. Other agents specialized in memory management (such as sleep-time agents) can also modify these blocks. This creates a mechanism for context rewriting, allowing agents to improve their context window over time by consolidating important information.
### External Storage &amp; Retrieval
Memory can also be stored in external databases and retrieved via tool calling. Different storage and retrieval mechanisms suit different applications:
* **Vector DBs:**Memories are saved, embedded, and queried via vector search
* **Graph DBs:**Memories form graph structures where agents can traverse relationships between concepts, enabling sophisticated reasoning about connected information
While retrieval (or RAG) is a tool for agent memory,[it is not “memory” in of itself](https://www.letta.com/blog/rag-vs-agent-memory).
## Engineering Systems for Agent Memory
### MemGPT: The Operating System Approach
[MemGPT (MemoryGPT)](https://research.memgpt.ai/)is a system that intelligently manages different storage tiers to effectively provide extended context within the LLM&#x27;s limited context window. MemGPT treats context windows as a constrained memory resource and implements a memory hierarchy similar to operating systems.
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/686b5f0fae589c7f6a4e66e8_memgpt-system-diagram.png)
System figure from the original MemGPT research paper
The system provides function calls that allow the LLM to manage its own memory autonomously. Agents can move data between in-context core memory (analogous to RAM) and externally stored archival and recall memory (analogous to disk storage), creating an illusion of unlimited memory while working within fixed context limits.
### Sleep-Time Compute: Asynchronous &amp; Specialized Memory Agents
Another approach to memory is using[sleep-time agents](https://www.letta.com/blog/sleep-time-compute)to manage memory asynchronously. The sleep-time compute paradigm introduces several key improvements to the agent design from the original MemGPT paper:
* **Non-Blocking Operations:**Unlike MemGPT, where memory management, conversation, and other tasks are bundled into a single agent (potentially causing slower responses during memory operations), sleep-time agents handle memory management asynchronously, improving both response times and memory quality.
* **Proactive Memory Refinement:**Instead of lazy, incremental updates during conversations, memory can be reorganized and improved during idle periods.
This approach allows for higher quality memory blocks, enabling improved learning and memory formation over time –in addition to correlating the agent’s interaction latency.
## Analogies Between Human and Agent Memory
While it&#x27;s tempting to draw direct parallels between human and artificial memory, it&#x27;s crucial to remember that LLMs are fundamentally text-in, text-out systems. Their &quot;memory&quot; consists solely of what exists in their context window.
Rather than hard-coding human-like memory structures, we should focus on context engineering —designing systems that effectively manage the information available to the model at inference time. This involves designing:
* How the context window is organized (determining message buffer size and memory block design)
* Tools for retrieving archival memory to pull externally stored context back into the window
* Prompts that help agents understand their memory limitations and leverage both in-context and external memory to overcome them
The goal isn&#x27;t to replicate human memory mechanics but to create memory systems that enable agents to be genuinely helpful, consistent, and capable of learning within the token-based paradigm of LLMs.
## Short-term vs. Long-term Agent Memory
An agent&#x27;s “short-term” memory consists of whatever resides in the message buffer, as this content will eventually be evicted. All other memory types qualify as &quot;long-term.&quot; However, it&#x27;s more helpful to conceptualize agent memory as context engineering: understanding what is or isn&#x27;t in the context window, and how tokens are pulled back into the context window. Ultimately, memory is about choosing which tokens to place in your context window at any given moment.
## Conclusion
Agent memory represents one of the most critical frontiers in AI development. The future of agent memory lies not in any single technique but in the thoughtful combination of multiple approaches: careful eviction and summarization, intelligent management of memory blocks, and sophisticated systems for storing and retrieving external context.
If you’re looking to build agents that can form memories and learn over time to become more intelligent and personalized, check out[Letta](https://docs.letta.com/quickstart).
‍[
Back
](https://www.letta.com/trash/old-blog)
[
Twitter/X
](#)[
LinkedIn
](#)
[## Company
Company announcements, partnerships
](https://www.letta.com/blog-categories/company)
[](https://www.letta.com/blog/guide-to-context-engineering)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6866c72419989f4527ad72d4_letta_CPU.OS%402x.png)
Jul 3, 2025
Anatomy of a Context Window: A Guide to Context Engineering
As AI agents become more sophisticated, understanding how to design and manage their context windows (via context engineering) has become crucial for developers.
[](https://www.letta.com/blog/memory-blocks)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6824ff9e8b9b8cfa0b38d37d_memory-h-l4.png)
May 14, 2025
Memory Blocks: The Key to Agentic Context Management
Memory blocks offer an elegant abstraction for context window management. By structuring the context into discrete, functional units, we can give LLM agents more consistent, usable memory.
[](https://www.letta.com/blog/rag-vs-agent-memory)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/67aafd6c88a6c68cca350b59_letta_books%402x.webp)
Feb 13, 2025
RAG is not Agent Memory
Although RAG provides a way to connect LLMs and agents to more data than what can fit into context, traditional RAG is insufficient for building agent memory.
[](https://www.letta.com/blog/stateful-agents)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/67a44735ae8c2311297490c9_letta_memory_2x.webp)
Feb 6, 2025
Stateful Agents: The Missing Link in LLM Intelligence
Introducing “stateful agents”: AI systems that maintain persistent memory and actually learn during deployment, not just during training.
[](https://www.letta.com/blog/ai-agents-stack)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6735971c9bed4dbe4fd98d55_BlogPost_01.webp)
Nov 14, 2024
The AI agents stack
Understanding the AI agents stack landscape.
[](https://www.letta.com/blog/deeplearning-ai-llms-as-operating-systems-agent-memory)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6732732bb6386c6228ad1ae9_letta_dlai_grey.webp)
Nov 7, 2024
New course on Letta with DeepLearning.AI
DeepLearning.AI has released a new course on agent memory in collaboration with Letta.
[](https://www.letta.com/blog/announcing-letta)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/67314733cc0d8719cd76879f_letta_intro.webp)
Sep 23, 2024
Announcing Letta
We are excited to publicly announce Letta.
[](https://www.letta.com/blog/memgpt-and-letta)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/67314a470f07af58bc65b179_letta_memgpt.webp)
Sep 23, 2024
MemGPT is now part of Letta
The MemGPT open source project is now part of Letta.
[## Product
Release notes, feature announcements
](https://www.letta.com/blog-categories/product)
[](https://www.letta.com/blog/letta-code)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/69419caea50a5208e60e88d9_letta-code-blog-thumb.png)
Dec 16, 2025
Letta Code: A Memory-First Coding Agent
Introducing Letta Code, a memory-first coding agent. Letta Code is the #1 model-agnostic open source agent on the leading AI coding benchmark Terminal-Bench.
[](https://www.letta.com/blog/programmatic-tool-calling-with-any-llm)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/692dff0f8c7ecba7ca2db3fe_scale%20growing%402x.png)
Dec 1, 2025
Programmatic Tool Calling with any LLM
The Letta API now supports programmatic tool calling for any LLM model, enabling agents to generate their own workflows.
[](https://www.letta.com/blog/letta-evals)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/68f9cce19e13b738da57f275_evals2x.png)
Oct 23, 2025
Letta Evals: Evaluating Agents that Learn
Introducing Letta Evals: an open-source evaluation framework for systematically testing stateful agents.
[](https://www.letta.com/blog/letta-v1-agent)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/68edb440587079f73297d6f0_agentic-loop.webp)
Oct 14, 2025
Rearchitecting Letta’s Agent Loop: Lessons from ReAct, MemGPT, &amp; Claude Code
Introducing Letta&#x27;s new agent architecture, optimized for frontier reasoning models.
[](https://www.letta.com/blog/introducing-sonnet-4-5-and-the-memory-omni-tool-in-letta)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/68dc3e4f0f4b902c1443470f_tool_usage.webp)
Sep 30, 2025
Introducing Claude Sonnet 4.5 and the memory omni-tool in Letta
Letta agents can now take full advantage of Sonnet 4.5’s advanced memory tool capabilities to dynamically manage their own memory blocks.
[](https://www.letta.com/blog/letta-filesystem)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6881a27d66b2ac405309303b_image.png)
Jul 24, 2025
Introducing Letta Filesystem
Today we&#x27;re announcing Letta Filesystem, which provides an interface for agents to organize and reference content from documents like PDFs, transcripts, documentation, and more.
[](https://www.letta.com/blog/announcing-our-sdks)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/68012229d2774402e0e526ae_letta_fern_2x.webp)
Apr 17, 2025
Announcing Letta Client SDKs for Python and TypeScript
We&#x27;ve releasing new client SDKs (support for TypeScript and Python) and upgraded developer documentation
[](https://www.letta.com/blog/agent-file)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/67ed897786b9e1a53bd585e1_agentfile_blog_small.webp)
Apr 2, 2025
Agent File
Introducing Agent File (.af): An open file format for serializing stateful agents with persistent memory and behavior.
[](https://www.letta.com/blog/introducing-the-agent-development-environment)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/678685ffc445fbad06362394_ade_thumbnail.webp)
Jan 15, 2025
Introducing the Agent Development Environment
Introducing the Letta Agent Development Environment (ADE): Agents as Context + Tools
[](https://www.letta.com/blog/letta-v0-6-4-release)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/675ca410bbe509b8e72e2140_letta_064_release.webp)
Dec 13, 2024
Letta v0.6.4 release
Letta v0.6.4 adds Python 3.13 support and an official TypeScript SDK.
[](https://www.letta.com/blog/letta-v0-5-2-release)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6731407133e684213a75bcfe_letta_v052.webp)
Nov 6, 2024
Letta v0.5.2 release
Letta v0.5.2 adds tool rules, which allows you to constrain the behavior of your Letta agents similar to graphs.
[](https://www.letta.com/blog/letta-v0-5-1-release)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/67313f239f7f093166906290_letta_v051.webp)
Oct 23, 2024
Letta v0.5.1 release
Letta v0.5.1 adds support for auto-loading entire external tool libraries into your Letta server.
[](https://www.letta.com/blog/letta-v0-5-release)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/67313cb6ab1b61326e745837_letta_v05.webp)
Oct 14, 2024
Letta v0.5 release
Letta v0.5 adds dynamic model (LLM) listings across multiple providers.
[](https://www.letta.com/blog/letta-v0-4-1-release)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/67313680e8dcc90d962a4439_letta_v041.webp)
Oct 3, 2024
Letta v0.4.1 release
Letta v0.4.1 adds support for Composio, LangChain, and CrewAI tools.
[## Research
Sleep-time compute, anatomy of a context window
](https://www.letta.com/blog-categories/research)
[](https://www.letta.com/blog/continual-learning)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6939e1df2872ece8e8298a83_sound_waves%402x.png)
Dec 11, 2025
Continual Learning in Token Space
At Letta, we believe that learning in token space is the key to building AI agents that truly improve over time. Our interest in this problem is driven by a simple observation: agents that can carry their memories across model generations will outlast any single foundation model.
[](https://www.letta.com/blog/skill-learning)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/692f4687c4226272753e94b9_speed%402x.png)
Dec 2, 2025
Skill Learning: Bringing Continual Learning to CLI Agents
Today we’re releasing Skill Learning, a way to dynamically learn skills through experience. With Skill Learning, agents can use their past experience to actually improve, rather than degrade, over time.
[](https://www.letta.com/blog/context-bench-skills)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/690e3f466f9e5a266a7823d7_tracing%20and%20understanding%402x.png)
Nov 7, 2025
Can Any Model Use Skills? Adding Skills to Context-Bench
Today we&#x27;re releasing Skill Use, a new evaluation suite inside of Context-Bench that measures how well models discover and load relevant skills from a library to complete tasks.
[](https://www.letta.com/blog/context-bench)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6903098c91ecf5051a3ba64a_tokens%20words%402x.png)
Oct 30, 2025
Context-Bench: Benchmarking LLMs on Agentic Context Engineering
We are open-sourcing Context-Bench, which evaluates how well language models can chain file operations, trace entity relationships, and manage multi-step information retrieval in long-horizon tasks.
[](https://www.letta.com/blog/recovery-bench)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/68edd9502e6ba397447c9ee3_recovery.webp)
Aug 27, 2025
Introducing Recovery-Bench: Evaluating LLMs&#x27; Ability to Recover from Mistakes
We&#x27;re excited to announce Recovery-Bench, a benchmark and evaluation method for measuring how well agents can recover from errors and corrupted states.
[](https://www.letta.com/blog/benchmarking-ai-agent-memory)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/689ad5b144245a7bee0bb80a_evaluation%402x.png)
Aug 12, 2025
Benchmarking AI Agent Memory: Is a Filesystem All You Need?
Letta Filesystem scores 74.0% of the LoCoMo benchmark by simply storing conversational histories in a file, beating out specialized memory tool libraries.
[](https://www.letta.com/blog/terminal-bench)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/68924a831b743fff4eaadc89_terminalbench-thumb.png)
Aug 5, 2025
Building the #1 open source terminal-use agent using Letta
We built the #1 open-source agent for terminal use, achieving 42.5% overall score on Terminal-Bench ranking 4th overall and 2nd among agents using Claude 4 Sonnet.
[](https://www.letta.com/blog/letta-leaderboard)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/6838bc001f142182a0d48fbb_letta-leaderboard-thumb.webp)
May 29, 2025
Letta Leaderboard: Benchmarking LLMs on Agentic Memory
We&#x27;re excited to announce the Letta Leaderboard, a comprehensive benchmark suite that evaluates how effectively LLMs manage agentic memory.
[](https://www.letta.com/blog/sleep-time-compute)
![](https://cdn.prod.website-files.com/66bb3d1f468f0f3848a20a84/68065943b27ea6238e9d427e_sleeptime_header_wide.webp)
Apr 21, 2025
Sleep-time Compute
Sleep-time compute is a new way to scale AI capabilities: letting models &quot;think&quot; during downtime. Instead of sitting idle between tasks, AI agents can now use their &quot;sleep&quot; time to process information and form new connections by rewriting their memory state.
in this article
[This is some text inside of a div block.](#)
