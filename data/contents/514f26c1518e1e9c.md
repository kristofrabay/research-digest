# Introducing Any-Agent: An abstraction layer between your code and the many agentic frameworks

**URL:** https://blog.mozilla.ai/introducing-any-agent-an-abstraction-layer-between-your-code-and-the-many-agentic-frameworks/
**Published:** 2025-04-10T15:22:41.000Z

---

## Summary

The webpage introduces **Any-Agent**, an abstraction layer designed to simplify building and experimenting with different agentic frameworks.

It addresses the complexity arising from the variety of agent frameworks available (like LangChain, Smolagents, etc.), which often have opinionated implementations for agentic logic, routing, and default prompts.

**Key features and concepts mentioned in relation to the user query:**

*   **Agent Frameworks:** The page explicitly mentions and compares frameworks like **LangChain** and **Smolagents**, and lists others such as OpenAI Agents Python SDK, LangGraph Python SDK, AWS Bedrock Agents SDK, CrewAI Python SDK, AutoGen Python SDK, and Agno Python SDK.
*   **Tool Use & Structured Outputs:** These are mentioned as techniques used to improve the capability of LLM-powered applications.
*   **Agent Orchestration/Workflows vs. Agents:** Anthropic's definition is used to distinguish between prescriptive **workflows** (predefined code paths orchestrating LLMs and tools) and true **agents** (systems where LLMs dynamically direct their own processes and tool usage).
*   **MCP Servers:** The library is designed to load and configure **Model Context Protocol (MCP) Servers** for various agent frameworks, abstracting away framework-specific loading semantics.
*   **Agent Memory/Agentic Memory:** While the concept of agents is central, specific details about implementing or abstracting "agent memory" or "agentic memory" are not elaborated upon beyond the general discussion of agent capabilities.
*   **SDKs:** The page lists several SDKs related to agents, including the **OpenAI Agents SDK** (implied by mentioning LangChain's use of OpenAI models) and the **Anthropic Agents SDK** (implied by referencing Anthropic's definition). The **Google SDK** is not explicitly mentioned in the context of agent frameworks, though other providers are listed.
*   **Function Calling:** This is not explicitly mentioned by name, but it is related to the concept of **tool usage**.

**In summary, Any-Agent allows developers to write agent code once and easily switch between different underlying agent frameworks (like LangChain) while handling configuration details like MCP Server loading.**

---

## Full Content

Introducing Any-Agent: An abstraction layer between your code and the many agentic frameworks
[![Mozilla.ai](https://blog.mozilla.ai/content/images/2025/10/mozilla.ai_black-1.png)](https://blog.mozilla.ai)
[Sign in](#/portal/signin)[Subscribe](#/portal/signup)
# Introducing Any-Agent: An abstraction layer between your code and the many agentic frameworks
Since the launch of ChatGPT in 2022, generative AI and LLMs have rapidly entered everyday life. The viral adoption of these tools was unprecedented, and in some ways contentious. In order to grant greater capabilities to LLMs, they can be integrated into a framework that’s referred to as an “Agent”.
[![Nathan Brake](https://blog.mozilla.ai/content/images/size/w160/2025/02/Nathan.png)](https://blog.mozilla.ai/author/nathan/)[![David de la Iglesia Castro](https://blog.mozilla.ai/content/images/size/w160/2025/02/1697010560510.jpg)](https://blog.mozilla.ai/author/david/)[![Stefan French](https://blog.mozilla.ai/content/images/size/w160/2024/03/stefan-author.jpeg)](https://blog.mozilla.ai/author/stefan-french/)
#### [Nathan Brake](https://blog.mozilla.ai/author/nathan/),[David de la Iglesia Castro](https://blog.mozilla.ai/author/david/),[Stefan French](https://blog.mozilla.ai/author/stefan-french/)
Apr 10, 2025—4 min read
![Introducing Any-Agent: An abstraction layer between your code and the many agentic frameworks](https://blog.mozilla.ai/content/images/size/w1200/2025/04/kevin-grieve-alNlyjzup80-unsplash.jpg)Photo by[Kevin Grieve](https://unsplash.com/@grievek1610begur?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash)/[Unsplash](https://unsplash.com/photos/blue-yellow-and-red-lego-toys-alNlyjzup80?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash)
Ever since ChatGPT[burst onto the scene](https://openai.com/index/chatgpt/?ref=blog.mozilla.ai)in 2022, generative AI and Large Language Models (LLMs) have become a part of the cultural moment. The widespread and viral adoption of these tools into many parts of our lives was unprecedented, unexpected, and in some ways contentious: The risk of spreading misinformation and introducing[automation bias](https://www.forbes.com/sites/brycehoffman/2024/03/10/automation-bias-what-it-is-and-how-to-overcome-it/?ref=blog.mozilla.ai)through their use is a hotly debated topic.
Efforts to improve the reliability, explainability, and capability of LLM-powered applications have been an active area of research and have resulted in techniques like[Retrieval-Augmented Generation](https://www.geeksforgeeks.org/what-is-retrieval-augmented-generation-rag/?ref=blog.mozilla.ai)(RAG),[structured outputs](https://towardsdatascience.com/structured-outputs-and-how-to-use-them-40bd86881d39/?ref=blog.mozilla.ai), and[tool usage](https://www.anthropic.com/news/model-context-protocol?ref=blog.mozilla.ai). These extra capabilities can be used to improve the quality of LLM-powered chat applications (e.g. ChatGPT) and have been integrated into workflow automation, where a workflow is a sequence of pre-defined steps that can be executed with the help of the LLM.
In order to grant even greater capabilities to LLMs, they can be integrated into a framework that’s referred to by the community as an “Agent”. The term is quite fuzzy, however, Anthropic offers a helpful definition in their[blog post](https://www.anthropic.com/engineering/building-effective-agents?ref=blog.mozilla.ai)that clearly differentiates between workflow and agent:
*“Agent" can be defined in several ways. Some customers define agents as fully autonomous systems that operate independently over extended periods, using various tools to accomplish complex tasks. Others use the term to describe more prescriptive implementations that follow predefined workflows. At Anthropic, we categorize all these variations as**agentic systems**, but draw an important architectural distinction between**workflows**and**agents**:*
* ***Workflows**are systems where LLMs and tools are orchestrated through predefined code paths.*
* ***Agents**, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.*
Implementing an agent is no trivial task: The agent must be reliable and have a clearly understood design so that it can be properly evaluated and monitored. To accomplish this goal, there are a myriad of frameworks available to help build these systems. Some frameworks are specific to the model being used, while others are specific to the cloud provider that hosts the LLM, and yet others are agnostic to both model and provider. Although not an exhaustive list, several popular options currently exist, listed in no specific order:[OpenAI Agents Python SDK](https://github.com/openai/openai-agents-python?ref=blog.mozilla.ai),[LangGraph Python SDK](https://github.com/langchain-ai/langgraph?ref=blog.mozilla.ai),[AWS Bedrock Agents SDK](https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html?ref=blog.mozilla.ai),[Smolagents Python SDK](https://github.com/huggingface/smolagents?ref=blog.mozilla.ai),[CrewAI Python SDK](https://github.com/crewAIInc/crewAI?ref=blog.mozilla.ai),[AutoGen Python SDK](https://github.com/microsoft/autogen?ref=blog.mozilla.ai), and[Agno Python SDK](https://github.com/agno-agi/agno?ref=blog.mozilla.ai).
### Does the framework matter?
With so many options for building an agent, choosing a framework may seem like an arbitrary decision: Would it be sufficient to read the documentation and pick the one that looks like it will be the easiest API? It’s not clear that a framework would have a big impact on the performance of the agent. Although this is a reasonable assumption, it turns out to be a bit more complicated. An agent framework is rather opinionated in the way it implements agentic logic and routing, even for a defined processing framework like[ReAct](https://arxiv.org/abs/2210.03629?ref=blog.mozilla.ai). For example, the Smolagents library defaults to using a “[CodeAgent](https://github.com/huggingface/smolagents/blob/v1.13.0/src/smolagents/agents.py?ref=blog.mozilla.ai#L1126)”, which executes all of the tasks by generating python code and has specific LLM prompting text that is[hardcoded](https://github.com/huggingface/smolagents/blob/v1.13.0/src/smolagents/agents.py?ref=blog.mozilla.ai#L430). Similarly, Llama index has[hardcoded text](https://github.com/run-llama/llama_index/blob/e0d330e57dcf98b001f1b5989bdc46d5a21c8aaf/llama-index-core/llama_index/core/agent/workflow/react_agent.py?ref=blog.mozilla.ai#L123)for error handling. Many of the libraries may also have made opinionated decisions about the default`system\_prompt`used. Even if configurable parameters like temperature are set to 0, the difference in the prompt text that is provided to the LLM will result in different behavior.
### How should we evaluate which framework works best for our use?
The world of AI agents is just beginning, and with ever-expanding options, the question of how to choose a framework without locking into a specific API becomes important. Although the semantics and underlying code of each framework is different, many of them are intending to accomplish similar things at the high level, and we have found that it may be useful to provide a common language with which to build an agent, regardless of which framework you choose to build with.
To this end, today we’re sharing a library we’ve started working on called[Any-Agent](https://github.com/mozilla-ai/any-agent?ref=blog.mozilla.ai)! By using Any-Agent, you can build your agent a single time, and when you would like to experiment with the latest and greatest framework, switching to the new architecture can be as simple as changing the “AgentFramework” configuration parameter. In addition, Any-Agent handles normalization of logging (powered by[open-inference](https://github.com/Arize-ai/openinference?ref=blog.mozilla.ai)) so that you can see consistent outputs regardless of which framework you’ve selected.
We also have[provided a way to evaluate](https://mozilla-ai.github.io/any-agent/evaluation/?ref=blog.mozilla.ai)these Agents using a “trace-first” approach, which uses LLM-as-a-judge to help give you confidence that the agent performed the steps you expected!
### Example
Let's see a simple use case: Creating an agent in LangChain vs an agent in smolagents (note that most real agentic use cases will be far more complex than this, involving the use of many tools and maybe Model Context Protocol (MCP) servers as well).
Here’s the code to load an agent with LangChain:
```
`from langchain\_openai import ChatOpenAI
from langgraph.prebuilt import create\_react\_agent
model = ChatOpenAI(model="gpt-4o")
graph = create\_react\_agent(model)
def print\_stream(stream):
for s in stream:
message = s["messages"][-1]
if isinstance(message, tuple):
print(message)
else:
message.pretty\_print()
inputs = {"messages": [("user", "How many seconds would it take for a leopard at full speed to run through Pont des Arts?")]}
print\_stream(graph.stream(inputs, stream\_mode="values"))`
```
Here’s the code to load an agent with smolagents:
```
`from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel
model = HfApiModel()
agent = CodeAgent(model=model)
agent.run("How many seconds would it take for a leopard at full speed to run through Pont des Arts?")`
```
Now, here’s how you could run either of these using Any-Agent by changing only a single variable.
```
`from any\_agent import AgentConfig, AgentFramework, AnyAgent
agent = AnyAgent.create(
AgentFramework("langchain"), # Set to "langchain" or "smolagents"
AgentConfig(model\_id="gpt-4o-mini")
)
agent.run("How many seconds would it take for a leopard at full speed to run through Pont des Arts?")`
```
The Any-Agent library is also designed to load and configure MCP Servers for all agent frameworks, avoiding the need for a developer to understand the semantics of loading an MCP server for the agent framework that was selected.
### Conclusion
Building and evaluating with agent frameworks can be complex, but the Any-Agent library has made it much easier for our team to compare and test different agentic frameworks. AI Agents have incredible potential to supercharge productivity, and we’ve found Any-Agent to be a valuable tool in exploring that potential.
We hope that you’ll find this library useful in your experiments and projects, and we look forward to hearing your thoughts ([https://github.com/mozilla-ai/any-agent](https://github.com/mozilla-ai/any-agent?ref=blog.mozilla.ai)).
## Read more
[![Building in the Open at Mozilla.ai: 2025 Year in Review](https://blog.mozilla.ai/content/images/size/w600/2025/12/mozilla.ai-year-in-review-2025.png)
### Building in the Open at Mozilla.ai: 2025 Year in Review
The year 2025 has been a busy one at Mozilla.ai. From hosting live demos and speaking at conferences, to releasing our latest open-source tools, we have made a lot of progress and more exploration this year.
](https://blog.mozilla.ai/building-in-the-open-at-mozilla-ai-2025-year-in-review/)[![Polyglot AI Agents: WebAssembly Meets the Java Virtual Machine (JVM)](https://blog.mozilla.ai/content/images/size/w600/2025/12/Polyglot-AI-Agents.png)
### Polyglot AI Agents: WebAssembly Meets the Java Virtual Machine (JVM)
Leverage the JVM&#x27;s polyglot capabilities to create a self-contained, enterprise-optimized server-side blueprint that combines the performance benefits of WebAssembly with the reliability and maturity of Java&#x27;s ecosystem.
](https://blog.mozilla.ai/polyglot-ai-agents-webassembly-meets-the-java-virtual-machine-jvm/)[![Introducing any-llm managed platform: A secure cloud vault and usage-tracking service for all your LLM providers](https://blog.mozilla.ai/content/images/size/w600/2025/12/any-llm-platform.png)
### Introducing any-llm managed platform: A secure cloud vault and usage-tracking service for all your LLM providers
any-llm managed platform adds end-to-end encrypted API key storage and usage tracking to the any-llm ecosystem. Keys are encrypted client-side, never visible to us, while you monitor token usage, costs, and budgets in one place. Supports OpenAI, Anthropic, Google, and more.
](https://blog.mozilla.ai/introducing-any-llm-managed-platform-a-secure-cloud-vault-and-usage-tracking-service-for-all-your-llm-providers/)[![Encoderfile v0.1.0: Deploy Encoder Transformers as Single Binary Executables](https://blog.mozilla.ai/content/images/size/w600/2025/11/encoderfile--1-.png)
### Encoderfile v0.1.0: Deploy Encoder Transformers as Single Binary Executables
Encoderfile compiles encoders into single-binary executables with no runtime dependencies, giving teams deterministic, auditable, and lightweight deployments. Built on ONNX and Rust, Encoderfile is designed for environments where latency, stability, and correctness matter most.
](https://blog.mozilla.ai/encoderfile-v0-1-0-deploy-encoder-transformers-as-single-binary-executables/)
