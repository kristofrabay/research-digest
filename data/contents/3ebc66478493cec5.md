# Improving RAG Accuracy with Rerankers

**URL:** https://www.infracloud.io/blogs/improving-rag-accuracy-with-rerankers/
**Published:** 2024-08-26T00:00:00.000Z

---

## Summary

The webpage focuses on **Rerankers** and how they improve the accuracy of **Retrieval-Augmented Generation (RAG)** frameworks.

Here is a summary of the topics covered that relate to your query:

*   **Rerankers:** They are models used to re-evaluate and prioritize information retrieved by a base retriever based on its relevance to the user's query, leading to more specific and pertinent answers.
*   **Embeddings:** Rerankers are built on top of embeddings, which convert text into numerical vectors that LLMs use for processing and retrieval.
*   **RAG Architectures:** The article details how rerankers are integrated into the existing RAG pipeline, specifically showing a workflow where a reranker acts as a compressor/filter after the initial retrieval step.
*   **Types of Rerankers:** Three main types are discussed: BERT-based, Cross-Encoder (high precision, high latency), and Bi-Encoder (efficient, scalable).
*   **Considerations:** Key factors for selecting a reranker include Relevance, Latency, Scalability, and Integration.
*   **Open source vs. closed source reranker models:** The trade-offs between transparency/flexibility (open source) and high performance/support (closed source) are outlined.

The page **does not** explicitly discuss: Vector databases, new efficient embedding models (beyond mentioning embeddings are used), RAG alternatives, hybrid search, or chunking strategies.

---

## Full Content

Improving RAG Accuracy with Rerankers
[Exciting news! We're joining forces with Improving - a global leader in digital services with 20+ years of experience üöÄRead More-\>](https://improving.com/thoughts/infracloud-acquisition/)
![Improving RAG Accuracy with Rerankers](https://www.infracloud.io/assets/img/Blog/rag-optimization-with-rerankers/enhancing-insightful-with-a-reranker-1600x350.webp)
* [Blogs](https://www.infracloud.io/blogs/)
* [AI Cloud](https://www.infracloud.io/blogs/category/ai-cloud/)# Improving RAG Accuracy with Rerankers
![Shreyas Mocherla](https://www.infracloud.io/assets/img/author/1x/shreyas-mocherla.webp)
Shreyas Mocherla
26thAugust 2024
12 mins
In our previous post, we talked about[creating an AI agent for technical communities](https://www.infracloud.io/blogs/developing-ai-agent-for-smart-contextual-qna/)that can use the conversation history amongst colleagues and other members to answer the user‚Äôs common questions.[InSightful](https://github.com/infracloudio/insightful/tree/main)is the agent we built that uses the Reasoning and Action (ReAct) approach to respond to user queries accurately. However, during the retrieval process the generalization of the retrieved information causes the agent to provide a high-level overview of the information. You can greatly improve the results of the retrieved information from the conversation history within a community by retrieving relevant**specific**information according to a query. This can be achieved with a reranker.
In this blog post, we will explore rerankers, types of rerankers, selecting an appropriate reranker for your project, and implementing it in an existing application to improve the[Retrieval- Augmented Generation (RAG)](https://www.infracloud.io/blogs/retrieval-augmented-generation-using-data-with-llms/)framework.
## What are rerankers?
Rerankers are models used to ‚Äúrerank‚Äù retrieved information based on its relevance to a user‚Äôs query. After a base[retriever model](https://www.infracloud.io/blogs/vector-databases-beginners-guide/)retrieves information from a data source, this information is passed to the reranker model. The reranker then evaluates and prioritizes the most relevant pieces of information according to the user‚Äôs query. This process significantly enhances the quality of the Agent‚Äôs generated response by ensuring that it utilizes the most pertinent information retrieved in relation to the user‚Äôs question.
## How do rerankers work?
An embedding model converts text and information into numerical data that can be understood and processed by a Large Language Model (LLM). It places the tokenized text into vectors, enabling vector operations. These embeddings allow the LLM to augment its responses with retrieved information, powering the Retrieval-Augmented Generation (RAG) framework.
Rerankers are built on top of embeddings. They take the retrieved embeddings, obtained through[similarity search or maximum marginal relevance search](https://wiki.genexus.com/enterprise-ai/wiki?206,VectorStore+Search+Options#), and prioritize the information based on relevance.
In other words, rerankers act as a ‚Äúfilter‚Äù on top of embeddings. Their singular aim is to determine the most relevant information by performing their own similarity search or maximum marginal relevance search on the retrieved embeddings.
![Working of a reranker](https://www.infracloud.io/assets/img/Blog/rag-optimization-with-rerankers/working-of-a-reranker.webp)
[(Working of a reranker)](https://www.pinecone.io/learn/series/rag/rerankers/)
## Considerations when selecting rerankers
There are several factors that you should consider when selecting a reranker, such as your use case, nature of data, and performance characteristics you require. Regardless of these factors, you must be sure to check off certain criteria before proceeding with a said reranker model, here are some to keep in mind:
* **Relevance**: Determine the level of precision needed in the retrieval tasks.
* **Latency**: Consider how quickly you want the reranker to produce results. This is especially important in production environments where mission critical tasks are of utmost importance.
* **Scalability**: Analyze if the reranker can handle the existing and expected volume of data, number of users and frequency of queries.
* **Integration**: The selected reranker should be able to integrate with the existing systems and workflows.
With these considerations in mind, let‚Äôs explore the different types of rerankers.
## Types of rerankers
Primarily, there are 3 types of rerankers:
* **BERT-based:**These rerankers utilize the[BERT](https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;opi=89978449&amp;url=https://en.wikipedia.org/wiki/BERT_(language_model)#:~:text=Bidirectional%20Encoder%20Representations%20from%20Transformers,state%20of%20the%20art%20models.&amp;ved=2ahUKEwiFr5jAhdOHAxWPyTgGHfVZE5sQFnoECCIQAw&amp;usg=AOvVaw0tBrvbwCRKDtMHm5P35RBS)model to rerank embeddings. BERT‚Äôs bidirectional nature allows for a deep contextual understanding of the text, improving the relevance of search results by considering the context of both the query and the document.
* **Cross-Encoder:**Cross-encoders handle the document and query together, encoding them simultaneously. This method allows for a more integrated and nuanced understanding of their relationship, which can significantly enhance the precision of relevance scoring. The joint encoding process enables the model to directly learn and evaluate the interactions between the query and document, providing a high level of accuracy in reranking.
* **Bi-Encoder:**Bi-encoders handle the document and query separately, making them more suitable for large datasets and real-time applications. They independently generate embeddings for the query and document, which are then compared using a similarity metric such as cosine similarity. This approach allows for efficient retrieval and scalability.
The Cross-Encoder and Bi-Encoder also use BERT to encode the document, however, the approach for each of these is different. Here‚Äôs a diagram to reinforce these concepts:
![Difference Between Bi-Encoder and Cross-Encoder](https://www.infracloud.io/assets/img/Blog/rag-optimization-with-rerankers/difference-between-bi-encoder-and-cross-encoder.webp)
[(Difference Between Bi-Encoder and Cross-Encoder)](https://www.sbert.net/examples/applications/cross-encoder/README.html)
## Choosing a reranker: BERT-based vs Cross-Encoder vs Bi-Encoder
As we‚Äôve discussed the types of rerankers, let‚Äôs see how we choose the best reranker for our use case. For this, we‚Äôll break down the pros and cons of each type to make the decision easier.
|**Reranker Type**|**Pros**|**Cons**|**Best Use Cases**|
BERT-based Rerankers|Deep contextual understanding: BERT‚Äôs bidirectional nature allows it to capture the context of words within a sentence, leading to highly accurate relevance scoring.
Fine-Tuning capability: These models can be fine-tuned on specific datasets to improve performance on particular tasks.|Computationally intensive: BERT models are large and require significant compute resources for training and inference.
High latency: They suffer from high latency, making them unsuitable for real-time applications such as recommendation systems and search engines.|Enterprise search: Retrieval of the most relevant internal documents, emails, and reports where precision is critical, and immediate results are not necessary.
Academic research: Finding the most pertinent academic papers and articles from large databases.|
Cross-Encoders|High precision: By jointly encoding the query and document, cross-encoders capture detailed interactions and provide high relevance precision.
Effective contextual understanding: They excel at understanding the complex relationships between the query and document, leading to more accurate relevance assessments.|High latency: Processing each query-document pair together is computationally expensive and time-consuming.
Scalability issues: Not ideal for large-scale or real-time applications due to the intensive computational requirements.|Question Answering systems: Providing precise and contextually appropriate answers to user queries.
Legal and Medical document retrieval: Retrieving the most relevant guidelines, research papers, and legal documents where detailed understanding is crucial.|
Bi-Encoders|Efficiency: Embeddings can be precomputed, allowing for fast retrieval and ranking.
Scalability: Suitable for large datasets and real-time applications due to lower computational requirements.|Potential precision trade-off: May not capture the intricate interactions between the query and document as effectively as cross-encoders, potentially leading to slightly lower precision.|Real-Time applications: Search engines, chatbots, and recommendation systems where quick responses are essential.
Large-Scale retrieval: Scenarios involving large datasets where efficiency and scalability are crucial.|
By understanding the strengths and weaknesses of each type of reranker, you can choose the best one for your specific use case, balancing the trade-offs between precision, efficiency, and scalability. This approach ensures that your information retrieval system is optimized for the task at hand, providing the best possible user experience.
### Open source vs closed source reranker models
With the increasing advocacy for open source AI technologies, there are numerous reranker models being developed and open-sourced online. For example, platforms like HuggingFace host a growing number of models in various fields of AI. Conversely, some companies have developed proprietary models and offer limited developer access through APIs. Notable companies include Anthropic, OpenAI, and NVIDIA.
Open source rerankers provide transparency and accessibility as their source code is available for inspection, modification, and improvement, fostering trust and community contributions. However, they can be resource-intensive, requiring significant computational resources and ongoing maintenance.
Closed-source rerankers, on the other hand, are known for high performance due to optimized models and advanced features resulting from extensive research and development. They offer reliability and support through dedicated customer service and Service Level Agreements (SLAs), ensuring prompt issue resolution and uptime guarantees. However, they come with significant costs, including usage fees and subscription costs, and lack transparency, as the inner workings are not available for inspection.
Ultimately, the two choices boil down to this:
* Open source rerankers offer flexibility, cost-effectiveness, and transparency, making them ideal for those with the necessary technical expertise and infrastructure.
* Closed-source rerankers, on the other hand, provide high performance, reliability, and ease of use, which are critical for enterprise applications requiring robust support and scalability.## Implementing a reranker in an existing application
Let‚Äôs now move on to the more practical aspects of a reranker and see it in action. Before jumping into the code and demo, let‚Äôs see a comparison between a reranker workflow and a non-reranker workflow:
![Workflow with and without Reranker](https://www.infracloud.io/assets/img/Blog/rag-optimization-with-rerankers/workflow-with-and-without-reranker.webp)
(Workflow with and without Reranker)
For clarity, the new sub-workflow of the reranker is numbered. The reranker ranks the documents after the documents are retrieved by the document retriever and returns it back to the function call which is then passed to the agent to generate its response.
```
`defcreate\_reranker\_retriever(name,model,description,client,chroma\_embedding\_function,embedder):rag=RAG(llm=model,embeddings=embedder,collection\_name="Slack",db\_client=client)pages=rag.load\_documents("spencer/software\_slacks",num\_docs=100)chunks=rag.chunk\_doc(pages)vector\_store=rag.insert\_embeddings(chunks,chroma\_embedding\_function,embedder)compressor=TEIRerank(url="http://{host}:{port}".format(host=os.getenv("RERANKER\_HOST","localhost"),port=os.getenv("RERANKER\_PORT","8082")),top\_n=10,batch\_size=16)retriever=vector\_store.as\_retriever(search\_type="similarity",search\_kwargs={"k":100})compression\_retriever=ContextualCompressionRetriever(base\_compressor=compressor,base\_retriever=retriever)info\_retriever=create\_retriever\_tool(compression\_retriever,name,description)returninfo\_retriever`
```
[(Developing a reranker as a tool)](https://github.com/infracloudio/insightful/blob/main/app.py#L190)
We start off with the usual RAG pipeline and create a retriever object of the vector store. The usage of vector store as a retriever is provided by LangChain. We developed our own`RAG`class and provide a set of standard arguments that are required for RAG. When we are loading the documents, we can specify the number of documents we want to download from the dataset. The dataset is a table with several rows, so the num\_docs parameter specifies the number of rows to download in our case.
In essence, this code snippet describes how a reranker is initialized in LangChain. The regular retrieving process followed through until`retriever`, then we use this as a base retriever and use it with a reranker. A[compressor](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/contextual_compression/)is used to compress context, and our reranker achieves this while retaining the most relevant information in the context. With a blend of the base retriever and the reranker, we create a new retrieval tool that is fed to our agent.
### TEI Rerank and LangChain
As of the time of writing, LangChain does not have an integration with the HuggingFace Text Embedding Inference (TEI) Server‚Äôs Rerank endpoint which caused us to write our own adapter to bring these two together. Here‚Äôs the link to our work for your reference:[InSightful Reranker](https://github.com/infracloudio/insightful/tree/reranker).
## Performance of InSightful with and without reranker
Let‚Äôs now look at the demo of InSightful‚Äôs performance. Observe the quality of response between the approaches.
![With a reranker](https://www.infracloud.io/assets/img/Blog/rag-optimization-with-rerankers/with-a-reranker.webp)
(With a reranker)
![Without a reranker](https://www.infracloud.io/assets/img/Blog/rag-optimization-with-rerankers/without-a-reranker.webp)
(Without a reranker)
As you can see, the reranker provides a more precise answer, using an actual message sent by a participant in the conversation to generate its response. On the other hand, not using a reranker provides a high-level overview of the general discussion on. As the amount of information increases, the reranker will do a better job at providing concise and accurate information according to the user‚Äôs query.
## Conclusion
In this blog post, we demystified rerankers and stripped it down to the very fundamentals. The references section has additional primers that you may find useful to understand rerankers. We hope that you can use this article as a guide that you can always come back to when you want to use a reranker for your own applications. With the provided code repo, you may also use it as a template and create your own versions. However, having an efficient and scalable cloud infrastructure is crucial for building an AI application.[AI &amp; GPU Cloud experts](https://www.infracloud.io/build-ai-cloud/)can help you achieve this.
We hope you found this article as useful as intended. If you have any feedback, suggestions, or questions, please feel free to reach out to[Shreyas on LinkedIn](https://www.linkedin.com/in/aiwithshrey/).
## References
* [Pinecone Rerankers](https://www.pinecone.io/learn/series/rag/rerankers/)
* [Rerankers](https://docs.voyageai.com/docs/reranker)
* [Mastering RAG: How to Select A Reranking Model - Galileo](https://www.rungalileo.io/blog/mastering-rag-how-to-select-a-reranking-model)
* [Boosting RAG: Picking the Best Embedding &amp; Reranker models ‚ÄîLlamaIndex, Data Framework for LLM Applications](https://www.llamaindex.ai/blog/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83)
* [Say Hello to Precision: How Rerankers and Embeddings Boost Search](https://cohere.com/blog/say-hello-to-precision-how-rerankers-and-embeddings-boost-search)
## Stay updated with latest in AI and Cloud Native tech
We hate üòñspam as much as you do! You're in a safe company.
Only delivering solid AI &amp; cloud native content.
Email is required
Subscribe to Newsletter
In this Blog
* [What are rerankers?](#what-are-rerankers)
* [How do rerankers work?](#how-do-rerankers-work)
* [Considerations when selecting rerankers](#considerations-when-selecting-rerankers)
* [Types of rerankers](#types-of-rerankers)
* [Choosing a reranker: BERT-based vs Cross-Encoder vs Bi-Encoder](#choosing-a-reranker-bert-based-vs-cross-encoder-vs-bi-encoder)
* [Open source vs closed source reranker models](#open-source-vs-closed-source-reranker-models)
* [Implementing a reranker in an existing application](#implementing-a-reranker-in-an-existing-application)
* [TEI Rerank and LangChain](#tei-rerank-and-langchain)
* [Performance of InSightful with and without reranker](#performance-of-insightful-with-and-without-reranker)
* [Conclusion](#conclusion)
* [References](#references)
![](https://www.infracloud.io/assets/img/generic/logo-for-black-bg.svg)
We Make AI Cloud Easy
Helping you build AI cloud for your specific needs.
[Learn More](https://www.infracloud.io/build-ai-cloud/)
Share this Blog
* * * * * ### Posts You Might Like
[
![](https://www.infracloud.io/assets/img/Blog/ai-agents-for-kubernetes/ai-agents-for-kubernetes-1200x628.png)
AI Cloud
#### AI Agents for Kubernetes: Getting Started with Kagent
Adding AI into Kubernetes with Kagent, giving Gemini awareness of Kubernetes environment to deliver smarter insights, suggestions, and simplified operations.
![Debjyoti Maity](https://www.infracloud.io/assets/img/author/1x/debjyoti-maity.webp)
Debjyoti Maity
12thSeptember 202516 mins
](https://www.infracloud.io/blogs/ai-agents-for-kubernetes/)
[
![](https://www.infracloud.io/assets/img/Blog/ai-workload-cost-optimization/cost-optimization-for-ai-cloud-workloads-1200x628.png)
AI Cloud
#### Cost Optimization Strategies for AI Workloads
Explore the cost drivers of AI cloud workloads and discover proven strategies to cut expenses without compromising performance or scalability.
![Y Sarvani](https://www.infracloud.io/assets/img/author/1x/y-sarvani.webp)
Y Sarvani
11thAugust 202516 mins
](https://www.infracloud.io/blogs/ai-workload-cost-optimization/)
[![Glassdoor rating](https://www.infracloud.io/assets/img/generic/glassdoor-rating.svg)](https://www.glassdoor.co.in/Reviews/InfraCloud-Technologies-Reviews-E2051738.htm)
![Cloud Native](https://www.infracloud.io/assets/img/generic/cncf-stacked-color.svg)
![Kubernetes certified](https://www.infracloud.io/assets/img/generic/kubernetes-kcsp-color.svg)![Stratus Award](https://www.infracloud.io/assets/img/generic/certified-tag-2.svg)![ISO](https://www.infracloud.io/assets/img/generic/iso.svg)[![Great place to work](https://www.infracloud.io/assets/img/generic/certified-tag.svg)](https://www.infracloud.io/careers/)
![InfraCloud](https://www.infracloud.io/assets/img/infracloud.svg)
We unleash growth by helping companies adopt cloud native technologies with our products and services!
![Footer Background](https://www.infracloud.io/assets/img/generic/footer-bg-element.svg)
![Footer Background](https://www.infracloud.io/assets/img/generic/footer-bg-element.svg)
![Footer Background](https://www.infracloud.io/assets/img/generic/footer-bg-element.svg)
![Footer Background](https://www.infracloud.io/assets/img/generic/footer-bg-element.svg)
![Footer Background](https://www.infracloud.io/assets/img/generic/footer-bg-element.svg)
![Footer Background](https://www.infracloud.io/assets/img/generic/footer-bg-element.svg)
* [Terms](https://www.infracloud.io/terms-and-conditions/)
* [Privacy](https://www.infracloud.io/privacy-policy/)
* [Employee Data Privacy](https://www.infracloud.io/employee-data-privacy-policy/)
* [Equal Opportunity](https://www.infracloud.io/equal-opportunity-policy/)
* [Sitemap](https://www.infracloud.io/sitemap/)
* Global Presence :
* USA
* Canada
* M√©xico
* Argentina
* Chile
* India
&copy; 2025 InfraCloud
This website uses cookies to offer you a better browsing experience
![check-mark](https://www.infracloud.io/assets/img/check-mark-icon.svg)Accept
