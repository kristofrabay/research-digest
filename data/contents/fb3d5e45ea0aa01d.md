# Computer Science > Artificial Intelligence

**URL:** https://arxiv.org/abs/2502.12521
**Published:** 2025-02-18T00:00:00.000Z

---

## Summary

The webpage is an abstract for the arXiv paper "[2502.12521] Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights."

The paper examines the **reasoning and planning capabilities of Large Language Models (LLMs)** using **inference-time techniques** (techniques applied during inference without additional training) to enhance performance. It specifically mentions the novel multi-step reasoning and verification used by OpenAI's o1 model.

The authors constructed a comprehensive benchmark called **Sys2Bench** and evaluated existing inference-time techniques across eleven diverse tasks covering arithmetic, logical, common sense, algorithmic reasoning, and **planning**.

The key finding is that **scaling inference-time computation has limitations**, as no single technique consistently performs well across all reasoning and planning tasks.

This directly addresses several parts of your query: **reasoning and planning with LLMs**, **inference-time compute**, and implicitly touches upon the need for better reasoning techniques (which relates to hallucination reduction and grounding, though these specific terms are not detailed in the abstract).

---

## Full Content

[2502.12521] Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights
[Skip to main content](#content)
[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)
In just 5 minutes help us improve arXiv:
[Annual Global Survey](https://cornell.ca1.qualtrics.com/jfe/form/SV_6kZEJCkEgp3yGZo)
We gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)
[](https://arxiv.org/IgnoreMe)
[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2502.12521
[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)
All fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text
Search
[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)
[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)
open search
GO
open navigation menu
# Computer Science \> Artificial Intelligence
**arXiv:2502.12521**(cs)
[Submitted on 18 Feb 2025]
# Title:Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights
Authors:[Shubham Parashar](https://arxiv.org/search/cs?searchtype=author&amp;query=Parashar,+S),[Blake Olson](https://arxiv.org/search/cs?searchtype=author&amp;query=Olson,+B),[Sambhav Khurana](https://arxiv.org/search/cs?searchtype=author&amp;query=Khurana,+S),[Eric Li](https://arxiv.org/search/cs?searchtype=author&amp;query=Li,+E),[Hongyi Ling](https://arxiv.org/search/cs?searchtype=author&amp;query=Ling,+H),[James Caverlee](https://arxiv.org/search/cs?searchtype=author&amp;query=Caverlee,+J),[Shuiwang Ji](https://arxiv.org/search/cs?searchtype=author&amp;query=Ji,+S)
View a PDF of the paper titled Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights, by Shubham Parashar and 6 other authors
[View PDF](https://arxiv.org/pdf/2502.12521)[HTML (experimental)](https://arxiv.org/html/2502.12521v1)> > Abstract:
> We examine the reasoning and planning capabilities of large language models (LLMs) in solving complex tasks. Recent advances in inference-time techniques demonstrate the potential to enhance LLM reasoning without additional training by exploring intermediate steps during inference. Notably, OpenAI&#39;s o1 model shows promising performance through its novel use of multi-step reasoning and verification. Here, we explore how scaling inference-time techniques can improve reasoning and planning, focusing on understanding the tradeoff between computational cost and performance. To this end, we construct a comprehensive benchmark, known as Sys2Bench, and perform extensive experiments evaluating existing inference-time techniques on eleven diverse tasks across five categories, including arithmetic reasoning, logical reasoning, common sense reasoning, algorithmic reasoning, and planning. Our findings indicate that simply scaling inference-time computation has limitations, as no single inference-time technique consistently performs well across all reasoning and planning tasks. Subjects:|Artificial Intelligence (cs.AI); Machine Learning (cs.LG)|
Cite as:|[arXiv:2502.12521](https://arxiv.org/abs/2502.12521)[cs.AI]|
|(or[arXiv:2502.12521v1](https://arxiv.org/abs/2502.12521v1)[cs.AI]for this version)|
|[https://doi.org/10.48550/arXiv.2502.12521](https://doi.org/10.48550/arXiv.2502.12521)
Focus to learn more
arXiv-issued DOI via DataCite
|
## Submission history
From: Shubham Parashar [[view email](https://arxiv.org/show-email/49541ab0/2502.12521)]
**[v1]**Tue, 18 Feb 2025 04:11:29 UTC (313 KB)
Full-text links:## Access Paper:
View a PDF of the paper titled Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights, by Shubham Parashar and 6 other authors
* [View PDF](https://arxiv.org/pdf/2502.12521)
* [HTML (experimental)](https://arxiv.org/html/2502.12521v1)
* [TeX Source](https://arxiv.org/src/2502.12521)
[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)
Current browse context:
cs.AI
[&lt;&lt;prev](https://arxiv.org/prevnext?id=2502.12521&amp;function=prev&amp;context=cs.AI) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2502.12521&amp;function=next&amp;context=cs.AI)
[new](https://arxiv.org/list/cs.AI/new)|[recent](https://arxiv.org/list/cs.AI/recent)|[2025-02](https://arxiv.org/list/cs.AI/2025-02)
Change to browse by:
[cs](https://arxiv.org/abs/2502.12521?context=cs)
[cs.LG](https://arxiv.org/abs/2502.12521?context=cs.LG)
### References &amp; Citations
* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2502.12521)
* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2502.12521)
* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2502.12521)
export BibTeX citationLoading...
## BibTeX formatted citation
&times;
loading...
Data provided by:
### Bookmark
[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)]()
Bibliographic Tools
# Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*
Connected Papers Toggle
Connected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*
Litmaps Toggle
Litmaps*([What is Litmaps?](https://www.litmaps.co/))*
scite.ai Toggle
scite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*
Code, Data, Media
# Code, Data and Media Associated with this Article
alphaXiv Toggle
alphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*
Links to Code Toggle
CatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*
DagsHub Toggle
DagsHub*([What is DagsHub?](https://dagshub.com/))*
GotitPub Toggle
Gotit.pub*([What is GotitPub?](http://gotit.pub/faq))*
Huggingface Toggle
Hugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*
Links to Code Toggle
Papers with Code*([What is Papers with Code?](https://paperswithcode.com/))*
ScienceCast Toggle
ScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*
Demos
# Demos
Replicate Toggle
Replicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*
Spaces Toggle
Hugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*
Spaces Toggle
TXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*
Related Papers
# Recommenders and Search Tools
Link to Influence Flower
Influence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*
Core recommender toggle
CORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*
* Author
* Venue
* Institution
* Topic
About arXivLabs
# arXivLabs: experimental projects with community collaborators
arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.
Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.
Have an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).
[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2502.12521)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))
