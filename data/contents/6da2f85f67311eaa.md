# Reasoning in LLMs as MCTS over Tokens (Motivation and three papers)

**URL:** https://www.linkedin.com/pulse/reasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc
**Published:** 2024-12-09T00:00:00.000Z

---

## Summary

The webpage discusses **Reasoning in LLMs as MCTS over Tokens**, focusing on how **Monte Carlo Tree Search (MCTS)** can be integrated with Large Language Models (LLMs) to improve their capabilities in **planning** and **reasoning**.

Key points related to your query:

*   **Reasoning LLMs & Planning with LLMs:** LLMs often struggle with long-term planning and goal-conditioned reasoning because they are trained primarily for next-token prediction. Integrating MCTS allows LLMs to explore multiple potential continuations, simulate outcomes, and guide generation towards long-term objectives.
*   **MCTS (Monte Carlo Tree Search) for language models:** MCTS is presented as a method to transform the LLM reasoning process into a strategic exploration of solutions. It involves defining **states** (the current status of reasoning), **actions** (meaningful reasoning moves or next tokens), and a **reward mechanism** to guide the search toward successful outcomes. This helps LLMs navigate the vast search space of language generation.
*   **Inference-time compute:** The MCTS process inherently involves additional computation at inference time as it iteratively builds and explores a search tree to find optimal solutions.

The page does not explicitly detail concepts like *chain-of-thought*, *self-reflection*, *test-time scaling*, *hallucination reduction and detection*, *grounding*, or *factuality* in depth, although improving coherence and optimizing reasoning through MCTS might indirectly address some of these issues.

---

## Full Content

LinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including **professional and job ads**) on and off LinkedIn. Learn more in our [Cookie Policy](https://www.linkedin.com/legal/cookie-policy).

Select Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your [settings](https://www.linkedin.com/mypreferences/g/guest-cookies).

Accept

Reject

Agree & Join LinkedIn

By clicking Continue to join or sign in, you agree to LinkedInâ€™s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy).

`` `` `` `` `` ``

 `` `` `` `` `` `` `` [Skip to main content](https://www.linkedin.com/pulse/reasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc#main-content)

`` `` `` ``

![Reasoning in LLMs as MCTS over Tokens (Motivation and three papers)](https://media.licdn.com/dms/image/v2/D5612AQG5US_NKao4Ig/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1733758935346?e=2147483647&v=beta&t=1RpJMNpVWPSIdIPto4HQpdUqaAcvFebrApFn8bMlGPU)

Monte Carlo Tree Search (MCTS) is a heuristic method for making optimal decisions. It benefits areas with many choices, such as games, planning and model-based optimisation problems. While the concepts behind MCTS have been around for decades, the method gained significant attention in the mid-2000s due to its success in game-playing AI, e.g., AlphaGo, which used MCTS to beat professional human players in the game of Go. In addition, MCTS has found applications in robotics, automated planning \\cite{MCTSPlanning}, and even drug discovery. Those successes and the effectiveness of MCTS in handling large search spaces without brute force search made it a valuable tool for modern AI.

In the 2010s and early 2020s, AI graduated from computer games and mastered human-like text generation with the advent of large-scale neural networks, large computing clusters, and internet-scale data. This period saw the rise of large language models (LLMs), which leveraged massive datasets and billions of parameters to achieve unprecedented performance in natural language processing tasks. These models demonstrated a remarkable ability to generate coherent, contextually appropriate text, making them transformative tools that reshaped academia, industry and humanity, I dare to say.

Why MCTS for LLMs: While LLMs excel at producing fluent and contextually relevant responses, they face challenges in tasks requiring long-term planning, reasoning, or exploration of complex decision spaces. This behaviour is unsurprising, given that those models are trained primarily on next-token prediction. Their objective is to generate the next most likely token based on prior context rather than to think ahead strategically or work towards a specific goal. As a result, they could refrain from engaging in goal-conditioned reasoning and instead focus on producing locally plausible outputs that may lack logical consistency. For example, when solving complex mathematical problems or making strategic decisions in a game-like setting, LLMs may generate locally plausible outputs but lack global optimality.

This is one place where Monte Carlo tree search can play a crucial role for LLMs. By integrating MCTS into LLMs' reasoning and decision-making process, it becomes possible to explore multiple potential continuations, simulate their outcomes, and use these simulations to guide the generation process. MCTS provides a potentially practical approach to navigating the vast search space of language generation, balancing the exploration of creative possibilities while exploiting promising paths that meet the goal in question. Incorporating MCTS with LLMs opens up opportunities to 1) Improve Planning: MCTS can help LLMs evaluate multiple steps ahead, ensuring that decisions align with long-term objectives or constraints; 2) Improve Coherence: By simulating and assessing the outcomes of different branches, MCTS reduces the risk of contradictions or inconsistencies in the generated text; 3) Optimise Reasoning: MCTS allows LLMs to explore diverse problem-solving strategies and identify the most effective approach; 4) Handle Large Action/Token Spaces: MCTS can systematically explore the vast vocabulary and possible sequences, focusing on the most promising options.

This synergy between MCTS and LLMs holds the potential to address critical limitations in current language models, enabling them to tackle more complex, multi-step reasoning tasks with greater precision and reliability.

How to reformulate: Reformulating the reasoning capabilities of large language models (LLMs) through Monte Carlo Tree Search (MCTS) offers a structured and efficient framework for navigating complex problem-solving tasks. Traditionally, LLMs generate responses by predicting one token at a time, leading to sprawling and unmanageable search spaces, especially for multi-step reasoning. By integrating MCTS, we can transform the reasoning process into a strategic exploration of possible solutions, enhancing the efficiency and accuracy of the modelâ€™s outputs.

At the core of this approach is the concept of the state. In the context of MCTS-driven reasoning, a state represents the current status of the reasoning process. This includes all the information accumulated up to that point, such as the partially constructed solution, relevant context from the input prompt, and any intermediate conclusions drawn. Unlike raw text, which can be vast and unstructured, each state serves as a concise snapshot that captures the essential elements needed to proceed further in the reasoning chain. This structured representation allows MCTS to evaluate and navigate through the different stages of problem-solving effectively.

Actions within this framework are defined as the potential next steps the model can take from any given state. These actions correspond to meaningful reasoning moves, such as applying a specific mathematical operation, invoking a particular rule or theorem, or making an inference based on the current information. By discretizing the possible actions, MCTS can systematically explore various paths, assessing which actions are most likely to lead to a successful and coherent solution. This contrasts with the token-by-token generation approach, where the model lacks a strategic overview of the reasoning process.

The reward mechanism is integral to guiding the MCTS process. Rewards are assigned based on the outcomes of reasoning paths, reflecting the correctness, efficiency, and relevance of the solutions generated. For instance, successfully solving a problem or arriving at a valid conclusion would yield a high reward, while incorrect or irrelevant paths receive lower or no rewards. This reward structure enables MCTS to prioritise actions more likely to lead to desirable outcomes, effectively learning which reasoning strategies are most effective over time.

Implementing MCTS with LLMs involves constructing a search tree where each node represents a state, and each edge represents an action leading to a new state. The MCTS algorithm iteratively builds this tree by selecting promising nodes to explore, expanding them by applying possible actions, simulating potential outcomes, and backpropagating the rewards to update the value estimates of the traversed states. This process balances the exploration of new reasoning paths with the exploitation of known successful strategies, ensuring a comprehensive yet efficient search for optimal solutions.

## Recommended by LinkedIn

[ðŸ”‹ Fixing AI's Energy Consumption\
\
Pascal Biese\
6 months ago](https://www.linkedin.com/pulse/fixing-ais-energy-consumption-pascal-biese-sndjf)

[Probabilistic Nearest Neighbors: The Swiss Army Knifeâ€¦\
\
Vincent Granville\
10 months ago](https://www.linkedin.com/pulse/probabilistic-nearest-neighbors-swiss-army-knife-genai-granville-lmoec)

[Introduction to Prompt Engineering: The Alchemy of AIâ€¦\
\
Reuven Cohen\
1 year ago](https://www.linkedin.com/pulse/introduction-prompt-engineering-alchemy-ai-future-creativity-cohen)

One of the key advantages of framing reasoning as an MCTS search is the enhanced decision-making capability it provides to LLMs. By systematically evaluating multiple reasoning paths and leveraging the reward signals, MCTS helps the model avoid common pitfalls such as getting stuck in loops or following incorrect logic. Additionally, this structured approach improves the interpretability of the reasoning process, as each step can be traced and analyzed based on the actions taken and the resulting states. This transparency is particularly valuable for complex tasks where understanding the reasoning pathway is as important as the final answer.

Here are three paper summaries that attempted to do that, which I found to be interesting:

I will continue to add those as I go through the literature. If you find it interesting, make sure to like, follow and research.

See you soon!

[Less-Hyped AI](https://www.linkedin.com/newsletters/less-hyped-ai-6980067977496797184)

### Less-Hyped AI

#### 3,372 followers

[\+ Subscribe](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc)

`` `` `` `` ``

``

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_like-toggle_like-cta)

Like

Celebrate

Support

Love

Insightful

Funny

[Comment](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_comment-cta)

`` ``

- Copy
- LinkedIn
- Facebook
- Twitter

Share

`` ``

[81](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_likes-count_social-actions-reactions) `` `` `` `` `` `` `` [8 Comments](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_likes-count_social-actions-comments)

[Jamal El Kuweiss](https://de.linkedin.com/in/jamal-el-kuweiss?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)

Consultant

4mo

- [Report this comment](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)

Interesting read, thank you :)
Couple of questions:
1) What do you foresee as a major obstacle in the implementation of MCTS into commercial LLMS?
2) How would one set the rewards for the MCTS process in this case? How would it look like? What kind of data?

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply) [2Â Reactions](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reactions) 3Â Reactions

[Warren Powell](https://www.linkedin.com/in/warrenbpowell?trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_actor-name)

Professor Emeritus, Princeton University/
Co-Founder, Optimal Dynamics/
Executive-in-Residence Rutgers Business School

4mo

- [Report this comment](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)

MCTS is a model-based direct lookahead approximationâ€¦ this is fundamentally different than training a LLM which is completely dependent on a training dataset. MCTS requires a model of the problem (more precisely, an approximate model for the lookahead policy) but does not require a training dataset.

[Like](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_like) [Reply](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reply) [11Â Reactions](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments-action_comment_reactions) 12Â Reactions

[See more comments](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_comments_comment-see-more)

To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_x-social-details_feed-cta-banner-cta)

## More articles by Haitham Bou-Ammar

- [From VR to Grippers: How We Built a Bimanual Robot That Learns](https://www.linkedin.com/pulse/from-vr-grippers-how-we-built-bimanual-robot-learns-haitham-bou-ammar-0a5fe)







Apr 6, 2025



### From VR to Grippers: How We Built a Bimanual Robot That Learns



In recent years, weâ€™ve seen enormous progress in AI â€” from large language models to powerful vision systems. Howeverâ€¦

`` ``



31

`` `` `` `` `` `` ``

3 Comments

- [Short Circuit â€” Let AI Design Your Chips](https://www.linkedin.com/pulse/short-circuit-let-ai-design-your-chips-haitham-bou-ammar-6wkxe)







Aug 28, 2024



### Short Circuit â€” Let AI Design Your Chips



Introduction The rapid expansion of artificial intelligence (AI) applications has significantly increased computationalâ€¦

`` ``



29

`` `` `` `` `` `` ``

- [New Grounds in Theorem Proving with DeepSeek-Prover-V1.5](https://www.linkedin.com/pulse/new-grounds-theorem-proving-deepseek-prover-v15-%D9%87%D9%8A%D8%AB%D9%85-%D8%A8%D9%88-%D8%B9%D9%85%D8%A7%D8%B1-x7sle)







Aug 18, 2024



### New Grounds in Theorem Proving with DeepSeek-Prover-V1.5



DeepSeek-Prover-V1.5 represents a significant leap forward from its predecessor, DeepSeek-Prover-V1.

`` ``



16

`` `` `` `` `` `` ``

- [Deriving DPO's Loss](https://www.linkedin.com/pulse/deriving-dpos-loss-haitham-bou-ammar-%D9%87%D9%8A%D8%AB%D9%85-%D8%A8%D9%88-%D8%B9%D9%85%D8%A7%D8%B1-ul4bf)







Aug 15, 2024



### Deriving DPO's Loss



Direct preference optimisation has become critical for aligning LLMs with human preferences. I have been talking toâ€¦

`` ``



21

`` `` `` `` `` `` ``

- [Model Predictive Control from Mere Natural Language Commands](https://www.linkedin.com/pulse/model-predictive-control-from-mere-natural-language-%D9%87%D9%8A%D8%AB%D9%85-%D8%A8%D9%88-%D8%B9%D9%85%D8%A7%D8%B1-egqee)







Aug 14, 2024



### Model Predictive Control from Mere Natural Language Commands



Generating model predictive control without domain expertise via large language models! Significant progress is beingâ€¦

`` ``



17

`` `` `` `` `` `` ``

- [DATA INTERPRETER: AN LLM AGENT FOR DATA SCIENCE](https://www.linkedin.com/pulse/data-interpreter-llm-agent-science-haitham-bou-ammar-%D9%87%D9%8A%D8%AB%D9%85-%D8%A8%D9%88-%D8%B9%D9%85%D8%A7%D8%B1-whape)







Aug 13, 2024



### DATA INTERPRETER: AN LLM AGENT FOR DATA SCIENCE



Introduction In the rapidly evolving field of artificial intelligence, large language models (LLMs) have emerged asâ€¦

`` ``



16

`` `` `` `` `` `` ``

- [A Leap Towards Human-Like AI: Recreating Human Memory in LLMs](https://www.linkedin.com/pulse/leap-towards-human-like-ai-recreating-human-memory-%D9%87%D9%8A%D8%AB%D9%85-%D8%A8%D9%88-%D8%B9%D9%85%D8%A7%D8%B1-gz8ce)







Aug 10, 2024



### A Leap Towards Human-Like AI: Recreating Human Memory in LLMs



In artificial intelligence, large language models (LLMs) have demonstrated remarkable capabilities in understanding andâ€¦

`` ``



42

`` `` `` `` `` `` ``

5 Comments

- [Pluralistic Alignment of LLMs: Fix your Algorithm not just your data](https://www.linkedin.com/pulse/pluralistic-alignment-llms-fix-your-algorithm-just-%D9%87%D9%8A%D8%AB%D9%85-%D8%A8%D9%88-%D8%B9%D9%85%D8%A7%D8%B1-1cose)







Aug 6, 2024



### Pluralistic Alignment of LLMs: Fix your Algorithm not just your data



Interjection: Recent studies have found that large language models (LLMs) are biased, with many articles demonstratingâ€¦

`` ``



10

`` `` `` `` `` `` ``

- [Robotic Parkour with Deep RL](https://www.linkedin.com/pulse/robotic-parkour-deep-rl-haitham-bou-ammar)







Jul 8, 2023



### Robotic Parkour with Deep RL



This post summarises the fantastic work from Hoeller et. 2023.

`` ``



61

`` `` `` `` `` `` ``

3 Comments

- [Empowering Efficient BO Transfer with Neural Acquisition Process (NAP)](https://www.linkedin.com/pulse/empowering-efficient-bo-transfer-neural-acquisition-nap-bou-ammar)







Jun 5, 2023



### Empowering Efficient BO Transfer with Neural Acquisition Process (NAP)



General Objectives & Results: Our primary objective is to enhance the effectiveness of Bayesian Optimisation (BO) byâ€¦

`` ``



57

`` `` `` `` `` `` ``


Show more

[See all articles](https://uk.linkedin.com/in/haitham-bou-ammar-a723a932/recent-activity/articles/)

## Sign in

Stay updated on your professional world

[Sign in](https://www.linkedin.com/uas/login?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_xandr-ad-fallback_signin)

By clicking Continue to join or sign in, you agree to LinkedInâ€™s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=article-ssr-frontend-pulse_auth-button_user-agreement), [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=article-ssr-frontend-pulse_auth-button_privacy-policy), and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=article-ssr-frontend-pulse_auth-button_cookie-policy).

New to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=%2Fpulse%2Freasoning-llms-mcts-over-tokens-motivation-three-papers-bou-ammar-rl6uc&trk=article-ssr-frontend-pulse_xandr-ad-fallback_join-link)

## Insights from the community

- [Artificial Intelligence\
\
What are the biggest challenges of making machine learning models transparent and explainable?](https://www.linkedin.com/advice/0/what-biggest-challenges-making-machine-jaglf)
- [Algorithms\
\
Here's how you can unleash creativity to create groundbreaking algorithms for image recognition.](https://www.linkedin.com/advice/0/heres-how-you-can-unleash-creativity-create-groundbreaking-ojjze)
- [Algorithm Development\
\
What are the benefits and challenges of using randomized algorithms in AI applications?](https://www.linkedin.com/advice/3/what-benefits-challenges-using-randomized)
- [Artificial Neural Networks\
\
How do you incorporate prior knowledge or constraints into GANs' loss functions?](https://www.linkedin.com/advice/0/how-do-you-incorporate-prior-knowledge-2f)
- [Machine Learning\
\
What's the best way to choose a model architecture that's easy to interpret?](https://www.linkedin.com/advice/1/whats-best-way-choose-model-architecture-thats-ufacf)
- [Generative AI\
\
How do you apply GANs to novel and challenging domains, such as text, graphs, or 3D models?](https://www.linkedin.com/advice/3/how-do-you-apply-gans-novel-challenging-domains-text)
- [Computer Science\
\
What are the best techniques for using gated recurrent units in machine learning algorithms?](https://www.linkedin.com/advice/1/what-best-techniques-using-gated-recurrent-units-dslce)

Show more

Show less

## Others also viewed

- [**The New Intelligence** \
\
Obvious Ventures\
2y](https://www.linkedin.com/pulse/new-intelligence-obvious-ventures)
- [**How close are we to developing true artificial general intelligence like in the movies?** \
\
Pinaki Laskar\
1y](https://www.linkedin.com/pulse/how-close-we-developing-true-artificial-general-like-movies-laskar-ef9jf)
- [**Brilliant Polymaths & NewAge synthetic Intellects** \
\
Aravindan Umashankar\
2mo](https://www.linkedin.com/pulse/brilliant-polymaths-newage-synthetic-intellects-aravindan-umashankar-ih61f)
- [**Enhanced Problem-Solving, Improved Flexibility, Handling Uncertainty, and Tree of Thoughts AI** \
\
Jim Santana\
8mo](https://www.linkedin.com/pulse/enhanced-problem-solving-improved-flexibility-handling-jim-santana-bwwec)
- [**The Quantum-Ready Future of AI: How the Transformerâ€“Huginn Synergy Could Redefine Intelligent Systems** \
\
Oliver Neutert\
2mo](https://www.linkedin.com/pulse/quantum-ready-future-ai-how-transformerhuginn-synergy-oliver-neutert-3qfzf)
- [**The Architecture of Artificial Minds: A Journey Through AI's Layers of Being** \
\
Arup Maity\
2mo](https://www.linkedin.com/pulse/architecture-artificial-minds-journey-through-ais-layers-arup-maity-ss5fc)
- [**Top AI/ML Papers of the Week \[29/04 - 05/05\]** \
\
Bruno Lopes e Silva\
11mo](https://www.linkedin.com/pulse/top-aiml-papers-week-2904-0505-bruno-miguel-l-silva-ftomf)
- [**Neurosymbolic Nerding Out** \
\
Brad Edwards\
1y](https://www.linkedin.com/pulse/neurosymbolic-nerding-out-brad-edwards-1c)
- [**Artificial Intelligence: The Technology Shaping Human Destiny** \
\
Maloy Chakraborti\
6mo](https://www.linkedin.com/pulse/artificial-intelligence-technology-shaping-human-mlqxc)
- [**Creating AI without Turing's prejudice: Reality vs. Perception, Quantity vs. Quality: why computers canâ€™t think as humans** \
\
Azamat Abdoullaev\
2y](https://www.linkedin.com/pulse/creating-ai-without-turings-prejudice-machine-vs-human-abdoullaev)

Show more

Show less

## Explore topics

- [Sales](https://www.linkedin.com/pulse/topics/sales-s5/)
- [Marketing](https://www.linkedin.com/pulse/topics/marketing-s2461/)
- [IT Services](https://www.linkedin.com/pulse/topics/it-services-s57547/)
- [Business Administration](https://www.linkedin.com/pulse/topics/business-administration-s50111/)
- [HR Management](https://www.linkedin.com/pulse/topics/hr-management-s50359/)
- [Engineering](https://www.linkedin.com/pulse/topics/engineering-s166/)
- [Soft Skills](https://www.linkedin.com/pulse/topics/soft-skills-s2976/)
- [See All](https://www.linkedin.com/pulse/topics/home/)
