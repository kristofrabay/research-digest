# Chain of Thought Prompting Elicits Reasoning in Large Language Models
     
      (2201.11903v1)

**URL:** https://www.emergentmind.com/articles/2201.11903
**Published:** None

---

## Summary

The webpage summarizes the paper "Chain of Thought Prompting Elicits Reasoning in Large Language Models" (2201.11903).

**Summary relevant to the user query:**

The paper introduces **Chain-of-Thought (CoT) prompting**, a technique that elicits **reasoning** in Large Language Models (LLMs) by including intermediate reasoning steps in few-shot examples.

*   **Reasoning LLMs & Chain-of-Thought:** CoT prompting guides LLMs to generate a "chain of thought"—a series of short sentences mimicking a human reasoning process—before providing the final answer. This significantly improves performance on multi-step reasoning tasks like arithmetic, commonsense, and symbolic manipulation, which large models often struggle with using standard prompting.
*   **Emergent Ability & Inference-Time Compute:** CoT reasoning was found to be an **emergent ability** tied to model scale; it only consistently improved performance for models larger than approximately 100 billion parameters. The increased output length implies increased **inference-time compute**.
*   **Hallucination Reduction and Detection (Factuality):** While CoT improves performance, the paper notes a limitation: there is **no guarantee that the generated chains of thought are factually correct or logically sound**, even if they lead to a correct answer. Manual analysis showed that errors in reasoning (major errors) and calculation/logic (minor errors) still occur, highlighting an open challenge in ensuring the **factuality** of the generated reasoning.
*   **Planning with LLMs:** The paper tested CoT on commonsense reasoning tasks like StrategyQA and SayCan robot **planning**, showing applicability beyond pure arithmetic.
*   **Grounding:** The paper does not explicitly discuss grounding in the context of external knowledge bases, but the manual analysis suggests that major errors stem from semantic understanding issues, which relates to how well the model grounds its reasoning in the problem's context.

**Topics not explicitly covered or detailed:**

*   MCTS (Monte Carlo Tree Search) for language models.
*   Self-reflection (though CoT is a form of self-correction/step-by-step verification).
*   Test-time scaling (beyond the observation that CoT emerges at scale).

---

## Full Content

Chain-of-Thought Prompting in LLMs
2201.11903
Papers
Topics
Lightbulb On Streamline Icon: https://streamlinehq.com
Authors
Recent
[View all](https://www.emergentmind.com/history)
Magnifying Glass Streamline Icon: https://streamlinehq.com
 
 
2000 character limit reached
[SponsorInformation Square Streamline Icon: https://streamlinehq.com](https://www.emergentmind.com/sponsorship)
[![](https://d2zk8qdx2y1ber.cloudfront.net/assets/sponsors/paperpile-logo-w343-d7fd7c8c33d166ed3ac6f5bb45f26f8b89eca7f00c1e1433295e91ce6a7d2fae.png)](https://www.paperpile.com?utm_source=emergentmind&utm_medium=sidebar-image)
Organize your preprints, BibTeX, and PDFs with Paperpile.
[Get 30 days free](https://www.paperpile.com?utm_source=emergentmind&utm_medium=sidebar-text)
Chrome Extension
Enhance arXiv with our new Chrome Extension.
[Chrome Extension](https://chromewebstore.google.com/detail/emergent-mind-—-arxiv-int/hgmnadjffdiipehljmhagdgpaoiiklml)
# Chain of Thought Prompting Elicits Reasoning in Large Language Models(2201.11903v1)
Published28 Jan 2022 in cs.CL and cs.AI
**Abstract:**Although scaling up LLM size has reliably improved performance on a range of NLP tasks, even the largest models currently struggle with certain reasoning tasks such as math word problems, symbolic manipulation, and commonsense reasoning. This paper explores the ability of LLMs to generate a coherent chain of thought -- a series of short sentences that mimic the reasoning process a person might have when responding to a question. Experiments show that inducing a chain of thought via prompting can enable sufficiently LLMs to better perform reasoning tasks that otherwise have flat scaling curves.
[Abstract](https://arxiv.org/abs/2201.11903)[PDF](https://arxiv.org/pdf/2201.11903)[Chat Bubble Oval Streamline Icon: https://streamlinehq.comChat (Pro)](https://www.emergentmind.com/pricing)
Citations (6,541)
[View on Semantic Scholar]()
### Sponsor
[![](https://d2zk8qdx2y1ber.cloudfront.net/assets/sponsors/paperpile-logo-w343-d7fd7c8c33d166ed3ac6f5bb45f26f8b89eca7f00c1e1433295e91ce6a7d2fae.png)](https://www.paperpile.com?utm_source=emergentmind&utm_medium=inline-logo)
Organize your preprints, BibTeX, and PDFs with Paperpile.
[Get 30 days free](https://www.paperpile.com?utm_source=emergentmind&amp;utm_medium=inline-button)
[![Paperpile](https://d2zk8qdx2y1ber.cloudfront.net/assets/sponsors/paperpile-on-laptop-caa897b8bd2dbb1dedf34da417761efa97093c381f939bf194fee6ef94a9b446.png)](https://www.paperpile.com?utm_source=emergentmind&amp;utm_medium=inline-screenshot)
### Summary
* The paper introduces chain-of-thought prompting that guides LLMs through intermediate reasoning steps to improve multi-step solving capabilities.
* It demonstrates substantial performance gains on arithmetic, commonsense, and symbolic reasoning tasks with models over 100B parameters.
* The approach requires no fine-tuning, offering enhanced interpretability and practical insights into the model’s reasoning process.
This paper, &quot;Chain-of-Thought Prompting Elicits Reasoning in LLMs&quot; (2201.11903), introduces a simple prompting technique called[chain-of-thought](https://www.emergentmind.com/topics/chain-of-thought-cot-6c32f039-72dd-425a-88b0-8f648cabbe4e)([CoT](https://www.emergentmind.com/topics/chain-of-thoughts-cot)) prompting that significantly enhances the reasoning abilities of LLMs. The core idea is to include a sequence of intermediate reasoning steps—a &quot;chain of thought&quot;—in the few-shot exemplars provided in the prompt, guiding the model to generate similar intermediate steps before producing the final answer.
**Core Idea and Motivation**
Standard[few-shot prompting](https://www.emergentmind.com/topics/few-shot-prompting), where the model is given input-output pairs, has been successful for many tasks but often falls short on those requiring multi-step reasoning, like arithmetic word problems or complex commonsense questions. Prior work addressed this by training or finetuning models to generate intermediate steps or rationales, but creating large datasets of high-quality rationales is costly.[Chain-of-thought prompting](https://www.emergentmind.com/topics/chain-of-thought-prompting-348cd614-e776-4486-8999-0d4a0246a5bc)(2201.11903) combines the benefits of generating intermediate steps with the advantages of few-shot prompting. Instead of just`input -&gt; output`examples, CoT prompting uses`input -&gt; chain of thought -&gt; output`examples. This approach requires no model finetuning, allowing a single LLM to perform various reasoning tasks using only few-shot prompting.
**Experimental Setup**
The researchers evaluated CoT prompting on a diverse set of reasoning tasks:
1. **Arithmetic Reasoning:**Math word problems from benchmarks like GSM8K, SVAMP, ASDiv, AQuA, and MAWPS.
2. **Commonsense Reasoning:**Tasks including CSQA, StrategyQA, Date Understanding, Sports Understanding, and SayCan robot planning.
3. **Symbolic Reasoning:**Toy tasks like last letter concatenation and coin flip, designed to test the model&#39;s ability to manipulate symbols and track state.
Experiments were conducted using various LLMs, including LaMDA, GPT-3 (InstructGPT variants), PaLM, UL2, and Codex. For each task, a small number of few-shot exemplars (typically 8, manually composed) were used. The standard prompting baseline used the same exemplars but excluded the intermediate[chain-of-thought steps](https://www.emergentmind.com/topics/chain-of-thought-cot-steps-ea304189-c8ce-48b7-9907-442fc45e07b5). Greedy decoding[was](https://www.emergentmind.com/topics/wireless-agents-was)primarily used for generation. For arithmetic tasks, the authors also investigated the effect of using an external Python calculator to evaluate the mathematical expressions generated within the chain of thought, demonstrating that errors can stem from either reasoning logic or arithmetic computation itself.
**Key Findings**
The experiments revealed several significant findings:
* **Emergent Ability:**[Chain-of-thought reasoning](https://www.emergentmind.com/topics/chain-of-thought-reasoning)was found to be an*emergent ability*of model scale (2201.11903). It did not consistently improve performance, and sometimes even hurt it, for models smaller than approximately 100 billion parameters. Only with sufficiently large models (e.g., GPT-3 175B, PaLM 540B) did CoT prompting consistently and significantly improve performance on reasoning tasks compared to standard prompting. Smaller models tended to produce fluent but often illogical or incoherent chains of thought.
* **Performance Gains:**CoT prompting yielded substantial performance improvements across the tested benchmarks.
* On GSM8K (math word problems), PaLM 540B with CoT achieved a solve rate of 56.9%, a significant jump from 17.9% with standard prompting, surpassing prior state-of-the-art results.
* Similar large gains were observed on other math datasets like SVAMP and MAWPS, particularly on the more complex multi-step subsets.
* For commonsense tasks like StrategyQA and Date Understanding, CoT prompting also improved performance, demonstrating its applicability beyond purely numerical problems.
* In[symbolic reasoning tasks](https://www.emergentmind.com/topics/symbolic-reasoning-tasks)(last letter concatenation, coin flip), CoT enabled impressive performance, often approaching 100% accuracy for in-domain examples on large models.
* **Generalization to Length:**CoT prompting facilitated generalization to out-of-domain examples with more steps than seen in the few-shot prompt (e.g., longer names for concatenation, more flips for coin tracking), a capability largely absent in standard prompting.
* **Ablation Studies:**Experiments compared CoT prompting against variants:
* **Equation only:**Prompting the model to output only a mathematical equation before the answer provided some benefit for simpler arithmetic tasks but was less effective than full CoT on complex problems like GSM8K, suggesting the natural language steps are crucial for semantic understanding and decomposition (2201.11903).
* **Variable compute only:**Prompting the model to output a series of dots equivalent to the computation length showed little improvement, indicating that simply spending more tokens is not the key; the content of the intermediate steps matters (2201.11903).
* **Reasoning after answer:**Placing the chain of thought*after*the final answer did not improve performance, suggesting that the sequential generation of reasoning steps*leading to*the answer is essential for deriving the solution (2201.11903).
* **Robustness:**While exemplar-based prompting can be sensitive, CoT prompting showed robustness across different annotators who wrote the chains of thought, different sets of exemplars (including those from a separate dataset), and variations in the number and order of exemplars (2201.11903).
**Manual Analysis**
A manual analysis of generated chains of thought for LaMDA 137B on GSM8K provided insight into*why*CoT works and where models still fail. For correct answers, the generated chains of thought were mostly logically and mathematically sound. For incorrect answers, errors were categorized:
* Minor errors (calculator errors, symbol mapping errors, one step missing) accounted for a significant portion of mistakes (46%). Scaling models from 62B to 540B was observed to fix many of these types of errors, suggesting improved semantic understanding and logical flow with scale.
* Major errors (semantic understanding errors, incoherent reasoning) constituted the remaining mistakes (54%).
This analysis suggests that improvements in foundational abilities like semantic understanding and the ability to maintain coherent, step-by-step logic contribute to the emergence of CoT reasoning at scale (2201.11903).
**Practical Implications and Limitations**
CoT prompting offers a powerful way to unlock the reasoning capabilities of existing LLMs without needing expensive task-specific finetuning datasets. It provides a degree of interpretability by showing the steps the model took.
However, the approach has limitations:
* It is most effective only on very large models, which are costly to train and serve.
* There is no guarantee that the generated chains of thought are factually correct or logically sound, even if they lead to a correct answer, particularly for non-arithmetic tasks. Ensuring the factuality and coherence of generated reasoning remains an open challenge.
* While few-shot annotation cost is minimal, creating extensive CoT data for potential finetuning applications would be expensive, although[synthetic data generation](https://www.emergentmind.com/topics/synthetic-data-generation)could be explored.
* [Chain of thought](https://www.emergentmind.com/topics/chain-of-thought-cot)may not be beneficial for all tasks, particularly simple ones where standard prompting already performs well or tasks that don&#39;t naturally decompose into sequential steps.
The paper concludes that CoT prompting demonstrates that standard prompting may only show a lower bound of LLMs&#39; capabilities and highlights the potential for further exploration of language-based reasoning methods (2201.11903).
[File Document Download Save Streamline Icon: https://streamlinehq.comPDF](https://www.emergentmind.com/users/sign_up?redirect_to=https://www.emergentmind.com/articles/2201.11903)[File Document Download Save Streamline Icon: https://streamlinehq.comMarkdown](https://www.emergentmind.com/users/sign_up?redirect_to=https://www.emergentmind.com/articles/2201.11903)
### Whiteboard
Generate a whiteboard explanation of this paper.
[Ai Sparkles Streamline Icon: https://streamlinehq.comSign Up to Generate](https://www.emergentmind.com/users/sign_up?redirect_to=https://www.emergentmind.com/articles/2201.11903)
### Paper Prompts
Sign up for free to create and run prompts on this paper using GPT-5.
#### Top Community Prompts
[Explain it Like I&#39;m 14](https://www.emergentmind.com/paper-prompts/eli14)[
offon
](https://www.emergentmind.com/users/sign_up)
[Knowledge Gaps](https://www.emergentmind.com/paper-prompts/knowledge-gaps)[
offon
](https://www.emergentmind.com/users/sign_up)
[Glossary](https://www.emergentmind.com/paper-prompts/glossary)[
offon
](https://www.emergentmind.com/users/sign_up)
[Practical Applications](https://www.emergentmind.com/paper-prompts/practical-applications)[
offon
](https://www.emergentmind.com/users/sign_up)
[Conceptual Simplification](https://www.emergentmind.com/paper-prompts/conceptual-simplification)[
offon
](https://www.emergentmind.com/users/sign_up)
[User Circle Single Streamline Icon: https://streamlinehq.comSign Up to Activate](https://www.emergentmind.com/users/sign_up?redirect_to=https://www.emergentmind.com/papers/2201.11903)[List Streamline Icon: https://streamlinehq.comView All Prompts](https://www.emergentmind.com/paper-prompts)
### Open Problems
We haven't generated a list of open problems mentioned in this paper yet.
[Ai Sparkles Streamline Icon: https://streamlinehq.comGenerate Now](https://www.emergentmind.com/users/sign_up?redirect_to=https://www.emergentmind.com/articles/2201.11903)
### Continue Learning
1. [How does chain-of-thought prompting interact with model architectures or pretraining data—are some models or data sources more conducive to emergent reasoning abilities?](https://www.emergentmind.com/search?q=How+does+chain-of-thought+prompting+interact+with+model+architectures+or+pretraining+data%E2%80%94are+some+models+or+data+sources+more+conducive+to+emergent+reasoning+abilities?+(2201.11903))
2. [What strategies exist or could be developed to ensure that generated chains of thought are logically sound and factually accurate, especially for tasks beyond arithmetic?](https://www.emergentmind.com/search?q=What+strategies+exist+or+could+be+developed+to+ensure+that+generated+chains+of+thought+are+logically+sound+and+factually+accurate,+especially+for+tasks+beyond+arithmetic?+(2201.11903))
3. [How robust is CoT prompting across languages, domains, or culturally specific reasoning tasks—can it generalize to non-English or highly domain-specific problems?](https://www.emergentmind.com/search?q=How+robust+is+CoT+prompting+across+languages,+domains,+or+culturally+specific+reasoning+tasks%E2%80%94can+it+generalize+to+non-English+or+highly+domain-specific+problems?+(2201.11903))
4. [What are the computational and latency trade-offs for deploying CoT prompting in real-world applications, given the increased length and complexity of model outputs?](https://www.emergentmind.com/search?q=What+are+the+computational+and+latency+trade-offs+for+deploying+CoT+prompting+in+real-world+applications,+given+the+increased+length+and+complexity+of+model+outputs?+(2201.11903))
5. [Find recent papers about improving the reliability and factuality of chain-of-thought reasoning in large language models.](https://www.emergentmind.com/search?q=Find+recent+papers+about+improving+the+reliability+and+factuality+of+chain-of-thought+reasoning+in+large+language+models.)
### Related Papers
1. [Large Language Models as Analogical Reasoners](https://www.emergentmind.com/articles/2310.01714)(2023)
2. [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models](https://www.emergentmind.com/articles/2205.10625)(2022)
3. [Large Language Models are Zero-Shot Reasoners](https://www.emergentmind.com/articles/2205.11916)(2022)
4. [Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters](https://www.emergentmind.com/articles/2212.10001)(2022)
5. [Teaching Small Language Models to Reason](https://www.emergentmind.com/articles/2212.08410)(2022)
6. [Automatic Chain of Thought Prompting in Large Language Models](https://www.emergentmind.com/articles/2210.03493)(2022)
7. [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://www.emergentmind.com/articles/2305.04091)(2023)
8. [Contrastive Chain-of-Thought Prompting](https://www.emergentmind.com/articles/2311.09277)(2023)
9. [Chain-of-Thought Reasoning Without Prompting](https://www.emergentmind.com/articles/2402.10200)(2024)
10. [ChainLM: Empowering Large Language Models with Improved Chain-of-Thought Prompting](https://www.emergentmind.com/articles/2403.14312)(2024)
### Authors (9)
1. [Jason Wei](https://www.emergentmind.com/search?q=Jason+Wei)
2. [Xuezhi Wang](https://www.emergentmind.com/search?q=Xuezhi+Wang)
3. [Dale Schuurmans](https://www.emergentmind.com/search?q=Dale+Schuurmans)
4. [Maarten Bosma](https://www.emergentmind.com/search?q=Maarten+Bosma)
5. [Ed Chi](https://www.emergentmind.com/search?q=Ed+Chi)
6. [Quoc Le](https://www.emergentmind.com/search?q=Quoc+Le)
7. [Denny Zhou](https://www.emergentmind.com/search?q=Denny+Zhou)
### Collections
Sign up for free to add this paper to one or more collections.
[User Circle Single Streamline Icon: https://streamlinehq.comSign Up](https://www.emergentmind.com/users/sign_up?redirect_to=https://www.emergentmind.com/articles/2201.11903)
### Tweets
Sign up for free to view the**107 tweets**with**2418 likes**about this paper.
[User Circle Single Streamline Icon: https://streamlinehq.comSign Up for Free](https://www.emergentmind.com/users/sign_up?redirect_to=https://www.emergentmind.com/articles/2201.11903)
### YouTube
[Show All Videos](#)
Content
[Paper](#paper)[Summary](#summary)[Whiteboard](#whiteboard)[Paper Prompts](#prompts)[Open Problems](#open-problems)[Continue Learning](#continue-learning)[Related Papers](#related-papers)[Authors](#authors)[Collections](#collections)[Tweets](#x)[YouTube](#youtube)
Stay informed about trending AI/ML papers:
 
## Don't miss out on important new AI/ML research
See which papers are being discussed right now on X, Reddit, and more:
[
![](https://d2zk8qdx2y1ber.cloudfront.net/assets/trending-fde8de4bc94d03d5767ec2ce0bd5b89fa415d9b1ded4c842d7eea6fd460e2d48.webp)
](https://www.emergentmind.com/)
[Explore Trending Papers](https://www.emergentmind.com/)
> > > > > &#8220;Emergent Mind helps me see which AI papers have caught fire online.&#8221; > > > > > > ![Philip](https://d2zk8qdx2y1ber.cloudfront.net/assets/homepage/testimonials/ai-explained-247821fa1557c54ceb4cb888dd587fce50bac63f02a0eaee990ad45b18462952.webp)> > > > > > > Philip > > > Creator, AI Explained on YouTube > > > > >
