{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d002122a",
   "metadata": {},
   "source": [
    "## Step 1: Pipeline to run research to collect candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76bda8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 19:39:23,699 - data.content_manager - INFO - Loaded content index with 2484 entries\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from components.agents.research_agents import run_mixed_research_agents\n",
    "from components.prompts.research_agents import FOCUS_AREAS\n",
    "from data.content_manager import ContentManager\n",
    "from data.dedup import deduplicate_research\n",
    "\n",
    "content_manager = ContentManager(base_path=\"../data\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdfbd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1624bf",
   "metadata": {},
   "source": [
    "## 1. Using OpenAI, Anthropic and EXA web agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447c8133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['reasoning_and_planning', 'agents_and_finance', 'agent_infrastructure', 'retrieval_and_embeddings', 'multimodal_and_generation'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOCUS_AREAS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faaa1fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning LLMs, chain-of-thought, inference-time compute, self-reflection, planning with LLMs, MCTS (Monte Carlo Tree Search) for language models, test-time scaling, hallucination reduction and detection, grounding, factuality\n"
     ]
    }
   ],
   "source": [
    "print(FOCUS_AREAS['reasoning_and_planning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735d34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "855c4bed",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4762f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 19:39:30,773 - components.agents.research_agents - INFO - Running 15 tasks\n",
      "Research agents (mixed):   0%|          | 0/15 [00:00<?, ?it/s]2025-12-28 19:39:30,790 - components.agents.research_agents - INFO - Running OpenAI research agent for focus area: agents_and_finance\n",
      "2025-12-28 19:39:31,084 - components.agents.research_agents - INFO - Running Anthropic research agent for focus area: agent_infrastructure\n",
      "2025-12-28 19:39:31,093 - components.agents.research_agents - INFO - Running OpenAI research agent for focus area: multimodal_and_generation\n",
      "2025-12-28 19:39:31,096 - components.agents.research_agents - INFO - Running OpenAI research agent for focus area: agent_infrastructure\n",
      "2025-12-28 19:39:31,098 - components.agents.research_agents - INFO - Running Exa research agent for focus area: reasoning_and_planning\n",
      "2025-12-28 19:39:31,134 - components.agents.research_agents - INFO - Running Exa research agent for focus area: agent_infrastructure\n",
      "2025-12-28 19:39:31,135 - components.agents.research_agents - INFO - Running Anthropic research agent for focus area: agents_and_finance\n",
      "2025-12-28 19:39:31,137 - components.agents.research_agents - INFO - Running OpenAI research agent for focus area: reasoning_and_planning\n",
      "2025-12-28 19:39:31,139 - components.agents.research_agents - INFO - Running Exa research agent for focus area: agents_and_finance\n",
      "2025-12-28 19:39:31,141 - components.agents.research_agents - INFO - Running Exa research agent for focus area: multimodal_and_generation\n",
      "2025-12-28 19:39:31,141 - components.agents.research_agents - INFO - Running Anthropic research agent for focus area: multimodal_and_generation\n",
      "2025-12-28 19:39:31,142 - components.agents.research_agents - INFO - Running OpenAI research agent for focus area: retrieval_and_embeddings\n",
      "2025-12-28 19:39:31,144 - components.agents.research_agents - INFO - Running Anthropic research agent for focus area: retrieval_and_embeddings\n",
      "2025-12-28 19:39:31,145 - components.agents.research_agents - INFO - Running Anthropic research agent for focus area: reasoning_and_planning\n",
      "2025-12-28 19:39:31,146 - components.agents.research_agents - INFO - Running Exa research agent for focus area: retrieval_and_embeddings\n",
      "2025-12-28 19:39:35,706 - httpx - INFO - HTTP Request: POST https://api.exa.ai/search \"HTTP/1.1 200 OK\"\n",
      "2025-12-28 19:39:35,714 - httpx - INFO - HTTP Request: POST https://api.exa.ai/search \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):   7%|▋         | 1/15 [00:05<01:21,  5.83s/it]2025-12-28 19:39:36,616 - httpx - INFO - HTTP Request: POST https://api.exa.ai/search \"HTTP/1.1 200 OK\"\n",
      "2025-12-28 19:39:36,617 - httpx - INFO - HTTP Request: POST https://api.exa.ai/search \"HTTP/1.1 200 OK\"\n",
      "2025-12-28 19:39:36,619 - httpx - INFO - HTTP Request: POST https://api.exa.ai/search \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):  20%|██        | 3/15 [00:09<00:34,  2.86s/it]2025-12-28 19:41:04,828 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true \"HTTP/1.1 200 OK\"\n",
      "2025-12-28 19:41:05,252 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):  40%|████      | 6/15 [01:34<02:57, 19.74s/it]2025-12-28 19:41:08,711 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):  53%|█████▎    | 8/15 [01:38<01:29, 12.83s/it]2025-12-28 19:41:15,551 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):  60%|██████    | 9/15 [01:45<01:09, 11.53s/it]2025-12-28 19:41:26,006 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages?beta=true \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):  67%|██████▋   | 10/15 [01:55<00:56, 11.26s/it]2025-12-28 19:44:21,626 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "/Users/kristof.rabay/Documents/code/research-digest/.venv/lib/python3.11/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseOutputMessage` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseFileSearchToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseFunctionToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(PydanticSerializationUnexpectedValue: Expected `literal['search']` - serialized value may not be as expected [field_name='type', input_value='find_in_page', input_type=str]\n",
      "PydanticSerializationUnexpectedValue: Expected `ActionOpenPage` - serialized value may not be as expected [field_name='action', input_value=ActionSearch(query=None, .../weaviate-1-21-release'), input_type=ActionSearch]\n",
      "PydanticSerializationUnexpectedValue: Expected `ActionFind` - serialized value may not be as expected [field_name='action', input_value=ActionSearch(query=None, .../weaviate-1-21-release'), input_type=ActionSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseComputerToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseReasoningItem` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseCompactionItem` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ImageGenerationCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseCodeInterpreterToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `LocalShellCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseFunctionShellToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseFunctionShellToolCallOutput` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseApplyPatchToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseApplyPatchToolCallOutput` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `McpCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `McpListTools` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `McpApprovalRequest` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseCustomToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseOutputMessage` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseFileSearchToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseFunctionToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(PydanticSerializationUnexpectedValue: Expected `literal['search']` - serialized value may not be as expected [field_name='type', input_value='find_in_page', input_type=str]\n",
      "PydanticSerializationUnexpectedValue: Expected `ActionOpenPage` - serialized value may not be as expected [field_name='action', input_value=ActionSearch(query=None, ...2.5.x/release_notes.md'), input_type=ActionSearch]\n",
      "PydanticSerializationUnexpectedValue: Expected `ActionFind` - serialized value may not be as expected [field_name='action', input_value=ActionSearch(query=None, ...2.5.x/release_notes.md'), input_type=ActionSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseComputerToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseReasoningItem` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseCompactionItem` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ImageGenerationCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseCodeInterpreterToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `LocalShellCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseFunctionShellToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseFunctionShellToolCallOutput` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseApplyPatchToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseApplyPatchToolCallOutput` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `McpCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `McpListTools` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `McpApprovalRequest` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseCustomToolCall` - serialized value may not be as expected [field_name='output', input_value=ResponseFunctionWebSearch... type='web_search_call'), input_type=ResponseFunctionWebSearch])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "Research agents (mixed):  73%|███████▎  | 11/15 [04:51<03:31, 52.76s/it]2025-12-28 19:44:28,784 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):  80%|████████  | 12/15 [04:58<02:01, 40.59s/it]2025-12-28 19:45:05,028 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):  87%|████████▋ | 13/15 [05:34<01:18, 39.41s/it]2025-12-28 19:45:48,785 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed):  93%|█████████▎| 14/15 [06:18<00:40, 40.61s/it]2025-12-28 19:47:09,956 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "Research agents (mixed): 100%|██████████| 15/15 [07:39<00:00, 30.62s/it]\n"
     ]
    }
   ],
   "source": [
    "research_results = await run_mixed_research_agents(\n",
    "    focus_areas=FOCUS_AREAS,\n",
    "    content_manager=content_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf349753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21291fee",
   "metadata": {},
   "source": [
    "### Deduplicate based on URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65b52513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 449 ResearchItems present in the research results\n"
     ]
    }
   ],
   "source": [
    "# Parse the research results into a flat list of records\n",
    "records = []\n",
    "for key, result in research_results.items():\n",
    "    focus_area, llm_provider = key.split(' --- ')\n",
    "    for item in result.items:\n",
    "        records.append({\n",
    "            'focus_area': focus_area,\n",
    "            'provider': llm_provider,\n",
    "            'url': item.url,\n",
    "            'title': item.title,\n",
    "            'source': item.source,\n",
    "            'published': item.published,\n",
    "            'relevance': item.relevance,\n",
    "            'date_added': datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(f\"There are {len(df)} ResearchItems present in the research results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2cca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (449, 8)\n",
      "df.shape: (431, 8)\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate based on URL (keep first occurrence)\n",
    "print(f\"df.shape: {df.shape}\")\n",
    "df = df.drop_duplicates(subset='url', keep='first')\n",
    "print(f\"df.shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26686227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca441422",
   "metadata": {},
   "source": [
    "### Add to existing collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de618e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 19:47:10,391 - data.dedup - INFO - Loaded 4202 existing items from ../data/research_items.csv\n",
      "2025-12-28 19:47:10,393 - data.dedup - INFO - New items: 153, Skipped (duplicates): 278\n",
      "2025-12-28 19:47:10,581 - data.dedup - INFO - Saved 4355 items to ../data/research_items.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 153 new items\n",
      "Skipped 278 duplicates\n",
      "Total in DB: 4355\n"
     ]
    }
   ],
   "source": [
    "result = deduplicate_research(\n",
    "    new_df=df,\n",
    "    main_csv=\"../data/research_items.csv\",\n",
    "    save=True\n",
    ")\n",
    "\n",
    "print(f\"Added {result['new_added']} new items\")\n",
    "print(f\"Skipped {result['skipped']} duplicates\")\n",
    "print(f\"Total in DB: {result['total_after']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ededa2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84efbcdb",
   "metadata": {},
   "source": [
    "## 2. Using direct arXiv API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ebe73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.tools import ArxivClient, ARXIV_CATEGORIES, ARXIV_KEYWORDS\n",
    "arxiv = ArxivClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11fd00c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 19:48:04,431 - components.tools.arxiv - INFO - Found 3000 entries for submitted categories\n",
      "2025-12-28 19:48:17,260 - components.tools.arxiv - INFO - Found 150 entries for submitted keywords\n",
      "2025-12-28 19:48:17,263 - components.tools.arxiv - INFO - Found 3150 total entries\n"
     ]
    }
   ],
   "source": [
    "arxiv_results = arxiv.search_cats_and_kws_both(\n",
    "    categories=ARXIV_CATEGORIES,\n",
    "    keywords=ARXIV_KEYWORDS,\n",
    "    max_results_cats=3000,\n",
    "    max_results_kws=150,\n",
    "    last_n_days=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab7dc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3150"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arxiv_results.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f48aa9",
   "metadata": {},
   "source": [
    "Dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "878b7e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3150 ResearchItems present in the research results\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame (same as web agents)\n",
    "records = []\n",
    "for item in arxiv_results.items:\n",
    "    records.append({\n",
    "        'focus_area': 'arxiv',\n",
    "        'provider': 'arxiv',\n",
    "        'url': item.url,\n",
    "        'title': item.title,\n",
    "        'source': item.source,\n",
    "        'published': item.published,\n",
    "        'relevance': item.relevance,\n",
    "        'date_added': datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    })\n",
    "\n",
    "df_arxiv = pd.DataFrame(records)\n",
    "print(f\"There are {len(df_arxiv)} ResearchItems present in the research results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d013bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (3150, 8)\n",
      "df.shape: (3068, 8)\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate based on URL (keep first occurrence)\n",
    "print(f\"df.shape: {df_arxiv.shape}\")\n",
    "df_arxiv = df_arxiv.drop_duplicates(subset='url', keep='first')\n",
    "print(f\"df.shape: {df_arxiv.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05019c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceea463b",
   "metadata": {},
   "source": [
    "Add to existing collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912fdbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-28 19:48:49,907 - data.dedup - INFO - Loaded 4355 existing items from ../data/research_items.csv\n",
      "2025-12-28 19:48:49,910 - data.dedup - INFO - New items: 0, Skipped (duplicates): 3068\n",
      "2025-12-28 19:48:50,100 - data.dedup - INFO - Saved 4355 items to ../data/research_items.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0 new items\n",
      "Skipped 3068 duplicates\n",
      "Total in DB: 4355\n"
     ]
    }
   ],
   "source": [
    "result = deduplicate_research(\n",
    "    new_df=df_arxiv,\n",
    "    main_csv=\"../data/research_items.csv\",\n",
    "    save=True\n",
    ")\n",
    "\n",
    "print(f\"Added {result['new_added']} new items\")\n",
    "print(f\"Skipped {result['skipped']} duplicates\")\n",
    "print(f\"Total in DB: {result['total_after']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2b827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a42562d",
   "metadata": {},
   "source": [
    "### Check research items csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a87d23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_df = pd.read_csv(\"../data/research_items.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35606fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute counts:\n",
      "provider\n",
      "arxiv        3126\n",
      "openai        520\n",
      "anthropic     421\n",
      "exa           288\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Normalized (proportions):\n",
      "provider\n",
      "arxiv        0.717796\n",
      "openai       0.119403\n",
      "anthropic    0.096670\n",
      "exa          0.066131\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "provider_counts = recent_df['provider'].value_counts()\n",
    "print(\"Absolute counts:\")\n",
    "print(provider_counts)\n",
    "print(\"\\nNormalized (proportions):\")\n",
    "print(recent_df['provider'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad02998",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
