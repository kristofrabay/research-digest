{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d002122a",
   "metadata": {},
   "source": [
    "### Pipeline to run research to collect candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76bda8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from components.agents.research_agents import run_mixed_research_agents\n",
    "from components.prompts.research_agents import FOCUS_AREAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447c8133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['reasoning_and_planning', 'agents_and_finance', 'agent_infrastructure', 'retrieval_and_embeddings', 'multimodal_and_generation'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOCUS_AREAS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faaa1fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning LLMs, chain-of-thought, inference-time compute, self-reflection, planning with LLMs, MCTS (Monte Carlo Tree Search) for language models, test-time scaling, hallucination reduction and detection, grounding, factuality\n"
     ]
    }
   ],
   "source": [
    "print(FOCUS_AREAS['reasoning_and_planning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735d34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "855c4bed",
   "metadata": {},
   "source": [
    "### Test run on dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4762f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-24 16:10:34,006 - components.agents.research_agents - INFO - Running 2 tasks\n",
      "Research agents (mixed):   0%|          | 0/2 [00:00<?, ?it/s]2025-12-24 16:10:34,020 - components.agents.research_agents - INFO - Running OpenAI research agent for focus area: reasoning_agent\n",
      "2025-12-24 16:10:34,256 - components.agents.research_agents - INFO - Running Anthropic research agent for focus area: reasoning_agent\n"
     ]
    }
   ],
   "source": [
    "research_results = await run_mixed_research_agents(\n",
    "    {\"reasoning_agent\": \"reasoning agents, chain of thought planning with LLMs, test time compute\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cca26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
